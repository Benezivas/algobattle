{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Algobattle","text":"<p>Algobattle is a framework that lets you run tournaments where teams compete to solve algorithmic problems. It is being developed by the Computer Science Theory group of RWTH Aachen University, which also offers a lab course based on it since 2019. This repository contains the code that instructors and students need to run the tournament itself. In addition to that, we also develop Algobattle Web, a web server providing an easy-to-use interface to manage the overall structure of such a course.</p> <p>The idea of the lab is to pose several, usually NP-complete problems over the course of the semester. Teams of students then write code that generates hard-to-solve instances for these problems and solvers that solve these problems quickly. The teams then battle against each other, generating instances for other teams, and solving instances that were generated for them. Each team then is evaluated on its performance and is awarded points.</p>"},{"location":"#where-to-start-reading","title":"Where to start reading","text":"<p>The Algobattle documentation is aimed at two different groups of people: students participating in lab courses, and instructors running them. In order to keep everything short and sweet we've structured our documentation so that everyone can easily focus just on what they need to learn about.</p> <p>For everyone, the best place to start learning more about Algobattle is by reading through the tutorial. It contains everything you need to know to use the framework and start working with it. Students won't necessarily need anything further to participate in the course, but may later run into things they can best look up in the advanced section.</p> <p>After finishing the tutorial we then recommend instructors to go through the topics in the instructor's corner. This will get you up to speed to run an Algobattle lab course on your own.</p> <p>Just want a broad overview?</p> <p>If you're not yet interested in reading all the nitty-gritty and just want a basic idea of how such a Lab course works to decide if you want to run one yourself, the teaching concept is ideal for you!</p>"},{"location":"#requirements","title":"Requirements","text":"<p>This project is being developed and tested on both Windows and Linux, macOS support is being worked on but still is tentative. We require python version 3.11 or higher and Docker.</p> <p>Note</p> <p>You can find more detailed information on this, including how to install everything, in the tutorial.</p>"},{"location":"#license","title":"License","text":"<p>This project is freely available under the MIT license.</p>"},{"location":"advanced/","title":"Advanced Topics","text":"<p>This section cover various topics that aren't really necessary to understand in depth and aren't covered in the tutorial. It's not meant to be read as a single continuous narrative but rather as a reference guide to look up when you need to.</p>"},{"location":"advanced/battle_types/","title":"Battle Types","text":"<p>When Algobattle runs a match it executes several battles that score how good one team is at solving another team's instances. In this page we will take a look at how exactly this works by going through all battle types.</p> <p>Custom battle types</p> <p>Algobattle lets users create custom battle types. If you're looking for information to how the battle type you're using works and can't find it here it's best you ask your course instructor about it.</p>"},{"location":"advanced/battle_types/#iterated","title":"Iterated","text":"<p>The basic idea behind iterated battles is very straightforward. Generally solving bigger instances is much harder than solving smaller ones. So we can judge how well a solver is doing by searching for the biggest instance size it can solve correctly. But we of course the only thing we care about isn't just whether a solver is able to solve some instance, but whether it is able to do so using a reasonable amount of system resources.  Algorithmically this means that we give each program some fixed amount of time, memory space, and CPU cores and then try to find the largest size where the solver can still correctly solver instances generated for it. The easiest way to do this would be to just steadily increase the instance size one by one and stop when the solver fails.</p> <p>A big issue with this is that \"hard\" instance sizes may be rather large. For example, even a very inefficient solver can easily solve Pairsum instances containing less than a few hundred numbers within seconds. To speed things up iterated battles take a more aggressive approach, they increase the instance size in larger (and growing) steps until the solver fails. For example, the progression of instance sizes might be 1, 2, 5, 14, 30, 55, 91, etc. This quickly gives us a rough idea that we then fine tune recursively. Say the biggest size the solver can tackle is 64, this first series of fights would then succeed until 55 and fail at 91. The progression is then restarted at 55 going up, 56, 60, 64, 73, etc. Here the solver fails at 73 which causes the battle to again reset the size to 65. The solver again fails at this size, which means that the battle has found the correct size since the solver succeeded at everything below 64 but not anything higher.</p> <p>This system works very well for programs that have a very sharp cut-off between instance sizes they can solve easily and ones they struggle with. On the other hand, it has trouble assessing ones that operate with random elements since they might fail very early due to bad luck. To smooth things out and provide a fair experience for many approaches the Iterated battle repeats this process of increasing the instance size several times and averages the reached sizes.</p>"},{"location":"advanced/battle_types/#config","title":"Config","text":"<p>The Iterated battle type uses the following keys in the <code>match.battle</code> table in addition to <code>type = \"Iterated</code>:</p> <code>rounds</code> Number of rounds that will be run and averaged. A round is one sequence of fights until a size has been found where the solver succeeds at all smaller sizes and fails at all bigger ones. Defaults to 5. <code>maximum_size</code> Maximum size that will be iterated to. Defaults to 50000. <code>exponent</code> An integer that determines how quickly the size increases. For example, an exponent of 2 results in a size sequence of 1, 2, 6, 15, 31, etc. while an exponent of 3 leads to 1, 2, 9, 36, 100, 255, etc. Defaults to 2. <code>minimum_score</code> A float between 0 and 1 (inclusive) that is the minimum score a solver needs to achieve to \"successfully\" solve an instance. Defaults to 1. <code>max_generator_errors</code> If a generator fails to produce a valid instance, the solver wins the fight by default. This may create very lengthy battles where the generator keeps failing at higher and higher <code>max_size</code>s. You can use this setting to early exit and award the solver the full score if this happens. Set to an integer to exit after that many consecutive failures, or <code>\"unlimited\"</code> to never exit early."},{"location":"advanced/battle_types/#ui-data","title":"UI Data","text":"<p>Iterated battles display two values to the UI:</p> reached The biggest instance size reached in each round so far. cap The current cap on the instance size."},{"location":"advanced/battle_types/#averaged","title":"Averaged","text":"<p>It can also be interesting to restrict generators and solvers to a very narrow set of possible instances and see what possibilities for optimization this opens up. In particular, instead of considering how good a solver is at dealing with instances of increasing size we can judge how well it is at solving instances of a single, fixed size. This changes the thought process when writing the programs to favour more specialized approaches that try to tease out the best possible performance.</p> <p>Averaged battles fix not only the program runtime, memory, and CPU access, but also the instance size. A series of fights is run with these parameters and their results averaged.</p>"},{"location":"advanced/battle_types/#config_1","title":"Config","text":"<code>instance_size</code> The instance size every fight in each match will be fought at. Defaults to 25. <code>num_fights</code> The number of fights that will be fought in each match. Defaults to 10."},{"location":"advanced/battle_types/#ui-data_1","title":"UI Data","text":"<p>Averaged battles display a single value to the UI:</p> round The current round that is being fought."},{"location":"advanced/battle_types/#improving","title":"Improving","text":"<p>The idea behind this battle type is that the teams don't just create the best possible instances and solutions out of thin air, but try to learn over time and improve their output. We run multiple rounds, similar to Averaged battles, but programs will also receive information about the previous round's result. By default, this includes their score, the instances, and each program's own solutions.</p> <p>Example program input</p> <p>Using the default settings and the Pairsum problem, in the third round the solver would see an input folder like this:</p> <pre><code>/input\n\u251c\u2500 instance.json\n\u251c\u2500 info.json\n\u2514\u2500 battle_data/\n   \u251c\u2500 0/\n   \u2502  \u251c\u2500 score.txt\n   \u2502  \u251c\u2500 instance.json\n   \u2502  \u2514\u2500 solver_solution.json\n   \u2514\u2500 1/\n       \u251c\u2500 score.txt\n       \u251c\u2500 instance.json\n       \u2514\u2500 solver_solution.json\n</code></pre> <p>The <code>instance.json</code> file contains the actual instance that needs to be solved this round. The folders in <code>/input/battle_data</code> are named after the index of each previous fight and contain that fight's data.</p> <p>Missing files</p> <p>The instance and solution files may be missing in some or all of the fights. This happens if e.g. one of the programs crashes or outputs invalid data. In those cases the battle will continue with the corresponding files not existing in the input folder. Always check if the files are actually there and have a fallback ready!</p> <p>You can also configure this battle type to only include some of this information or reveal even more details about the previous fights to each team. This can lead to interesting challenges where e.g. every instance and generator's solution is fully revealed and the generating team thus needs to come up with very different instances every run.</p> <p>The overall score is calculated by averaging each round's score, but with later fights being weighted more. This means that cleverly using the given information about previous fights is more important than just having strong programs.</p>"},{"location":"advanced/battle_types/#config_2","title":"Config","text":"<code>instance_size</code> The instance size every fight in each match will be fought at. Defaults to 25. <code>num_fights</code> The number of fights that will be fought in each match. Defaults to 10. <code>weighting</code> How much additional weight each successive fight receives in the overall score. Needs to be a positive integer that expresses percentages. E.g. a <code>weighting</code> of <code>2</code> means the second fight is twice as impactful as the first, the third four times, etc. Note that series exhibits exponential growth and thus <code>weightings</code> close to <code>1</code> should be used to not make all but the last few fights matter. Defaults to <code>1.1</code>. <code>scores</code> A set of roles (a role is either <code>\"generator\"</code> or <code>\"solver\"</code>) that specifies which programs will see each previous rounds' scores. Defaults to <code>[\"generator\", \"solver\"]</code>. <code>instances</code> Similar to <code>scores</code> but regarding the problem instances. Defaults to <code>[\"generator\", \"solver\"]</code>. <code>generator_solutions</code> Similar to <code>scores</code> but regarding the generator's solutions (if the problem uses them). Defaults to <code>[\"generator\"]</code>. <code>solver_solutions</code> Similar to <code>scores</code> but regarding the solver's solutions. Defaults to <code>[\"solver\"]</code>."},{"location":"advanced/battle_types/#ui-data_2","title":"UI Data","text":"<p>Improving battles display a single value to the UI:</p> round The current round that is being fought."},{"location":"advanced/config/","title":"Settings","text":"<p>You can configure Algobattle in a lot of different ways, so that it does exactly what you want it to do.</p> <p>Unsure about TOML syntax?</p> <p>TOML syntax can be a bit confusing if you're unfamiliar with it, a full explanation of it can be found on the official site.</p>"},{"location":"advanced/config/#cli-config","title":"CLI config","text":"<p>To globally configure how Algobattle behaves you can use the cli config file. Open it by running</p> <pre><code>algobattle config\n</code></pre> <p>It's a TOML document that contains two tables:</p> <code>general</code> <p>This contains general cli config options. Its keys are:</p> <code>team_name</code> This is the team name used in the project config whenever you initialize a new project. It doesn't need to be the same name you use in the Algobattle website. The default is for Algobattle to dynamically generate a fun team name when you run the command. <code>install_mode</code> If a problem requires some dependencies Algobattle installs them during project initialization. If the mode is <code>user</code> it will do so in user space, if it is <code>normal</code> it will install it globally instead. We recommend you use <code>normal</code> if you're using an environment manager like Conda and <code>user</code> otherwise. In the default setting Algobattle will explicitly ask you to set this the first time it is needed. <code>generator_language</code> and <code>solver_language</code> This sets the default language to use in newly initialized projects. You can always override this by passing them explicitly when running the command. Defaults to <code>plain</code> for both. <code>default_project_table</code> This table contains default values you would like to use in the <code>project</code> table in project level config files. See the project config documentation for details on what you can specify here. Defaults to only containing a <code>results</code> key set to the <code>results</code> path."},{"location":"advanced/config/#project-config-files","title":"Project config files","text":"<p>These are the files normally called <code>algobattle.toml</code> that live in every Algobattle project folder. They can get quite big and offer a lot of room for customization. It's made up of several tables at keys <code>match</code>, <code>teams</code>, <code>problems</code>, <code>project</code>, and <code>docker</code>:</p> <p>Relative paths</p> <p>If any path in this config file is specified it will be interpreted as relative to the config file, not Algobattle's current working directory.</p>"},{"location":"advanced/config/#match","title":"<code>match</code>","text":"<p>This specifies how each match is run.</p> <p>Warning</p> Be careful not to accidentally change things in here and then develop your programs to work with those settings. The match run on the Algobattle server will use the settings you got from your course instructors, so your programs might break when making wrong assumptions about the match structure. <code>problem</code> The only mandatory key in this table. It must be the name of the problem that is to be used. Either the name of an installed problem, or one imported dynamically. If the latter option is used you need to specify the problem file's location in the <code>problems</code> table. <code>build_timeout</code> A timeout used for every program build. If a build does not complete within this limit it will be cancelled and the team whose program it is excluded from the match. Can either be specified as a number which is interpreted as seconds, a string in the <code>HH:MM:SS</code> format, or <code>false</code> to set no limit. Defaults to 10 minutes. <code>max_program_size</code> A limit on how big each program may be. Does not limit the memory it can use while running, but rather the disk space used by it after it has been built. Can either be an integer which is interpreted as bytes, or a string with a unit such as <code>500 MB</code> or <code>1.3gb</code>, or <code>false</code> to set no limit. Defaults to 4 GB. The Pydantic ByteSize docs contain a full explanation of possible formats. <code>strict_timeouts</code> Programs may run into their timeout after already having generated some output. This setting determines how these cases are handled, if it's set to <code>true</code> exceeding the time limit is considered a completely unsuccessful program execution and is treated similar to if it had crashed completely. If it is <code>false</code>, the program will just be stopped after the allotted time and any solution it may have generated is treated as is. Defaults to <code>false</code> <code>generator</code> and <code>solver</code> <p>Both of these fields accept the same type of table. They specify parameters guiding each generator and solver execution respectively.</p> <code>timeout</code> A limit on the program runtime. Exact behaviour of what happens when it is exceeded depends on the <code>strict_timeouts</code> setting. Can either be a number which is interpreted as seconds, a string in the <code>HH:MM:SS</code> format, or <code>false</code> to set no limit. Defaults to 20 seconds. <code>space</code> Limits the amount of memory space the program has available during execution. Can either be an integer which is interpreted as bytes, a string with a unit such as <code>500 MB</code> or <code>1.3gb</code>, or <code>false</code> to set no limit. Defaults to 4 GB. The Pydantic ByteSize docs contain a full explanation of possible formats. <code>cpus</code> Sets the number of physical CPUs the program can use. Can be any non-zero integer. Defaults to 1. <code>battle</code> <p>This is a table containing settings relevant to the battle type the match uses. Valid keys are documented at the battle type page. A single key is shared by all battle types:</p> <code>type</code> This key specifies which battle type to use. Must be the name of a currently installed battle type. Defaults to <code>\"Iterated\"</code>."},{"location":"advanced/config/#teams","title":"<code>teams</code>","text":"<p>This table tells Algobattle where it can find each team's programs. Keys are team names and values table with this structure with both keys being mandatory:</p> <code>generator</code> Path to the team's generator. <code>solver</code> Path to the team's solver."},{"location":"advanced/config/#problem","title":"<code>problem</code>","text":"<p>Contains data specifying how to dynamically import the problem.</p> <p>Note</p> <p>This table is usually filled in by the course administrators, if you're a student you probably won't have to worry about it.</p> <code>location</code> Path to the problem module. Defaults to <code>problem.py</code>. <code>dependencies</code> A list of PEP 508 conformant dependency specification strings. These will be installed during project initialization to make sure the problem can be run without issue. Defaults to an empty list."},{"location":"advanced/config/#project","title":"<code>project</code>","text":"<p>Contains various project settings.</p> <p>Feel free to customize this</p> Even though some affect how a match is run they will never change its result. Every student can change these to best fit their development workflow regardless of which ones might be used in the server matches. <code>points</code> An integer specifying the maximum number of points a team can achieve during this match. Defaults to 100. <code>parallel_battles</code> To speed up battle execution you can let Algobattle run multiple battles in parallel. Note that while programs can not directly interact with each other, they might still end up interfering with other programs that are being run at the same time by attempting to use the same CPU, memory, or disk resources as each other. You can use the <code>set_cpus</code> option to mitigate this problem. Defaults to 1. <code>set_cpus</code> <p>Many modern CPUs have different types of physical cores with different performance characteristics. To provide a level playing field it may be good to limit Algobattle to only use certain cores for programs. To do this, specify either a comma separated list of CPUs (the first is numbered 0) such as <code>0,1,3,5</code> or a range like <code>0-4</code>. Note that the formatting is very important here, you can not mix the two styles, add any spaces, or similar. A full format spec can be found on the Docker site.</p> <p>This option accepts either a single such string, or a list of them. If a list is provided each battle that is run in parallel will use one of the provided set of cores. For example, if this option is <code>[\"0,1\", \"2-3\", \"4,5\"]</code> and there are two battles executed at the same time, the first would use the first two physical CPUs and the second the next two. Defaults to no CPU limitation.</p> <code>name_images</code> Whether to give the Docker images descriptive names. This is very useful during development, but can lead to security risks in matches between competing teams. Because of this we recommend setting this to true <code>true</code> if you're a student running Algobattle on your own machine, and <code>false</code> in matches on the Algobattle server. Defaults to <code>true</code>. <code>cleanup_images</code> Whether to remove all Docker images after we're done using them. If set to <code>false</code> your system will be kept a bit tidier, but you will also have much longer build times since images can no longer be cached. Defaults to <code>false</code>. <code>results</code> Path to the folder where result files are saved. Each result file will be a json file with a name containing the command that created it and the current timestamp. Defaults to <code>results</code> <code>error_detail</code> Used to specify how detailed error messages included in the log files should be. Can be set to <code>high</code>, which includes full details and stack traces for any exceptions that occur, or <code>low</code> to hide sensitive data that may leak other team's strategic information. <code>log_program_io</code> <p>A table that specifies how each program's output should be logged.</p> <code>when</code> When to save the data. Can be either <code>never</code>, <code>error</code>, or <code>always</code>. When set to <code>never</code> or <code>always</code> it has the expected behaviour, when set to <code>error</code> it will save the data only if an error occurred during the fight. Defaults to <code>error</code>. <code>output</code> Where to store each program's output data. Currently only supports <code>disabled</code> to turn of logging program output or <code>inline</code> to store jsonable data in the match result json file. Defaults to <code>inline.</code>"},{"location":"advanced/config/#docker","title":"<code>docker</code>","text":"<p>Contains various advanced Docker settings that are passed through to the Docker daemon without influencing Algobattle itself. You generally should not need to use these settings. If you are running into a problem you cannot solve without them, we recommend first opening an issue on our GitHub to see if we can add this functionality to Algobattle directly.</p> <p>Danger</p> <p>Many of these settings are very complicated and have potentially disastrous consequences. We recommend not using any of these settings unless you are absolutely sure what the ones you are modifying do. Improper Docker Daemon configuration may not only break Algobattle but can give potential attackers root access to your host machine.</p> <code>build</code> Table containing parameters passed to the docker build command. Further documentation can be found on the Docker build site. <code>run</code> Table containing parameters passed to the docker run command. Further documentation can be found on the Docker run site."},{"location":"advanced/config/#algobattle-subcommands","title":"Algobattle subcommands","text":"<p>You can also directly configure many things as command line arguments. Which ones are available depends on the subcommand</p>"},{"location":"advanced/config/#run","title":"run","text":"<p>This command runs a match using the current project config file.</p> <code>path</code> A positional only argument that specifies where to find the project config file. May either point to a file directly, or to the parent directory of one named <code>algobattle.toml</code>. Defaults to the current working directory. <code>--ui</code> / <code>--no-ui</code> Keyword only option that controls whether the match UI is displayed during execution. Defaults to <code>True</code>. <code>--save</code> / <code>--no-save</code> Keyword only option that controls whether the match result is saved to disk after it's run. Defaults to <code>True</code>."},{"location":"advanced/config/#init","title":"init","text":"<p>This command initializes a project folder.</p> <code>target</code> Path to the folder to create the project data in. When initializing a new problem this defaults to a new subdirectory of the current working directory named after the problem. If you're instead using an existing project config file it defaults to the current directory. <code>--problem</code> / <code>-p</code> Specifies the problem to use for this project. Can either be missing to use an already existing project config, the name of an installed problem, or the path to a problem spec file. Defaults to using an already existing project config. <code>--generator</code> / <code>-g</code> <code>--solver</code> / <code>-s</code> <code>--language</code> / <code>-l</code> Specifies what language template to use for the generator, solver, or both. You cannot specify both <code>--language</code> and either one of the other two options. Can be one of the names of language templates supported by Algobattle. Uses the defaults set in the CLI config (which defaults to <code>plain</code>). Language list <p>The full list of languages template names is:</p> <ul> <li>python</li> <li>rust</li> <li>c</li> <li>cpp</li> <li>csharp</li> <li>javascript</li> <li>typescript</li> <li>java</li> <li>go</li> </ul> <code>--schemas</code> / <code>--no-schemas</code> Whether to also include the problem I/O json schemas in the <code>schemas</code> subdirectory. Defaults to <code>False</code>."},{"location":"advanced/config/#test","title":"test","text":"<p>This runs a basic test checking whether the programs in a project build and run correctly.</p> <code>project</code> Path to the Algobattle project to test. Can either point directly to a project config file, or to a folder containing one called <code>algobattle.toml</code>. Defaults to the current working directory. <code>--size</code> Will be passed to the generator as it's <code>max_size</code>. Defaults to the problem's minimum size."},{"location":"advanced/config/#config","title":"config","text":"<p>Opens the CLI config file. Accepts no arguments.1</p>"},{"location":"advanced/config/#package-problem","title":"package problem","text":"<p>Packages the problem in the project folder into a <code>.algo</code> file.</p> <code>project</code> Path to the Algobattle project containing the problem. Can either point directly to a project config file, or to a folder containing one called <code>algobattle.toml</code>. Defaults to the current working directory. <code>--description</code> Path to a file containing a human-readable description of the problem. Defaults to one called <code>description</code> (with any extension) in the project's directory. <code>--out</code> / <code>-o</code> Location where the packaged <code>.algo</code> file will be placed. Defaults to a file named after the problem in the project's directory."},{"location":"advanced/config/#package-programs","title":"package programs","text":"<p>Packages the programs of a particular team into <code>.prog</code> files. These files can be used to easily share programs, or upload them to the Algobattle website.</p> <p>Keep program sizes down</p> <p>Algobattle will package everything in the program directories into a zip file. This may include unnecessary build artefacts, logs, program output, etc. It's best to remove any superfluous files (in particular, anything in your <code>.gitignore</code>) from the directories before running this command.</p> <code>project</code> Path to the Algobattle project containing the programs. Can either point directly to a project config file, or to a folder containing one called <code>algobattle.toml</code>. Defaults to the current working directory. <code>--team</code> Name of the team whose programs should be packaged. If there is only one team in this project, it will be selected by default. <code>--generator</code> and <code>--solver</code> Whether to package this particular program. Defaults to <code>True</code>. <code>--test</code> / <code>--no-test</code> Whether to test the programs before packaging them to make sure that they are building and running correctly. Defaults to <code>True</code>."},{"location":"advanced/docker/","title":"Docker","text":"<p>Algobattle uses Docker to run the programs students write. This lets us support students using any language, easily restrict their time, space, and CPU usage, provide a safe environment, and much more.</p>"},{"location":"advanced/docker/#basic-functionality","title":"Basic functionality","text":"<p>If you haven't used Docker before, getting your head around what it's doing and what you need to do can be a bit confusing. Luckily we do not need to understand most of its behind the scenes working and, the parts that we do need are pretty straightforward. You can think of Docker as a virtual machine management tool, it lets you create images that basically are save files of an entire computer including the OS and everything else installed on it. We can then run these as containers, independent virtual machines that start off from that save file and then run some code.</p> <p>Algobattle uses such images and containers to manage the students' programs. What we actually care about when receiving e.g. the path to a generator is not all the source files and whatever else might be in that folder, but the Docker image that can be built using it.</p> <p>Since containers run essentially as virtual machines, they are entirely separate from the host machines' OS. In particular, they do not share a file system. This is why the programs do not see the host machines actual files and have to read/write from the <code>/input</code> and <code>/output</code> directories. Algobattle creates the containers with special links between the host machine's file system and these folders and then looks only at these directories.</p>"},{"location":"advanced/docker/#dockerfiles","title":"Dockerfiles","text":"<p>Dockerfiles are what Docker uses to create images. When Algobattle is told that there's a generator in <code>generator/</code>, it will ask Docker to build the Dockerfile in that folder. Docker then takes the file found at <code>generator/Dockerfile</code> and interprets every line in it as a particular step in the build process. These steps are completed in order of their occurrence in the Dockerfile. Once Docker has completed every step, the build is complete, and we get the finalized image. This image will essentially look exactly like the virtual machine did after the last build step ran, plus some special Docker metadata.</p> <p>The full specification of what Dockerfiles can contain is here, but most of it is not super relevant for us. The most important commands are listed here:</p>"},{"location":"advanced/docker/#the-from-statement","title":"The <code>FROM</code> statement","text":"<p>The first line of every Dockerfile has to be a <code>FROM</code> statement, the most basic example is <code>FROM scratch</code>. This line tells Docker what to base your image off of, <code>FROM scratch</code> means that it starts with a completely empty file system. If we do that we need to first install an operating system, configure it enough to be usable, and then install whatever we actually want to run. We can make our Dockerfiles much simpler by using one of the already existing images in the Docker Hub in our <code>FROM</code> statement instead. Instead of starting with an empty file system we then start with the file system of that image.</p> <p>All major operating systems have images containing a fresh installation of them on the Docker Hub. For example, here is the official Alpine image, here is Ubuntu, and here is Debian. If you want your code to run in a clean environment with nothing else you can use any of these as your base.</p> <p>Warning</p> <p>In principle Docker can also run Windows OS's inside the containers, but this requires special setup on the host machine. In particular, every image needs to then be a Windows image, there is no way to control both Linux and Windows containers at the same time. We recommend course administrators configure Docker to run Linux containers (this is the default) and inform students that they are required to use Linux in their images.</p> <p>Talk to your course administrators if you are a student and unsure about what OS to use.</p> <p>Since you want the container to execute some code you will most likely then need to install a compiler or runtime for whatever language you're using. We can easily skip this intermediary step and instead base our image off of one that already includes this. Most languages have officially published images that contain some Linux distro and an installation of everything that compiler/interpreter needs to work. For example, here is Python's and here Rust's.</p> <p>Images on the Docker Hub can also be versioned using tags. For example, the official Python image has dozens of slightly different versions that come with different OS's, Python versions, etc. If you want to use a specific tag you need to list it in the <code>FROM</code> statement after a colon. For example, if your code needs Python 3.10 you can write <code>FROM python:3.10</code>.</p> <p>Tip</p> <p>Different languages use different schemes for tagging their images. Always check the official page on the Docker Hub to make sure you're getting the right version of everything.</p>"},{"location":"advanced/docker/#changing-the-workdir","title":"Changing the <code>WORKDIR</code>","text":"<p>As the name suggests, <code>WORKDIR /some/dir</code> changes the current working directory. All subsequent commands will be executed from <code>/some/dir</code>. Note that the path must be absolute. This also can also affect where the program that runs when you start a container from the image if you change the working directory before the <code>CMD</code> or <code>ENTRYPOINT</code> line.</p>"},{"location":"advanced/docker/#copying-files","title":"<code>COPY</code>ing files","text":"<p>Now that we have a container that includes our language's runtime we also need to include our code and all other files we may need. The <code>COPY</code> command does exactly this. For it, we just list the path to the file on the host file system, and the path it should be at in the image. Our example has the generator code in a single file next to the Dockerfile, so we can place it into the root directory of the image with <code>COPY main.py /</code>. Paths can be absolute or relative, and you can specify multiple sources in a single line. You can also use a glob-like syntax to match multiple specific files.</p> Example <p>All of these are valid <code>COPY</code> statements:</p> <ul> <li><code>COPY some_file.py .</code> results in <code>some_file.py</code> being placed in the current directory</li> <li><code>COPY some_dir target_dir/</code> results in every file in <code>some_dir</code> and all its subfolders being placed     in <code>target_dir/</code>, effectively copying over the entire tree rooted at <code>some_dir</code> and rooting it at <code>target_dir</code></li> <li><code>COPY nested/location/source.txt .</code> copied the source file into the current directory</li> <li><code>COPY multiple.py source.json files.txt single/target/dir/</code> copies both source files to the target     directory</li> <li><code>COPY source.rs /absolute/target</code> copies the file into the target directory</li> <li><code>COPY *.py /</code> copies all Python files in the current directory into the root of the image</li> </ul> <p>The build context</p> <p>You cannot <code>COPY</code> files outside the directory containing the Dockerfile. That is <code>COPY ../../something ./</code> will not work. This is not a limitation of Algobattle but just a side effect of how Docker works.</p> <p>trailing slashes</p> <p>Notice how we sometimes specify trailing slashes even though they're not strictly needed. This is to make sure that Docker knows we are referring to a directory, not a file. If you just write <code>COPY something other</code> and <code>something</code> is a file it will place it into the current directory and rename it <code>other</code>. If you want it to instead keep the name and place it in the <code>other/</code> directory, you need to include the trailing slash.</p>"},{"location":"advanced/docker/#running-commands","title":"<code>RUN</code>ning commands","text":"<p>You can use <code>RUN some shell command</code> to execute <code>some shell command</code> in a shell during the image build step. This command will have access to everything that was copied into the image beforehand and anything that previously ran commands created. Most often, this is used to install dependencies of your program.</p> <p>This statement has two forms, the first <code>RUN some shell command</code>, and the other <code>RUN [\"some\", \"shell\", \"command\"]</code>. For our purposes they do largely the same thing, but their differences are explained here</p>"},{"location":"advanced/docker/#specifying-the-program-cmd","title":"Specifying the program <code>CMD</code>","text":"<p>Lastly, the container that runs from your image needs to know what it should actually do. You can specify this with the <code>CMD</code> statement. Its arguments form some shell command that is not executed during the build step, but when the container starts.</p> <p>Similar to run this command also has the same two forms, and you can choose whichever you prefer, though the list style syntax is usually preferred. They are explained in detail here.</p>"},{"location":"advanced/docker/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"advanced/docker/#faster-builds-with-better-caching","title":"Faster builds with better caching","text":"<p>Building docker images can take quite a long time depending on what is happening in the build. When you're developing your programs and keep making small changes to your code before rebuilding this can be incredibly annoying. Luckily Docker implements a cache of so-called layers for us. You can think of layers as basically being break points in between every line in your Dockerfile. Let's look at an example:</p> <pre><code>FROM python:3.11\n\nWORKDIR /algobattle\nCOPY . ./\nRUN pip install .\n\nWORKDIR /\nCMD [ \"python\", \"-m\", \"generator\" ]\n</code></pre> <p>The first layer is just the original Python base image, the next is the base image plus the change of the working directory, then the base image plus the changed working directory, plus the copied files, etc. If you now build this Dockerfile Docker will automatically cache every layer separately. Subsequent builds will then use these cached layers up until the point where things have changed and thus need to be built again.</p> <p>The important part here is being aware of what causes Docker to invalidate caches, and make sure that it happens as late in the Dockerfile as possible. <code>COPY</code> commands invalidate caches whenever the files you're copying over have changed. This means that every time you make a code change to the above code you invalidate the cache used for the <code>COPY</code> and all subsequent commands, which means that pip has to reinstall every dependency every time you rebuild the image. To better cache your dependencies you can install them before you copy over your code:</p> <pre><code>FROM python:3.11\n\nWORKDIR /algobattle\nCOPY pyproject.toml ./\nRUN pip install .\nCOPY . ./\nRUN pip install .\n\nWORKDIR /\nCMD [ \"python\", \"-m\", \"generator\" ]\n</code></pre> <p>This might look slower at first glance since it's doing a lot more, and it will be slightly slower during the first build, but if you're using dependencies that take a bit to install this will be much faster in the long run. Obviously, the same ideas apply to other languages. To make the best use of the cache, you want your <code>COPY</code> commands to be as selective as possible and be executed as late as possible.</p> <p><code>RUN</code> and caching</p> <p>The <code>RUN</code> command never invalidates the cache! Even if you are running some command that e.g. pulls from the web and the content of that download changes, Docker will not rerun it unless something before it created a cache miss. This is great most of the time since we're downloading deterministic data like dependencies, but can cause issues if you expect to dynamically update data.</p>"},{"location":"advanced/docker/#building-images-yourself","title":"Building images yourself","text":"<p>Sometimes it's nice to build images yourself to debug them. You can find the full documentation on the Docker build page, but the basics aren't as complicated as they make it out to be! In its purest form you just run</p> <pre><code>docker build path/to/build/dir\n</code></pre> <p>With a path pointing to the directory containing the Dockerfile you want to build. This will then build the image and display a detailed log including any error messages in the console. If you want to then refer back to the image you'll have to use its ID, which can become quite annoying, so you probably want to tag the image when you build it:</p> <pre><code>docker build -t some_name path/to/build/dir\n</code></pre>"},{"location":"advanced/docker/#running-containers-yourself","title":"Running containers yourself","text":"<p>You will probably also want to run containers yourself. This command is very powerful and even more complicated, if you're feeling brave you can check out the docs on the Docker run page. The most common style of command you will need is</p> <pre><code>docker run -ti some_name\n</code></pre> <p>This runs the container and then mirrors its stdin, stdout, and stderr to your console, effectively behaving as though you've opened a terminal inside the running container. <code>some_name</code> needs to be the same name you gave the image when you built it.</p> <p>Algobattle image names</p> <p>If you're using the <code>name_images</code> Algobattle setting (defaults to <code>true</code>) the images Algobattle creates will be named like <code>algobattle_{team_name}_{program_type}</code>, so e.g. <code>algobattle_crows_generator</code> or <code>algobattle_red_pandas_solver</code>. You can run these directly without having to build them yourself.</p> <p>Since the program expects the usual Algobattle input in the <code>/input</code> directory, which will be missing if you run it yourself, the container will most likely just crash. What's more useful is to tell Docker to use some other command when running the container. Like this:</p> <pre><code>docker run -ti some_name bash\n</code></pre> <p>This will run <code>some_name</code> but without executing the <code>CMD</code> command and running <code>bash</code> instead. So we effectively just open a terminal inside the container and can then inspect the container, build artefacts, etc to debug things.</p>"},{"location":"advanced/problems/","title":"Problems","text":"<p>If you're currently a student in an Algobattle lab course, you've probably wondered how exactly the problems work, found weird behaviour that you think might be a bug, or wanted to find out the exact file format it will accept. This page teaches you how to get all that info from just the files you've already got in your Algobattle project folder!</p> <p>Note</p> <p>This page goes over the anatomy of an Algobattle problem and how you can get what you're looking for from your project folder. This means it's mainly aimed at students who are trying to get more familiar with the course or a particular problem they're dealing with and course instructors who want to get an overview over how they work. If you instead are a course instructor looking to make a problem from scratch the instructor tutorial has more detailed info on that process.</p>"},{"location":"advanced/problems/#overall-structure","title":"Overall Structure","text":"<p>A typical problem file looks something like this</p> problem.py<pre><code>\"\"\"The Scheduling problem class.\"\"\"\nfrom typing import Annotated\n\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, minimize\nfrom algobattle.types import Interval, SizeLen\nfrom algobattle.util import Role\n\n\nTimespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Instance(InstanceModel):\n    \"\"\"The Scheduling problem class.\"\"\"\n\n    job_lengths: list[Timespan]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.job_lengths)\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"A solution to a Job Shop Scheduling problem.\"\"\"\n\n    assignments: Annotated[list[Machine], SizeLen]\n\n    @minimize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        finish_time = [0] * 5\n        for duration, machine in zip(instance.job_lengths, self.assignments):\n            finish_time[machine - 1] += duration * machine\n        return max(finish_time)\n\n\nScheduling = Problem(\n    name=\"Job Shop Scheduling\",\n    min_size=5,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <p>What exactly the problems we discuss here are about is not important for this guide. If you're still curious you can find them all in our Algobattle problems repo with additional explanations. We will now go through this file and explain what each section does.</p>"},{"location":"advanced/problems/#the-instance-class","title":"The Instance Class","text":"<p>This class defines what each instance of the problem will look like. It both tells you what your generator needs to create and what input your solver will receive. At the top of the class you will find a block of attribute definitions. In our case this is only a single line.</p> <pre><code>Timespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Instance(InstanceModel):\n    \"\"\"The Scheduling problem class.\"\"\"\n\n    job_lengths: list[Timespan]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.job_lengths)\n</code></pre> <p>This tells us that each instance's json file contains a single key, <code>job_lengths</code>, which maps to a list of Timespans. As we can see from the type alias above the class definition, a Timespan just is an integer between 0 and (2<sup>64</sup> - 1) / 5. What that means is that if you're programming your generator you must ensure to not output any numbers that do not fall in this range, and when implementing your solver you can safely assume that all inputs you will receive are in it.</p>"},{"location":"advanced/problems/#instance-size","title":"Instance Size","text":"<p>The instance size is defined by the <code>size</code> property.</p> <pre><code>Timespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Instance(InstanceModel):\n    \"\"\"The Scheduling problem class.\"\"\"\n\n    job_lengths: list[Timespan]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.job_lengths)\n</code></pre> <p>Note</p> <p>You should not include a <code>size</code> key in your instances. It will be computed from other attributes of the instance.</p>"},{"location":"advanced/problems/#additional-validation","title":"Additional Validation","text":"<p>Some problem instances, like this one for the Hikers problem, also include a <code>validate_instance</code> method.</p> <pre><code>class HikersInstance(InstanceModel):\n    \"\"\"The Hikers instance class.\"\"\"\n\n    hikers: list[tuple[u64, u64]]\n\n    @property\n    def size(self) -&gt; int:\n        \"\"\"The instance size is the number of hikers.\"\"\"\n        return len(self.hikers)\n\n    def validate_instance(self) -&gt; None:\n        super().validate_instance()\n        if any(min_size &gt; max_size for min_size, max_size in self.hikers):\n            raise ValidationError(\"One hiker's minimum group size is larger than their maximum group size.\")\n</code></pre> <p>This method contains further code that validates which inputs are allowable and which aren't. If you generate an instance that causes this method to raise an error, your instance will be considered invalid, and you will lose the fight.</p>"},{"location":"advanced/problems/#the-solution-class","title":"The Solution Class","text":"<p>This class is very similar to the instance class, except it specifies what solutions look like. In our case we again have a single attribute and thus the solutions contain only a single key.</p> <pre><code>Timespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"A solution to a Job Shop Scheduling problem.\"\"\"\n\n    assignments: Annotated[list[Machine], SizeLen]\n\n    @minimize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        finish_time = [0] * 5\n        for duration, machine in zip(instance.job_lengths, self.assignments):\n            finish_time[machine - 1] += duration * machine\n        return max(finish_time)\n</code></pre> <p>This time we not only use an alias to specify the allowable range of integer values, but also the <code>SizeLen</code> marker which means that the number of <code>assignments</code> must be exactly the same as the instance's size.</p>"},{"location":"advanced/problems/#solution-score","title":"Solution Score","text":"<p>Most solutions also have a <code>score</code> method. This tells Algobattle what the goal of this problem is and how to weigh different solutions.</p> <pre><code>Timespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"A solution to a Job Shop Scheduling problem.\"\"\"\n\n    assignments: Annotated[list[Machine], SizeLen]\n\n    @minimize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        finish_time = [0] * 5\n        for duration, machine in zip(instance.job_lengths, self.assignments):\n            finish_time[machine - 1] += duration * machine\n        return max(finish_time)\n</code></pre> <p>The decorator at the top can either be <code>maximize</code> or <code>minimize</code> and tells us if bigger or smaller score values are considered to be better. The function then computes some non-negative real number based on the instance and solution, this will be this solutions' score. Each fight in a battle will receive a single score, that will be calculated by comparing the solution score of the generator's and solver's solutions.</p> <p>In our example the score just is the longest time a machine takes to complete all jobs. If in the generator's solution all machines complete their jobs in 10 units, but the solver's solution takes 12, the fight's score will be approximately 0.83.</p>"},{"location":"advanced/problems/#additional-validation_1","title":"Additional Validation","text":"<p>Just like instances can undergo extra validation, so can solutions. They use the <code>validate_solution</code> method for this.</p> <pre><code>class Solution(SolutionModel[HikersInstance]):\n    \"\"\"A solution to a Hikers problem.\"\"\"\n\n    assignments: dict[Hiker, u64]\n\n    def validate_solution(self, instance: HikersInstance, role: Role) -&gt; None:\n        super().validate_solution(instance, role)\n        group_sizes = Counter(self.assignments.values())\n\n        for hiker, group in self.assignments.items():\n            min_size, max_size = instance.hikers[hiker]\n            if not (min_size &lt;= group_sizes[group] &lt;= max_size):\n                raise ValidationError(\"A Hiker is not happy with their assignment!\")\n\n    @maximize\n    def score(self, instance: HikersInstance, role: Role) -&gt; float:\n        return len(self.assignments)\n</code></pre>"},{"location":"advanced/problems/#the-problem-constructor","title":"The Problem Constructor","text":"<p>The last part of the problem file actually creates the problem.</p> <pre><code>\"\"\"The Scheduling problem class.\"\"\"\nfrom typing import Annotated\n\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, minimize\nfrom algobattle.types import Interval, SizeLen\nfrom algobattle.util import Role\n\n\nTimespan = Annotated[int, Interval(ge=0, le=(2**64 - 1) / 5)]\nMachine = Annotated[int, Interval(ge=1, le=5)]\n\n\nclass Instance(InstanceModel):\n    \"\"\"The Scheduling problem class.\"\"\"\n\n    job_lengths: list[Timespan]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.job_lengths)\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"A solution to a Job Shop Scheduling problem.\"\"\"\n\n    assignments: Annotated[list[Machine], SizeLen]\n\n    @minimize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        finish_time = [0] * 5\n        for duration, machine in zip(instance.job_lengths, self.assignments):\n            finish_time[machine - 1] += duration * machine\n        return max(finish_time)\n\n\nScheduling = Problem(\n    name=\"Job Shop Scheduling\",\n    min_size=5,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <p>It contains the name of the problem and references to the two classes we discussed. It also specifies what the smallest reasonable size of this problem is. In our case an instance should contain at least one job for each machine, so the minimum size of this problem is 5.</p>"},{"location":"api/","title":"API reference","text":"<p>This section contains documentation of the algobattle API. Note that it mostly only describes details about what each class or function does and how you should interact with it. To get a higher level overview of how to use the API and what the purpose of each part is, read the corresponding parts of the user guide.</p>"},{"location":"api/battle/","title":"Battle","text":"<p>This module defines the <code>Battle</code> class and thus what each battle type can do to customize how it runs and scores the programs. If you are implementing your own custom battle types, make sure they adhere to the api specifications laid out here.</p>"},{"location":"api/battle/#algobattle.battle.Battle","title":"<code>algobattle.battle.Battle</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Base for classes that execute a specific kind of battle.</p> <p>Each battle type determines what parameters each fight will be fought with, how many fights are fought, and how they will ultimately be scored.</p> Source code in <code>algobattle/battle.py</code> <pre><code>class Battle(BaseModel):\n    \"\"\"Base for classes that execute a specific kind of battle.\n\n    Each battle type determines what parameters each fight will be fought with, how many fights are fought, and how\n    they will ultimately be scored.\n    \"\"\"\n\n    fights: list[Fight] = Field(default_factory=list)\n    \"\"\"The list of fights that have been fought in this battle.\"\"\"\n    runtime_error: ExceptionInfo | None = None\n    \"\"\"The description of an otherwise unhandeled exception that occured during the execution of :meth:`Battle.run`.\"\"\"\n\n    _battle_types: ClassVar[dict[str, type[Self]]] = {}\n    \"\"\"Dictionary mapping the names of all registered battle types to their python classes.\"\"\"\n\n    class Config(BaseModel):\n        \"\"\"Config object for each specific battle type.\n\n        A custom battle type can override this class to specify config options it uses. They will be parsed from a\n        dictionary located at `battle` in the main config file. The created object will then be passed to the\n        :meth:`Battle.run` method with its fields set accordingly.\n        \"\"\"\n\n        type: Any\n        \"\"\"Type of battle that will be used.\"\"\"\n\n        @classmethod\n        def __get_pydantic_core_schema__(cls, source: Type, handler: GetCoreSchemaHandler) -&gt; CoreSchema:\n            # there's two bugs we need to catch:\n            # 1. this function is called during the pydantic BaseModel metaclass's __new__, so the BattleConfig class\n            # won't be ready at that point and be missing in the namespace\n            # 2. pydantic uses the core schema to build child classes core schema. for them we want to behave like a\n            # normal model, only our own schema gets modified\n            try:\n                if cls != Battle.Config:\n                    return handler(source)\n            except NameError:\n                return handler(source)\n\n            match len(Battle._battle_types):\n                case 0:\n                    subclass_schema = handler(source)\n                case 1:\n                    subclass_schema = handler(next(iter(Battle._battle_types.values())))\n                case _:\n                    subclass_schema = tagged_union_schema(\n                        choices={\n                            battle.Config.model_fields[\"type\"].default: battle.Config.__pydantic_core_schema__\n                            for battle in Battle._battle_types.values()\n                        },\n                        discriminator=\"type\",\n                    )\n\n            # we want to validate into the actual battle type's config, so we need to treat them as a tagged union\n            # but if we're initializing a project the type might not be installed yet, so we want to also parse\n            # into an unspecified dummy object. This wrap validator will efficiently and transparently act as a tagged\n            # union when ignore_uninstalled is not set. If it is set it catches only the error of a missing tag, other\n            # errors are passed through\n            def check_installed(val: object, handler: ValidatorFunctionWrapHandler, info: ValidationInfo) -&gt; object:\n                try:\n                    return handler(val)\n                except ValidationError as e:\n                    union_err = next(filter(lambda err: err[\"type\"] == \"union_tag_invalid\", e.errors()), None)\n                    if union_err is None:\n                        raise\n                    if info.context is not None and info.context.get(\"ignore_uninstalled\", False):\n                        if info.config is not None:\n                            settings: dict[str, Any] = {\n                                \"strict\": info.config.get(\"strict\", None),\n                                \"from_attributes\": info.config.get(\"from_attributes\"),\n                            }\n                        else:\n                            settings = {}\n                        return Battle.FallbackConfig.model_validate(val, context=info.context, **settings)\n                    else:\n                        passed = union_err[\"input\"][\"type\"]\n                        installed = \", \".join(b.name() for b in Battle._battle_types.values())\n                        raise ValueError(\n                            f\"The specified battle type '{passed}' is not installed. Installed types are: {installed}\"\n                        )\n\n            return with_info_wrap_validator_function(check_installed, subclass_schema)\n\n    class FallbackConfig(Config):\n        \"\"\"Fallback config object to parse into if the proper battle typ isn't installed and we're ignoring installs.\"\"\"\n\n        type: str\n\n        model_config = ConfigDict(extra=\"allow\")\n\n        if TYPE_CHECKING:\n            # to hint that we're gonna fill this with arbitrary data belonging to some supposed battle type\n            def __getattr__(self, __attr: str) -&gt; Any:\n                ...\n\n    class UiData(BaseModel):\n        \"\"\"Object containing custom diplay data.\n\n        The display data object will be displayed as key-value pairs generated from the :meth:`.field` method.\n        You can use the normally available pydantic config options to customize what these will look like.\n        \"\"\"\n\n    @staticmethod\n    def all() -&gt; dict[str, type[\"Battle\"]]:\n        \"\"\"Returns a dictionary mapping the names of all registered battle types to their python classes.\n\n        It includes all subclasses of :class:`Battle` that have been initialized so far, including ones exposed to the\n        algobattle module via the `algobattle.battle` entrypoint hook.\n        \"\"\"\n        return Battle._battle_types\n\n    @classmethod\n    def load_entrypoints(cls) -&gt; None:\n        \"\"\"Loads all battle types presented via entrypoints.\"\"\"\n        for entrypoint in entry_points(group=\"algobattle.battle\"):\n            battle = entrypoint.load()\n            if not (isclass(battle) and issubclass(battle, Battle)):\n                raise ValueError(f\"Entrypoint {entrypoint.name} targets something other than a Battle type\")\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **kwargs: Any) -&gt; None:\n        if cls.name() not in Battle._battle_types:\n            Battle._battle_types[cls.name()] = cls\n            Battle.Config.model_rebuild(force=True)\n        return super().__pydantic_init_subclass__(**kwargs)\n\n    @abstractmethod\n    def score(self, config: _BattleConfig) -&gt; float:\n        \"\"\"Calculates the score the solver has achieved during this battle.\n\n        Should always be a nonnegative float, with higher values indicating a better performance of the solver.\n        \"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def format_score(score: float) -&gt; str:\n        \"\"\"Formats a given score nicely.\n\n        Purely auxialiary method that can be used to customize how a score will be rendered.\n        \"\"\"\n        return f\"{score:.2f}\"\n\n    @classmethod\n    def name(cls) -&gt; str:\n        \"\"\"Name of this battle type.\n\n        Defaults to the battle class's name. Can be used to customize this behaviour if e.g. a battle type should have a\n        name that is not a valid python identifier.\n        \"\"\"\n        return cls.__name__\n\n    @abstractmethod\n    async def run_battle(self, fight: FightHandler, config: _BattleConfig, min_size: int, ui: BattleUi) -&gt; None:\n        \"\"\"Executes one battle.\n\n        Args:\n            fight: The :class:`FightHandler` used to run each fight of this battle. It already contains information\n                about the participating teams, default config settings, etc. Each fight can be executed using the\n                :meth:`FightHandler.run` method.\n            config: An instance of this battle type's :class:`BattleConfig` class, parsed from the corresponding section\n                of the config file.\n            min_size: The minimum size valid for this problem.\n            ui: An interface to interact with the ui.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Battle.UiData","title":"<code>UiData</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Object containing custom diplay data.</p> <p>The display data object will be displayed as key-value pairs generated from the :meth:<code>.field</code> method. You can use the normally available pydantic config options to customize what these will look like.</p> Source code in <code>algobattle/battle.py</code> <pre><code>class UiData(BaseModel):\n    \"\"\"Object containing custom diplay data.\n\n    The display data object will be displayed as key-value pairs generated from the :meth:`.field` method.\n    You can use the normally available pydantic config options to customize what these will look like.\n    \"\"\"\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Battle.score","title":"<code>score(config)</code>  <code>abstractmethod</code>","text":"<p>Calculates the score the solver has achieved during this battle.</p> <p>Should always be a nonnegative float, with higher values indicating a better performance of the solver.</p> Source code in <code>algobattle/battle.py</code> <pre><code>@abstractmethod\ndef score(self, config: _BattleConfig) -&gt; float:\n    \"\"\"Calculates the score the solver has achieved during this battle.\n\n    Should always be a nonnegative float, with higher values indicating a better performance of the solver.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Battle.format_score","title":"<code>format_score(score)</code>  <code>staticmethod</code>","text":"<p>Formats a given score nicely.</p> <p>Purely auxialiary method that can be used to customize how a score will be rendered.</p> Source code in <code>algobattle/battle.py</code> <pre><code>@staticmethod\ndef format_score(score: float) -&gt; str:\n    \"\"\"Formats a given score nicely.\n\n    Purely auxialiary method that can be used to customize how a score will be rendered.\n    \"\"\"\n    return f\"{score:.2f}\"\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Battle.name","title":"<code>name()</code>  <code>classmethod</code>","text":"<p>Name of this battle type.</p> <p>Defaults to the battle class's name. Can be used to customize this behaviour if e.g. a battle type should have a name that is not a valid python identifier.</p> Source code in <code>algobattle/battle.py</code> <pre><code>@classmethod\ndef name(cls) -&gt; str:\n    \"\"\"Name of this battle type.\n\n    Defaults to the battle class's name. Can be used to customize this behaviour if e.g. a battle type should have a\n    name that is not a valid python identifier.\n    \"\"\"\n    return cls.__name__\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Battle.run_battle","title":"<code>run_battle(fight, config, min_size, ui)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Executes one battle.</p> <p>Parameters:</p> Name Type Description Default <code>fight</code> <code>FightHandler</code> <p>The :class:<code>FightHandler</code> used to run each fight of this battle. It already contains information about the participating teams, default config settings, etc. Each fight can be executed using the :meth:<code>FightHandler.run</code> method.</p> required <code>config</code> <code>_BattleConfig</code> <p>An instance of this battle type's :class:<code>BattleConfig</code> class, parsed from the corresponding section of the config file.</p> required <code>min_size</code> <code>int</code> <p>The minimum size valid for this problem.</p> required <code>ui</code> <code>BattleUi</code> <p>An interface to interact with the ui.</p> required Source code in <code>algobattle/battle.py</code> <pre><code>@abstractmethod\nasync def run_battle(self, fight: FightHandler, config: _BattleConfig, min_size: int, ui: BattleUi) -&gt; None:\n    \"\"\"Executes one battle.\n\n    Args:\n        fight: The :class:`FightHandler` used to run each fight of this battle. It already contains information\n            about the participating teams, default config settings, etc. Each fight can be executed using the\n            :meth:`FightHandler.run` method.\n        config: An instance of this battle type's :class:`BattleConfig` class, parsed from the corresponding section\n            of the config file.\n        min_size: The minimum size valid for this problem.\n        ui: An interface to interact with the ui.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/battle/#algobattle.battle.FightHandler","title":"<code>algobattle.battle.FightHandler</code>  <code>dataclass</code>","text":"<p>Helper class to run fights of a given battle.</p> Source code in <code>algobattle/battle.py</code> <pre><code>@dataclass\nclass FightHandler:\n    \"\"\"Helper class to run fights of a given battle.\"\"\"\n\n    problem: Problem\n    generator: Generator\n    solver: Solver\n    battle: \"Battle\"\n    ui: FightUi\n    set_cpus: str | None\n    log_config: ProgramLogConfigView\n\n    @overload\n    async def run(\n        self,\n        max_size: int,\n        *,\n        with_results: Literal[False] = False,\n        **kwargs: Unpack[RunKwargs],\n    ) -&gt; Fight:\n        ...\n\n    @overload\n    async def run(\n        self,\n        max_size: int,\n        *,\n        with_results: Literal[True],\n        **kwargs: Unpack[RunKwargs],\n    ) -&gt; tuple[Fight, GeneratorResult, SolverResult | None]:\n        ...\n\n    async def run(\n        self,\n        max_size: int,\n        *,\n        with_results: bool = False,\n        **kwargs: Unpack[RunKwargs],\n    ) -&gt; Fight | tuple[Fight, GeneratorResult, SolverResult | None]:\n        \"\"\"Execute a single fight of a battle.\n\n        First the generator will be run and its output parsed. Then the solver will be given the created instance\n        and run. Its output gets parsed into a solution, which will then be scored.\n        The timeout, space, and cpu arguments each override the corresponding match config options if set. Leaving them\n        unset results in the config options being used.\n\n        Args:\n            max_size: The maximum instance size the generator is allowed to create.\n            timeout_generator: Timeout in seconds for the generator to finish running. `None` means it is given an\n                unlimited amount of time.\n            space_generator: Memory space in MB the generator has access to. `None` means it is given an unlimited\n                amount of space.\n            cpus_generator: Number of physical cpu cores the generator can use.\n            timeout_solver: Timeout in seconds for the solver to finish running. `None` means it is given an unlimited\n                amount of time.\n            space_solver: Memory space in MB the solver has access to. `None` means it is given\n                an unlimited amount of space.\n            cpus_solver: Number of physical cpu cores the solver can use.\n            generator_battle_input: Additional data the generator will be provided with.\n            solver_battle_input: Additional data the solver will be provided with.\n            generator_battle_output: Class used to parse additional data the generator outputs into a python object.\n            solver_battle_output: Class used to parse additional data the solver outputs into a python object.\n            with_results: Whether to return the raw result objects.\n\n        Returns:\n            The resulting info about the executed fight, and the results if the flag has been set.\n        \"\"\"\n        gen_result, sol_result = await self.run_raw(max_size=max_size, **kwargs)\n        if gen_result.instance is None or gen_result.solution is None:\n            score = 1\n        elif sol_result is None or sol_result.solution is None:\n            score = 0\n        else:\n            score = self.calculate_score(gen_result, sol_result)\n        fight = Fight.from_results(\n            score=score,\n            max_size=max_size,\n            generator=gen_result,\n            solver=sol_result,\n            config=self.log_config,\n        )\n        self.battle.fights.append(fight)\n        self.ui.end_fight()\n        if with_results:\n            return fight, gen_result, sol_result\n        else:\n            return fight\n\n    async def run_raw(\n        self,\n        max_size: int,\n        *,\n        timeout_generator: float | None | EllipsisType = ...,\n        space_generator: int | None | EllipsisType = ...,\n        cpus_generator: int | EllipsisType = ...,\n        timeout_solver: float | None | EllipsisType = ...,\n        space_solver: int | None | EllipsisType = ...,\n        cpus_solver: int | EllipsisType = ...,\n        generator_battle_input: Encodable | None = None,\n        solver_battle_input: Encodable | None = None,\n        generator_battle_output: type[Encodable] | None = None,\n        solver_battle_output: type[Encodable] | None = None,\n    ) -&gt; tuple[GeneratorResult, SolverResult | None]:\n        \"\"\"Runs a fight and returns the unprocessed results.\"\"\"\n        min_size = self.problem.min_size\n        if max_size &lt; min_size:\n            raise ValueError(\n                f\"Cannot run battle at size {max_size} since it is smaller than the smallest \"\n                f\"size the problem allows ({min_size}).\"\n            )\n        ui = self.ui\n        ui.start_fight(max_size)\n        gen_result = await self.generator.run(\n            max_size=max_size,\n            timeout=timeout_generator,\n            space=space_generator,\n            cpus=cpus_generator,\n            battle_input=generator_battle_input,\n            battle_output=generator_battle_output,\n            set_cpus=self.set_cpus,\n            ui=ui,\n        )\n        if gen_result.error is not None:\n            return gen_result, None\n        assert gen_result.instance is not None\n\n        sol_result = await self.solver.run(\n            gen_result.instance,\n            max_size=max_size,\n            timeout=timeout_solver,\n            space=space_solver,\n            cpus=cpus_solver,\n            battle_input=solver_battle_input,\n            battle_output=solver_battle_output,\n            set_cpus=self.set_cpus,\n            ui=ui,\n        )\n        return gen_result, sol_result\n\n    def calculate_score(self, gen_result: GeneratorResult, sol_result: SolverResult) -&gt; float:\n        \"\"\"Calculates the score achieved by the solver in this fight.\n\n        Both results need to contain all instance and/or solution data required.\n\n        Args:\n            gen_result: The generator's result.\n            sol_result: The solver's result\n\n        Returns:\n            A number in [0, 1] with higher numbers meaning the solver performed better.\n        \"\"\"\n        assert gen_result.instance is not None\n        assert sol_result.solution is not None\n        if self.problem.with_solution:\n            assert gen_result.solution is not None\n            score = self.problem.score(\n                gen_result.instance, solver_solution=sol_result.solution, generator_solution=gen_result.solution\n            )\n        else:\n            score = self.problem.score(gen_result.instance, solution=sol_result.solution)\n        return max(0, min(1, float(score)))\n</code></pre>"},{"location":"api/battle/#algobattle.battle.FightHandler.run","title":"<code>run(max_size, *, with_results=False, **kwargs)</code>  <code>async</code>","text":"<p>Execute a single fight of a battle.</p> <p>First the generator will be run and its output parsed. Then the solver will be given the created instance and run. Its output gets parsed into a solution, which will then be scored. The timeout, space, and cpu arguments each override the corresponding match config options if set. Leaving them unset results in the config options being used.</p> <p>Parameters:</p> Name Type Description Default <code>max_size</code> <code>int</code> <p>The maximum instance size the generator is allowed to create.</p> required <code>timeout_generator</code> <p>Timeout in seconds for the generator to finish running. <code>None</code> means it is given an unlimited amount of time.</p> required <code>space_generator</code> <p>Memory space in MB the generator has access to. <code>None</code> means it is given an unlimited amount of space.</p> required <code>cpus_generator</code> <p>Number of physical cpu cores the generator can use.</p> required <code>timeout_solver</code> <p>Timeout in seconds for the solver to finish running. <code>None</code> means it is given an unlimited amount of time.</p> required <code>space_solver</code> <p>Memory space in MB the solver has access to. <code>None</code> means it is given an unlimited amount of space.</p> required <code>cpus_solver</code> <p>Number of physical cpu cores the solver can use.</p> required <code>generator_battle_input</code> <p>Additional data the generator will be provided with.</p> required <code>solver_battle_input</code> <p>Additional data the solver will be provided with.</p> required <code>generator_battle_output</code> <p>Class used to parse additional data the generator outputs into a python object.</p> required <code>solver_battle_output</code> <p>Class used to parse additional data the solver outputs into a python object.</p> required <code>with_results</code> <code>bool</code> <p>Whether to return the raw result objects.</p> <code>False</code> <p>Returns:</p> Type Description <code>Fight | tuple[Fight, GeneratorResult, SolverResult | None]</code> <p>The resulting info about the executed fight, and the results if the flag has been set.</p> Source code in <code>algobattle/battle.py</code> <pre><code>async def run(\n    self,\n    max_size: int,\n    *,\n    with_results: bool = False,\n    **kwargs: Unpack[RunKwargs],\n) -&gt; Fight | tuple[Fight, GeneratorResult, SolverResult | None]:\n    \"\"\"Execute a single fight of a battle.\n\n    First the generator will be run and its output parsed. Then the solver will be given the created instance\n    and run. Its output gets parsed into a solution, which will then be scored.\n    The timeout, space, and cpu arguments each override the corresponding match config options if set. Leaving them\n    unset results in the config options being used.\n\n    Args:\n        max_size: The maximum instance size the generator is allowed to create.\n        timeout_generator: Timeout in seconds for the generator to finish running. `None` means it is given an\n            unlimited amount of time.\n        space_generator: Memory space in MB the generator has access to. `None` means it is given an unlimited\n            amount of space.\n        cpus_generator: Number of physical cpu cores the generator can use.\n        timeout_solver: Timeout in seconds for the solver to finish running. `None` means it is given an unlimited\n            amount of time.\n        space_solver: Memory space in MB the solver has access to. `None` means it is given\n            an unlimited amount of space.\n        cpus_solver: Number of physical cpu cores the solver can use.\n        generator_battle_input: Additional data the generator will be provided with.\n        solver_battle_input: Additional data the solver will be provided with.\n        generator_battle_output: Class used to parse additional data the generator outputs into a python object.\n        solver_battle_output: Class used to parse additional data the solver outputs into a python object.\n        with_results: Whether to return the raw result objects.\n\n    Returns:\n        The resulting info about the executed fight, and the results if the flag has been set.\n    \"\"\"\n    gen_result, sol_result = await self.run_raw(max_size=max_size, **kwargs)\n    if gen_result.instance is None or gen_result.solution is None:\n        score = 1\n    elif sol_result is None or sol_result.solution is None:\n        score = 0\n    else:\n        score = self.calculate_score(gen_result, sol_result)\n    fight = Fight.from_results(\n        score=score,\n        max_size=max_size,\n        generator=gen_result,\n        solver=sol_result,\n        config=self.log_config,\n    )\n    self.battle.fights.append(fight)\n    self.ui.end_fight()\n    if with_results:\n        return fight, gen_result, sol_result\n    else:\n        return fight\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Fight","title":"<code>algobattle.battle.Fight</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The result of one fight between the participating teams.</p> <p>For a more detailed description of what each fight looks like, see :meth:<code>FightHandler.run</code>.</p> Source code in <code>algobattle/battle.py</code> <pre><code>class Fight(BaseModel):\n    \"\"\"The result of one fight between the participating teams.\n\n    For a more detailed description of what each fight looks like, see :meth:`FightHandler.run`.\n    \"\"\"\n\n    score: float\n    \"\"\"The solving Team's score.\n\n    Always a number in [0, 1]. 0 indicates a total failure of the solver, 1 that it succeeded perfectly.\n    \"\"\"\n    max_size: int\n    \"\"\"The maximum size of an instance the generator was allowed to create.\"\"\"\n    generator: ProgramRunInfo\n    \"\"\"Data about the generator's execution.\"\"\"\n    solver: ProgramRunInfo | None\n    \"\"\"Data about the solver's execution.\"\"\"\n\n    @classmethod\n    def from_results(\n        cls,\n        max_size: int,\n        score: float,\n        generator: GeneratorResult,\n        solver: SolverResult | None,\n        *,\n        config: ProgramLogConfigView,\n    ) -&gt; Self:\n        \"\"\"Turns the involved result objects into a jsonable model.\"\"\"\n        inline_output = config.when == \"always\" or (\n            config.when == \"error\"\n            and (generator.error is not None or (solver is not None and solver.error is not None))\n        )\n        return cls(\n            max_size=max_size,\n            score=score,\n            generator=ProgramRunInfo.from_result(generator, inline_output=inline_output),\n            solver=ProgramRunInfo.from_result(solver, inline_output=inline_output) if solver is not None else None,\n        )\n</code></pre>"},{"location":"api/battle/#algobattle.battle.Fight.score","title":"<code>score: float</code>  <code>instance-attribute</code>","text":"<p>The solving Team's score.</p> <p>Always a number in [0, 1]. 0 indicates a total failure of the solver, 1 that it succeeded perfectly.</p>"},{"location":"api/battle/#algobattle.battle.Fight.max_size","title":"<code>max_size: int</code>  <code>instance-attribute</code>","text":"<p>The maximum size of an instance the generator was allowed to create.</p>"},{"location":"api/battle/#algobattle.battle.Fight.generator","title":"<code>generator: ProgramRunInfo</code>  <code>instance-attribute</code>","text":"<p>Data about the generator's execution.</p>"},{"location":"api/battle/#algobattle.battle.Fight.solver","title":"<code>solver: ProgramRunInfo | None</code>  <code>instance-attribute</code>","text":"<p>Data about the solver's execution.</p>"},{"location":"api/battle/#algobattle.battle.Fight.from_results","title":"<code>from_results(max_size, score, generator, solver, *, config)</code>  <code>classmethod</code>","text":"<p>Turns the involved result objects into a jsonable model.</p> Source code in <code>algobattle/battle.py</code> <pre><code>@classmethod\ndef from_results(\n    cls,\n    max_size: int,\n    score: float,\n    generator: GeneratorResult,\n    solver: SolverResult | None,\n    *,\n    config: ProgramLogConfigView,\n) -&gt; Self:\n    \"\"\"Turns the involved result objects into a jsonable model.\"\"\"\n    inline_output = config.when == \"always\" or (\n        config.when == \"error\"\n        and (generator.error is not None or (solver is not None and solver.error is not None))\n    )\n    return cls(\n        max_size=max_size,\n        score=score,\n        generator=ProgramRunInfo.from_result(generator, inline_output=inline_output),\n        solver=ProgramRunInfo.from_result(solver, inline_output=inline_output) if solver is not None else None,\n    )\n</code></pre>"},{"location":"api/problem/","title":"Problem","text":"<p>This module contains the <code>Problem</code>, <code>Instance</code>, <code>Solution</code>, and other related classes and thus the interface you can use to provide your own problems.</p>"},{"location":"api/problem/#algobattle.problem.Problem","title":"<code>algobattle.problem.Problem</code>","text":"<p>The definition of a problem.</p> Source code in <code>algobattle/problem.py</code> <pre><code>class Problem:\n    \"\"\"The definition of a problem.\"\"\"\n\n    @overload\n    def __init__(  # noqa: D107\n        self,\n        *,\n        name: str,\n        instance_cls: type[InstanceT],\n        solution_cls: type[SolutionT],\n        min_size: int = 0,\n        with_solution: Literal[True] = True,\n        score_function: ScoreFunctionWithSol[InstanceT, SolutionT] = default_score,\n        test_instance: InstanceT | None = None,\n    ) -&gt; None:\n        ...\n\n    @overload\n    def __init__(  # noqa: D107\n        self,\n        *,\n        name: str,\n        instance_cls: type[InstanceT],\n        solution_cls: type[SolutionT],\n        min_size: int = 0,\n        with_solution: Literal[False],\n        score_function: ScoreFunctionNoSol[InstanceT, SolutionT] = default_score,\n        test_instance: InstanceT | None = None,\n    ) -&gt; None:\n        ...\n\n    def __init__(\n        self,\n        *,\n        name: str,\n        instance_cls: type[InstanceT],\n        solution_cls: type[SolutionT],\n        min_size: int = 0,\n        with_solution: bool = True,\n        score_function: ScoreFunction[InstanceT, SolutionT] = default_score,\n        test_instance: InstanceT | None = None,\n    ) -&gt; None:\n        \"\"\"The definition of a problem.\n\n        Args:\n            name: The name of the problem.\n            instance_cls: Class defining what instances of this problem look like.\n            solution_cls: Class definitng what solutions of this problem look like.\n            min_size: Minimum size of valid instances of this problem.\n            with_solution: Whether the generator should also create a solution.\n            score_function: Function used to score how well a solution solves a problem instance.\n\n                The default scoring function returns the quotient of the solver's to the generator's solution score.\n\n                The score function always takes the instance as the first argument. If `with_solution` is set it then\n                gets the generated solutions at `generator_solution` and `solver_solution`. If it is not set it receives\n                the solver's solution at `solution`. It should return the calculated score, a number in [0, 1] with a\n                value of 0 indicating that the solver failed completely and 1 that it solved the instance perfectly.\n            test_instance: A dummy instance that can be used to test whether a solver produces correct output.\n        \"\"\"\n        self.name = name\n        self.instance_cls = instance_cls\n        self.solution_cls = solution_cls\n        self.min_size = min_size\n        self.with_solution = with_solution\n        self.score_function = score_function\n        self.test_instance = test_instance\n        self._problems[name] = self\n\n    __slots__ = (\"name\", \"instance_cls\", \"solution_cls\", \"min_size\", \"with_solution\", \"score_function\", \"test_instance\")\n    _problems: ClassVar[dict[str, Self]] = {}\n\n    @overload\n    def score(self, instance: InstanceT, *, solution: Solution[InstanceT]) -&gt; float:\n        ...\n\n    @overload\n    def score(\n        self, instance: InstanceT, *, generator_solution: Solution[InstanceT], solver_solution: Solution[InstanceT]\n    ) -&gt; float:\n        ...\n\n    def score(\n        self,\n        instance: Instance,\n        *,\n        solution: SolutionT | None = None,\n        generator_solution: SolutionT | None = None,\n        solver_solution: SolutionT | None = None,\n    ) -&gt; float:\n        \"\"\"Helper function to call self.score_function with easier to use overloads.\"\"\"\n        if self.with_solution:\n            if not (\n                isinstance(instance, self.instance_cls)\n                and isinstance(generator_solution, self.solution_cls)\n                and isinstance(solver_solution, self.solution_cls)\n                and solution is None\n            ):\n                raise TypeError\n            if TYPE_CHECKING:\n                assert isinstance(self.score_function, ScoreFunctionWithSol)\n            return self.score_function(instance, generator_solution=generator_solution, solver_solution=solver_solution)\n        else:\n            if not (\n                isinstance(instance, self.instance_cls)\n                and isinstance(solution, self.solution_cls)\n                and generator_solution is None\n                and solver_solution is None\n            ):\n                raise TypeError\n            if TYPE_CHECKING:\n                assert isinstance(self.score_function, ScoreFunctionNoSol)\n            return self.score_function(instance, solution=solution)\n\n    @classmethod\n    def load_file(cls, name: str, file: Path) -&gt; Self:\n        \"\"\"Loads the problem from the specified file.\"\"\"\n        existing_problems = cls._problems.copy()\n        cls._problems = {}\n        try:\n            import_file_as_module(file, \"__algobattle_problem__\")\n            if name not in cls._problems:\n                raise ValueError(f\"The {name} problem is not defined in {file}\")\n            else:\n                return cls._problems[name]\n        finally:\n            cls._problems = existing_problems\n\n    @classmethod\n    def load(cls, name: str, file: Path | None = None) -&gt; Self:\n        \"\"\"Loads the problem with the given name.\n\n        Args:\n            name: The name of the Problem to use.\n            file: Path to a file containing this problem.\n\n        Raises:\n            ValueError: If the problem is not specified properly\n            RuntimeError: If the problem's dynamic import fails\n        \"\"\"\n        if file:\n            return cls.load_file(name, file)\n        if name in cls._problems:\n            return cls._problems[name]\n        match list(entry_points(group=\"algobattle.problem\", name=name)):\n            case []:\n                raise ValueError(\"Problem name is not valid.\")\n            case [e]:\n                loaded: object = e.load()\n                if not isinstance(loaded, cls):\n                    raise ValueError(\n                        f\"The entrypoint '{name}' doesn't point to a problem but a {loaded.__class__.__qualname__}.\"\n                    )\n                return loaded\n            case entypoints:\n                raise ValueError(\n                    f\"Multiple problem entrypoints with the name {name} exist!\"\n                    f\" The modules providing them are: {', '.join(e.module for e in entypoints)}.\"\n                )\n\n    @classmethod\n    def available(cls) -&gt; set[str]:\n        \"\"\"Returns the names of all available Problems.\"\"\"\n        return set(chain(cls._problems.keys(), (e.name for e in entry_points(group=\"algobattle.problem\"))))\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Problem.__init__","title":"<code>__init__(*, name, instance_cls, solution_cls, min_size=0, with_solution=True, score_function=default_score, test_instance=None)</code>","text":"<p>The definition of a problem.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the problem.</p> required <code>instance_cls</code> <code>type[InstanceT]</code> <p>Class defining what instances of this problem look like.</p> required <code>solution_cls</code> <code>type[SolutionT]</code> <p>Class definitng what solutions of this problem look like.</p> required <code>min_size</code> <code>int</code> <p>Minimum size of valid instances of this problem.</p> <code>0</code> <code>with_solution</code> <code>bool</code> <p>Whether the generator should also create a solution.</p> <code>True</code> <code>score_function</code> <code>ScoreFunction[InstanceT, SolutionT]</code> <p>Function used to score how well a solution solves a problem instance.</p> <p>The default scoring function returns the quotient of the solver's to the generator's solution score.</p> <p>The score function always takes the instance as the first argument. If <code>with_solution</code> is set it then gets the generated solutions at <code>generator_solution</code> and <code>solver_solution</code>. If it is not set it receives the solver's solution at <code>solution</code>. It should return the calculated score, a number in [0, 1] with a value of 0 indicating that the solver failed completely and 1 that it solved the instance perfectly.</p> <code>default_score</code> <code>test_instance</code> <code>InstanceT | None</code> <p>A dummy instance that can be used to test whether a solver produces correct output.</p> <code>None</code> Source code in <code>algobattle/problem.py</code> <pre><code>def __init__(\n    self,\n    *,\n    name: str,\n    instance_cls: type[InstanceT],\n    solution_cls: type[SolutionT],\n    min_size: int = 0,\n    with_solution: bool = True,\n    score_function: ScoreFunction[InstanceT, SolutionT] = default_score,\n    test_instance: InstanceT | None = None,\n) -&gt; None:\n    \"\"\"The definition of a problem.\n\n    Args:\n        name: The name of the problem.\n        instance_cls: Class defining what instances of this problem look like.\n        solution_cls: Class definitng what solutions of this problem look like.\n        min_size: Minimum size of valid instances of this problem.\n        with_solution: Whether the generator should also create a solution.\n        score_function: Function used to score how well a solution solves a problem instance.\n\n            The default scoring function returns the quotient of the solver's to the generator's solution score.\n\n            The score function always takes the instance as the first argument. If `with_solution` is set it then\n            gets the generated solutions at `generator_solution` and `solver_solution`. If it is not set it receives\n            the solver's solution at `solution`. It should return the calculated score, a number in [0, 1] with a\n            value of 0 indicating that the solver failed completely and 1 that it solved the instance perfectly.\n        test_instance: A dummy instance that can be used to test whether a solver produces correct output.\n    \"\"\"\n    self.name = name\n    self.instance_cls = instance_cls\n    self.solution_cls = solution_cls\n    self.min_size = min_size\n    self.with_solution = with_solution\n    self.score_function = score_function\n    self.test_instance = test_instance\n    self._problems[name] = self\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Problem.score","title":"<code>score(instance, *, solution=None, generator_solution=None, solver_solution=None)</code>","text":"<p>Helper function to call self.score_function with easier to use overloads.</p> Source code in <code>algobattle/problem.py</code> <pre><code>def score(\n    self,\n    instance: Instance,\n    *,\n    solution: SolutionT | None = None,\n    generator_solution: SolutionT | None = None,\n    solver_solution: SolutionT | None = None,\n) -&gt; float:\n    \"\"\"Helper function to call self.score_function with easier to use overloads.\"\"\"\n    if self.with_solution:\n        if not (\n            isinstance(instance, self.instance_cls)\n            and isinstance(generator_solution, self.solution_cls)\n            and isinstance(solver_solution, self.solution_cls)\n            and solution is None\n        ):\n            raise TypeError\n        if TYPE_CHECKING:\n            assert isinstance(self.score_function, ScoreFunctionWithSol)\n        return self.score_function(instance, generator_solution=generator_solution, solver_solution=solver_solution)\n    else:\n        if not (\n            isinstance(instance, self.instance_cls)\n            and isinstance(solution, self.solution_cls)\n            and generator_solution is None\n            and solver_solution is None\n        ):\n            raise TypeError\n        if TYPE_CHECKING:\n            assert isinstance(self.score_function, ScoreFunctionNoSol)\n        return self.score_function(instance, solution=solution)\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Problem.load_file","title":"<code>load_file(name, file)</code>  <code>classmethod</code>","text":"<p>Loads the problem from the specified file.</p> Source code in <code>algobattle/problem.py</code> <pre><code>@classmethod\ndef load_file(cls, name: str, file: Path) -&gt; Self:\n    \"\"\"Loads the problem from the specified file.\"\"\"\n    existing_problems = cls._problems.copy()\n    cls._problems = {}\n    try:\n        import_file_as_module(file, \"__algobattle_problem__\")\n        if name not in cls._problems:\n            raise ValueError(f\"The {name} problem is not defined in {file}\")\n        else:\n            return cls._problems[name]\n    finally:\n        cls._problems = existing_problems\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Problem.load","title":"<code>load(name, file=None)</code>  <code>classmethod</code>","text":"<p>Loads the problem with the given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Problem to use.</p> required <code>file</code> <code>Path | None</code> <p>Path to a file containing this problem.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the problem is not specified properly</p> <code>RuntimeError</code> <p>If the problem's dynamic import fails</p> Source code in <code>algobattle/problem.py</code> <pre><code>@classmethod\ndef load(cls, name: str, file: Path | None = None) -&gt; Self:\n    \"\"\"Loads the problem with the given name.\n\n    Args:\n        name: The name of the Problem to use.\n        file: Path to a file containing this problem.\n\n    Raises:\n        ValueError: If the problem is not specified properly\n        RuntimeError: If the problem's dynamic import fails\n    \"\"\"\n    if file:\n        return cls.load_file(name, file)\n    if name in cls._problems:\n        return cls._problems[name]\n    match list(entry_points(group=\"algobattle.problem\", name=name)):\n        case []:\n            raise ValueError(\"Problem name is not valid.\")\n        case [e]:\n            loaded: object = e.load()\n            if not isinstance(loaded, cls):\n                raise ValueError(\n                    f\"The entrypoint '{name}' doesn't point to a problem but a {loaded.__class__.__qualname__}.\"\n                )\n            return loaded\n        case entypoints:\n            raise ValueError(\n                f\"Multiple problem entrypoints with the name {name} exist!\"\n                f\" The modules providing them are: {', '.join(e.module for e in entypoints)}.\"\n            )\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Problem.available","title":"<code>available()</code>  <code>classmethod</code>","text":"<p>Returns the names of all available Problems.</p> Source code in <code>algobattle/problem.py</code> <pre><code>@classmethod\ndef available(cls) -&gt; set[str]:\n    \"\"\"Returns the names of all available Problems.\"\"\"\n    return set(chain(cls._problems.keys(), (e.name for e in entry_points(group=\"algobattle.problem\"))))\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Instance","title":"<code>algobattle.problem.Instance</code>","text":"<p>             Bases: <code>Encodable</code>, <code>ABC</code></p> <p>Instance base class.</p> Source code in <code>algobattle/problem.py</code> <pre><code>class Instance(Encodable, ABC):\n    \"\"\"Instance base class.\"\"\"\n\n    @property\n    @abstractmethod\n    def size(self) -&gt; int:\n        \"\"\"The instance's size.\"\"\"\n        raise NotImplementedError\n\n    def validate_instance(self) -&gt; None:\n        \"\"\"Confirms that the parsed instance is valid.\n\n        Should be idempotent, but may also perform additional postprocessing such as bringing the instance\n        into a normal form.\n\n        Raises:\n            ValidationError: if the created instance is invalid.\n        \"\"\"\n        return\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Instance.size","title":"<code>size: int</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The instance's size.</p>"},{"location":"api/problem/#algobattle.problem.Instance.validate_instance","title":"<code>validate_instance()</code>","text":"<p>Confirms that the parsed instance is valid.</p> <p>Should be idempotent, but may also perform additional postprocessing such as bringing the instance into a normal form.</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>if the created instance is invalid.</p> Source code in <code>algobattle/problem.py</code> <pre><code>def validate_instance(self) -&gt; None:\n    \"\"\"Confirms that the parsed instance is valid.\n\n    Should be idempotent, but may also perform additional postprocessing such as bringing the instance\n    into a normal form.\n\n    Raises:\n        ValidationError: if the created instance is invalid.\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Solution","title":"<code>algobattle.problem.Solution</code>","text":"<p>             Bases: <code>EncodableBase</code>, <code>Generic[InstanceT]</code>, <code>ABC</code></p> <p>A proposed solution for an instance of this problem.</p> Source code in <code>algobattle/problem.py</code> <pre><code>class Solution(EncodableBase, Generic[InstanceT], ABC):\n    \"\"\"A proposed solution for an instance of this problem.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def decode(cls, source: Path, max_size: int, role: Role, instance: InstanceT) -&gt; Self:  # noqa: D102\n        raise NotImplementedError\n\n    def validate_solution(self, instance: InstanceT, role: Role) -&gt; None:\n        \"\"\"Confirms that the parsed solution is valid.\n\n        Should be idempotent, but may also perform additional postprocessing such as bringing the solution\n        into a normal form.\n\n        Args:\n            instance: The problem instance this solution is purported to solve.\n            role: The role of the team that generated this solution.\n\n        Raises:\n            ValidationError: if the created instance is invalid.\n        \"\"\"\n        return\n\n    def score(self, instance: InstanceT, role: Role) -&gt; float:\n        \"\"\"Calculate the score of this solution for the given problem instance.\n\n        The default implementation always returns 1, indicating that all solutions of this problem are equally good.\n\n        Args:\n            instance: The instance this solution solves\n            role: The role of the team that generated this solution\n        Returns:\n            The calculates score of this solution. Must be a nonnegative number. Bigger scores are considered better,\n            if your score rates better scores lower you can use the @minimize decorator.\n        \"\"\"\n        return 1\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Solution.validate_solution","title":"<code>validate_solution(instance, role)</code>","text":"<p>Confirms that the parsed solution is valid.</p> <p>Should be idempotent, but may also perform additional postprocessing such as bringing the solution into a normal form.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>InstanceT</code> <p>The problem instance this solution is purported to solve.</p> required <code>role</code> <code>Role</code> <p>The role of the team that generated this solution.</p> required <p>Raises:</p> Type Description <code>ValidationError</code> <p>if the created instance is invalid.</p> Source code in <code>algobattle/problem.py</code> <pre><code>def validate_solution(self, instance: InstanceT, role: Role) -&gt; None:\n    \"\"\"Confirms that the parsed solution is valid.\n\n    Should be idempotent, but may also perform additional postprocessing such as bringing the solution\n    into a normal form.\n\n    Args:\n        instance: The problem instance this solution is purported to solve.\n        role: The role of the team that generated this solution.\n\n    Raises:\n        ValidationError: if the created instance is invalid.\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/problem/#algobattle.problem.Solution.score","title":"<code>score(instance, role)</code>","text":"<p>Calculate the score of this solution for the given problem instance.</p> <p>The default implementation always returns 1, indicating that all solutions of this problem are equally good.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>InstanceT</code> <p>The instance this solution solves</p> required <code>role</code> <code>Role</code> <p>The role of the team that generated this solution</p> required <p>Returns:     The calculates score of this solution. Must be a nonnegative number. Bigger scores are considered better,     if your score rates better scores lower you can use the @minimize decorator.</p> Source code in <code>algobattle/problem.py</code> <pre><code>def score(self, instance: InstanceT, role: Role) -&gt; float:\n    \"\"\"Calculate the score of this solution for the given problem instance.\n\n    The default implementation always returns 1, indicating that all solutions of this problem are equally good.\n\n    Args:\n        instance: The instance this solution solves\n        role: The role of the team that generated this solution\n    Returns:\n        The calculates score of this solution. Must be a nonnegative number. Bigger scores are considered better,\n        if your score rates better scores lower you can use the @minimize decorator.\n    \"\"\"\n    return 1\n</code></pre>"},{"location":"api/problem/#algobattle.problem.InstanceModel","title":"<code>algobattle.problem.InstanceModel</code>","text":"<p>             Bases: <code>InstanceSolutionModel</code>, <code>EncodableModel</code>, <code>Instance</code>, <code>ABC</code></p> <p>An instance that can easily be parsed to/from a json file.</p> Source code in <code>algobattle/problem.py</code> <pre><code>class InstanceModel(InstanceSolutionModel, EncodableModel, Instance, ABC):\n    \"\"\"An instance that can easily be parsed to/from a json file.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/problem/#algobattle.problem.SolutionModel","title":"<code>algobattle.problem.SolutionModel</code>","text":"<p>             Bases: <code>InstanceSolutionModel</code>, <code>Solution[InstanceT]</code>, <code>ABC</code></p> <p>A solution that can easily be parsed to/from a json file.</p> Source code in <code>algobattle/problem.py</code> <pre><code>class SolutionModel(InstanceSolutionModel, Solution[InstanceT], ABC):\n    \"\"\"A solution that can easily be parsed to/from a json file.\"\"\"\n\n    @classmethod\n    def decode(cls, source: Path, max_size: int, role: Role, instance: InstanceT) -&gt; Self:\n        \"\"\"Uses pydantic to create a python object from a `.json` file.\"\"\"\n        context: dict[str, Any] = {\"max_size\": max_size, \"role\": role, \"instance\": instance}\n        return cls._decode(cls, source, **context)\n</code></pre>"},{"location":"api/problem/#algobattle.problem.SolutionModel.decode","title":"<code>decode(source, max_size, role, instance)</code>  <code>classmethod</code>","text":"<p>Uses pydantic to create a python object from a <code>.json</code> file.</p> Source code in <code>algobattle/problem.py</code> <pre><code>@classmethod\ndef decode(cls, source: Path, max_size: int, role: Role, instance: InstanceT) -&gt; Self:\n    \"\"\"Uses pydantic to create a python object from a `.json` file.\"\"\"\n    context: dict[str, Any] = {\"max_size\": max_size, \"role\": role, \"instance\": instance}\n    return cls._decode(cls, source, **context)\n</code></pre>"},{"location":"api/util/","title":"Utility","text":"<p>This module contains various objects needed in the rest of the algobattle package. In particular, the exception classes and the <code>Encodable</code> base classes.</p>"},{"location":"api/util/#algobattle.util.Role","title":"<code>algobattle.util.Role</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Indicates whether the role of a program is to generate or to solve instances.</p> Source code in <code>algobattle/util.py</code> <pre><code>class Role(StrEnum):\n    \"\"\"Indicates whether the role of a program is to generate or to solve instances.\"\"\"\n\n    generator = \"generator\"\n    solver = \"solver\"\n</code></pre>"},{"location":"api/util/#algobattle.util.BaseModel","title":"<code>algobattle.util.BaseModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Base class for all pydantic models.</p> Source code in <code>algobattle/util.py</code> <pre><code>class BaseModel(PydandticBaseModel):\n    \"\"\"Base class for all pydantic models.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", from_attributes=True, hide_input_in_errors=True)\n</code></pre>"},{"location":"api/util/#algobattle.util.Encodable","title":"<code>algobattle.util.Encodable</code>","text":"<p>             Bases: <code>EncodableBase</code>, <code>ABC</code></p> <p>Represents data that docker containers can interact with.</p> Source code in <code>algobattle/util.py</code> <pre><code>class Encodable(EncodableBase, ABC):\n    \"\"\"Represents data that docker containers can interact with.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def decode(cls, source: Path, max_size: int, role: Role) -&gt; Self:\n        \"\"\"Decodes the data found at the given path into a python object.\n\n        Args:\n            source: Path to data that can be used to construct an instance of this class. May either point to a folder\n                or a single file. The expected type of path should be consistent with the result of :meth:`.encode`.\n            max_size: Maximum size the current battle allows.\n            role: Role of the program that generated this data.\n\n        Raises:\n            EncodingError: If the data cannot be decoded into an instance.\n\n        Returns:\n            The decoded object.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/util/#algobattle.util.Encodable.decode","title":"<code>decode(source, max_size, role)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Decodes the data found at the given path into a python object.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Path to data that can be used to construct an instance of this class. May either point to a folder or a single file. The expected type of path should be consistent with the result of :meth:<code>.encode</code>.</p> required <code>max_size</code> <code>int</code> <p>Maximum size the current battle allows.</p> required <code>role</code> <code>Role</code> <p>Role of the program that generated this data.</p> required <p>Raises:</p> Type Description <code>EncodingError</code> <p>If the data cannot be decoded into an instance.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The decoded object.</p> Source code in <code>algobattle/util.py</code> <pre><code>@classmethod\n@abstractmethod\ndef decode(cls, source: Path, max_size: int, role: Role) -&gt; Self:\n    \"\"\"Decodes the data found at the given path into a python object.\n\n    Args:\n        source: Path to data that can be used to construct an instance of this class. May either point to a folder\n            or a single file. The expected type of path should be consistent with the result of :meth:`.encode`.\n        max_size: Maximum size the current battle allows.\n        role: Role of the program that generated this data.\n\n    Raises:\n        EncodingError: If the data cannot be decoded into an instance.\n\n    Returns:\n        The decoded object.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/util/#algobattle.util.EncodableModel","title":"<code>algobattle.util.EncodableModel</code>","text":"<p>             Bases: <code>EncodableModelBase</code>, <code>ABC</code></p> <p>Problem data that can easily be encoded into and decoded from json files.</p> Source code in <code>algobattle/util.py</code> <pre><code>class EncodableModel(EncodableModelBase, ABC):\n    \"\"\"Problem data that can easily be encoded into and decoded from json files.\"\"\"\n\n    @classmethod\n    def decode(cls, source: Path, max_size: int, role: Role) -&gt; Self:\n        \"\"\"Uses pydantic to create a python object from a `.json` file.\"\"\"\n        return cls._decode(cls, source, max_size=max_size, role=role)\n</code></pre>"},{"location":"api/util/#algobattle.util.EncodableModel.decode","title":"<code>decode(source, max_size, role)</code>  <code>classmethod</code>","text":"<p>Uses pydantic to create a python object from a <code>.json</code> file.</p> Source code in <code>algobattle/util.py</code> <pre><code>@classmethod\ndef decode(cls, source: Path, max_size: int, role: Role) -&gt; Self:\n    \"\"\"Uses pydantic to create a python object from a `.json` file.\"\"\"\n    return cls._decode(cls, source, max_size=max_size, role=role)\n</code></pre>"},{"location":"api/util/#algobattle.util.AlgobattleBaseException","title":"<code>algobattle.util.AlgobattleBaseException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Base exception class for errors used by the algobattle package.</p> Source code in <code>algobattle/util.py</code> <pre><code>class AlgobattleBaseException(Exception):\n    \"\"\"Base exception class for errors used by the algobattle package.\"\"\"\n\n    def __init__(self, message: LiteralString, *, detail: str | list[str] | list[dict[str, Any]] | None = None) -&gt; None:\n        \"\"\"Base exception class for errors used by the algobattle package.\n\n        Args:\n            message: Simple error message that can always be displayed.\n            detail: More detailed error message that may include sensitive information.\n        \"\"\"\n        self.message = message\n        self.detail = detail\n        super().__init__()\n</code></pre>"},{"location":"api/util/#algobattle.util.AlgobattleBaseException.__init__","title":"<code>__init__(message, *, detail=None)</code>","text":"<p>Base exception class for errors used by the algobattle package.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>LiteralString</code> <p>Simple error message that can always be displayed.</p> required <code>detail</code> <code>str | list[str] | list[dict[str, Any]] | None</code> <p>More detailed error message that may include sensitive information.</p> <code>None</code> Source code in <code>algobattle/util.py</code> <pre><code>def __init__(self, message: LiteralString, *, detail: str | list[str] | list[dict[str, Any]] | None = None) -&gt; None:\n    \"\"\"Base exception class for errors used by the algobattle package.\n\n    Args:\n        message: Simple error message that can always be displayed.\n        detail: More detailed error message that may include sensitive information.\n    \"\"\"\n    self.message = message\n    self.detail = detail\n    super().__init__()\n</code></pre>"},{"location":"api/util/#algobattle.util.EncodingError","title":"<code>algobattle.util.EncodingError</code>","text":"<p>             Bases: <code>AlgobattleBaseException</code></p> <p>Indicates that the given data could not be encoded or decoded properly.</p> Source code in <code>algobattle/util.py</code> <pre><code>class EncodingError(AlgobattleBaseException):\n    \"\"\"Indicates that the given data could not be encoded or decoded properly.\"\"\"\n</code></pre>"},{"location":"api/util/#algobattle.util.ValidationError","title":"<code>algobattle.util.ValidationError</code>","text":"<p>             Bases: <code>AlgobattleBaseException</code></p> <p>Indicates that the decoded problem instance or solution is invalid.</p> Source code in <code>algobattle/util.py</code> <pre><code>class ValidationError(AlgobattleBaseException):\n    \"\"\"Indicates that the decoded problem instance or solution is invalid.\"\"\"\n</code></pre>"},{"location":"api/util/#algobattle.util.BuildError","title":"<code>algobattle.util.BuildError</code>","text":"<p>             Bases: <code>AlgobattleBaseException</code></p> <p>Indicates that the build process could not be completed successfully.</p> Source code in <code>algobattle/util.py</code> <pre><code>class BuildError(AlgobattleBaseException):\n    \"\"\"Indicates that the build process could not be completed successfully.\"\"\"\n</code></pre>"},{"location":"api/util/#algobattle.util.ExecutionError","title":"<code>algobattle.util.ExecutionError</code>","text":"<p>             Bases: <code>AlgobattleBaseException</code></p> <p>Indicates that the program could not be executed successfully.</p> Source code in <code>algobattle/util.py</code> <pre><code>class ExecutionError(AlgobattleBaseException):\n    \"\"\"Indicates that the program could not be executed successfully.\"\"\"\n\n    def __init__(self, message: LiteralString, *, detail: str | None = None, runtime: float) -&gt; None:\n        \"\"\"Indicates that the program could not be executed successfully.\n\n        Args:\n            message: Simple error message that can always be displayed.\n            runtime: Runtime of the program in seconds until the error occured.\n            detail: More detailed error message that may include sensitive information.\n        \"\"\"\n        self.runtime = runtime\n        super().__init__(message, detail=detail)\n</code></pre>"},{"location":"api/util/#algobattle.util.ExecutionError.__init__","title":"<code>__init__(message, *, detail=None, runtime)</code>","text":"<p>Indicates that the program could not be executed successfully.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>LiteralString</code> <p>Simple error message that can always be displayed.</p> required <code>runtime</code> <code>float</code> <p>Runtime of the program in seconds until the error occured.</p> required <code>detail</code> <code>str | None</code> <p>More detailed error message that may include sensitive information.</p> <code>None</code> Source code in <code>algobattle/util.py</code> <pre><code>def __init__(self, message: LiteralString, *, detail: str | None = None, runtime: float) -&gt; None:\n    \"\"\"Indicates that the program could not be executed successfully.\n\n    Args:\n        message: Simple error message that can always be displayed.\n        runtime: Runtime of the program in seconds until the error occured.\n        detail: More detailed error message that may include sensitive information.\n    \"\"\"\n    self.runtime = runtime\n    super().__init__(message, detail=detail)\n</code></pre>"},{"location":"api/util/#algobattle.util.ExecutionTimeout","title":"<code>algobattle.util.ExecutionTimeout</code>","text":"<p>             Bases: <code>ExecutionError</code></p> <p>Indicates that the program ran into the timeout.</p> Source code in <code>algobattle/util.py</code> <pre><code>class ExecutionTimeout(ExecutionError):\n    \"\"\"Indicates that the program ran into the timeout.\"\"\"\n</code></pre>"},{"location":"api/util/#algobattle.util.DockerError","title":"<code>algobattle.util.DockerError</code>","text":"<p>             Bases: <code>AlgobattleBaseException</code></p> <p>Indicates that an issue with the docker daemon occured.</p> Source code in <code>algobattle/util.py</code> <pre><code>class DockerError(AlgobattleBaseException):\n    \"\"\"Indicates that an issue with the docker daemon occured.\"\"\"\n</code></pre>"},{"location":"api/util/#algobattle.util.ExceptionInfo","title":"<code>algobattle.util.ExceptionInfo</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Details about an exception that was raised.</p> Source code in <code>algobattle/util.py</code> <pre><code>class ExceptionInfo(BaseModel):\n    \"\"\"Details about an exception that was raised.\"\"\"\n\n    type: str\n    message: str\n    detail: str | list[str] | list[dict[str, Any]] | None = None\n\n    @classmethod\n    def from_exception(cls, error: Exception) -&gt; Self:\n        \"\"\"Constructs an instance from a raised exception.\"\"\"\n        if isinstance(error, AlgobattleBaseException):\n            return cls(\n                type=error.__class__.__name__,\n                message=error.message,\n                detail=error.detail,\n            )\n        elif isinstance(error, PydanticValidationError):\n            return cls(\n                type=error.__class__.__name__,\n                message=str(error),\n                detail=str(error.errors(include_input=True, include_url=False)),\n            )\n        else:\n            return cls(\n                type=error.__class__.__name__,\n                message=\"Unknown exception occurred.\",\n                detail=format_exception(error),\n            )\n</code></pre>"},{"location":"api/util/#algobattle.util.ExceptionInfo.from_exception","title":"<code>from_exception(error)</code>  <code>classmethod</code>","text":"<p>Constructs an instance from a raised exception.</p> Source code in <code>algobattle/util.py</code> <pre><code>@classmethod\ndef from_exception(cls, error: Exception) -&gt; Self:\n    \"\"\"Constructs an instance from a raised exception.\"\"\"\n    if isinstance(error, AlgobattleBaseException):\n        return cls(\n            type=error.__class__.__name__,\n            message=error.message,\n            detail=error.detail,\n        )\n    elif isinstance(error, PydanticValidationError):\n        return cls(\n            type=error.__class__.__name__,\n            message=str(error),\n            detail=str(error.errors(include_input=True, include_url=False)),\n        )\n    else:\n        return cls(\n            type=error.__class__.__name__,\n            message=\"Unknown exception occurred.\",\n            detail=format_exception(error),\n        )\n</code></pre>"},{"location":"instructor/","title":"Instructor's Corner","text":"<p>This section is all about the stuff behind the scenes. It covers how you can structure the course and detailed info on how to interact with the framework. Individual pages are largely independent of each other and can be read in sequence or used as a reference as needed.</p>"},{"location":"instructor/#overview","title":"Overview","text":"<ul> <li> <p>The teaching concept provides a high level overview of the project, what a full course looks     like, and what our goals are.</p> </li> <li> <p>The problem pages discuss how to create your own problems for students to solve. The intro and     basic section cover everything you need to know to get started and work with most     types of problems. However, the framework is incredibly versatile and lets you create much more complex and out of     the box problems than you might initially think. The following pages dive into more detail on everything else.</p> </li> <li> <p>Battle types discusses how you can customize the Algobattle match process itself by writing your own     battle types.</p> </li> </ul>"},{"location":"instructor/teaching_english/","title":"Lab Course Teaching Concept","text":"<p>This page also is available in German</p> <p>Switch language </p>"},{"location":"instructor/teaching_english/#basics","title":"Basics","text":""},{"location":"instructor/teaching_english/#about-this-document","title":"About this Document","text":"<p>This document describes a teaching concept that was developed in university teaching. Its goal is to support teachers to use the <code>algobattle</code>-tool as well as related software for their own teaching. The focus is here on the teaching aspect. For an explanation of the technical requirements as well as a manual, please consult the technical documentation.</p>"},{"location":"instructor/teaching_english/#who-is-this-software-made-for","title":"Who is this Software Made for?","text":"<p>The <code>algobattle</code>-tool has been developed since 2019 by the Theory Group of RWTH Aachen University for use in a software programming lab course in a bachelor of computer science.  Although this is reflected in the collection of pre-made problems, nothing speaks against using this tool in other study courses of late high-school teaching.</p> <p>The project is thus targeted at teachers, for whom we want to ease the work to establish a competitive teaching experience. The extremely modular nature of the project allows to either cover a wide range of different topics or to focus on a specific topic.</p>"},{"location":"instructor/teaching_english/#what-do-i-have-to-know-about-licensing","title":"What do I have to Know about Licensing?","text":"<p>The complete software and associated documentation are published under a free MIT-license, if not stated otherwise. You can thus use, modify, extend or use them, even in a commercial context, without asking for permission. We would however appreciate it if you would reference us as a source if you do.</p>"},{"location":"instructor/teaching_english/#how-many-students-can-the-lab-course-accommodate","title":"How Many Students Can the Lab Course Accommodate?","text":"<p>We recommend splitting up your students into groups; from our experience groups of six students work best. There then can be an arbitrary number of such groups. Do mind of course, that with an increase in students, the supervisory effort increases as well. With two teaching assistants we were able to manage 18 students over the course of a semester, requiring not more than two work days in total per week.</p>"},{"location":"instructor/teaching_english/#structure","title":"Structure","text":""},{"location":"instructor/teaching_english/#basic-idea","title":"Basic Idea","text":"<p>The Algorithmic Battle, in its original form, had the aim of providing students a practical way to engage with commonly theoretical results from their lectures. In computer science, complexity theory is an important element: It tells us that for many problems we should not expect to find algorithms that are fast, correct and universal at the same time.</p> <p>This often neglects the fact that such problems do in fact need to be solved and indeed do get solved in practice. Especially due to the boom of so-called MIP-solvers such as Gurobi, CPLEX and others, practical optimization problems are solved and often very fast.</p> <p>This observation is based on seeing a problem as a collection of all possible instances: For some problems, there are cores that consist of subsets of such instances. On the other hand, many other subsets do admit solutions that are very easy to find and these seem to correlate with practical instances.</p>"},{"location":"instructor/teaching_english/#teaching-goals","title":"Teaching Goals","text":"<p>The focus of the lab course lies in letting the students take both perspectives of a solving process. They should learn to answer two questions:</p> <ul> <li>What are \"hard instances\" of a problem?</li> <li>How do I write algorithms that are fast and correct most of the time?</li> </ul> <p>This means that students should both write code for a <code>generator</code> for the creation of hard instances (given an instance size), as well as a <code>solver</code>, that takes an instance as an argument and should output a good solution within a given time limit.</p> <p>Every <code>generator</code> of a team is then matched against the <code>solver</code> of another team. In the classical setting, the question is then up to which instance size the <code>solver</code> of one team is able to still solve the instances generated by the other team. The scoring is then done by how much better the winning team is than the other: The highest instance size for which an instance of one team still could be solved is compared to that of the other, and points are awarded according to this ratio. To maximize this relative distance of scores, it is thus important on the one hand to write a <code>generator</code> that outputs hard instances, in order to ensure that the other teams <code>solver</code> fails early. On the other hand, it is just as important to also write a strong <code>solver</code>, as not to fail early on instances that should not be so hard to solve.</p> <p>We see it as particularly encouraging that we do not give any limitations on external software used by the students (as long as they do not result in legal issues.) Since all student software is deployed in docker containers and since one is not artificially held back in real life either, the students are actively encouraged to research their given problem, related publications and software to use in their code. There are only very few limitations that we actively enforce:</p> <ul> <li>Only use software if the license allows you to do so</li> <li>No plotting with or spying out other teams</li> <li>Do not exploit our framework software (see also <code>Bug Bounties</code>)</li> </ul> <p>We let the students develop their code in a version control system to which we have full observer rights. The students should coordinate their coding process and organize themselves, be it by simply talking, creating issues or creating branches and pull requests. By having a full view of the commit history, one can already see during the duration of the lab course whether individual persons do not contribute substantially, allowing you to interfere early.</p> <p>We additionally demand a full documentation of the development process. Every researched idea and every implementation, even if only attempted, is to be documented. For this to work, we let every person of a team be responsible for the coordination of the documentation once during the semester. Every other person of the team then has the responsibility to report to the documenting person what they have done. The coordinating person thus does not have the responsibility to nag their team members: Those who do not report their progress will not be part of the documentation and are thus assumed not to have contributed anything until proven otherwise.</p>"},{"location":"instructor/teaching_english/#sample-structure-of-a-semester","title":"Sample Structure of a Semester","text":"<p>We next describe the structure of a typical semester-long lab course at RWTH Aachen University. This structure of of course not in any way binding, but resulted in very positive feedback by the students over the past years.</p> <p>Every semester starts the same. Shortly before or right at the start of the lecture period, we host a kick-off meeting in which we inform the students about the format and structure of the lab course. We next find a regular time-slot in the week for the weekly meeting and assign the students into groups of six. We have a focus on putting at most subgroups of three students that already are a peer group into one team, to lower the risk of exclusive behavior.</p> <p>The first task that we use as a primer is always the same, namely the <code>pairsum</code> task, which can be found in the <code>algobattle-problems</code> repository. The achieved points in this task do not count towards the global rating, the task is meant to get familiar with the framework, our software and the format of battles. We do however insist on creating a documentation, as described above. As in all subsequent tasks, we start scheduling daily automated battles with the current state of the student's software after a week, to give them feedback on how good or bad their code performs against the code of the other teams.</p> <p>At the end of this task and every following one, we have a concluding meeting. In this meeting, we ask two randomly chosen students to (freely) present the ideas of their <code>solver</code> and <code>generator</code> to the rest of the students. We expect every student to be informed about their software and the development process, which we try to enforce by this random selection.</p> <p>We then present the overall results of all battles, talk about possibly collected <code>Bug Bounties</code> and discuss in an open round what the students have learned in the past two weeks. Finally, we present the next task.</p> <p>The cycle is then always the same: After getting a description of the next problem, we let the groups research and implement for a week. After this week, we meet with every group separately. In this meeting, we discuss their ideas and implementations, as well as possible problems. After this meeting, we schedule daily battles until the final meeting. The first of these battles does not award points to mitigate the consequences of oversights in implementations resulting in crashes.</p> <p>In a typical semester, there is time for 6-7 tasks of this format (<code>pairsum</code> included.) We recommend sticking to six tasks and to use the remaining time as a buffer for other tasks. This results in less pressure for the students and matches the number of documentations to be created.</p> <p>Regarding the teaching goals for individual tasks, we roughly follow the following scheme of task types:</p> <ol> <li><code>pairsum</code> as a warm-up task</li> <li>A classical, NP-complete problem to encourage research</li> <li>Problem in P for strong optimizations of data structures and algorithms</li> <li>Approximation problem with an approximation ratio that should not allow for polynomial algorithms</li> <li>Non-classical, NP-complete problem to encourage the use of MIP-solvers</li> <li>Wildcard problem, e.g. strongly limited Memory, problem in FPT,...</li> </ol> <p>After the last task, the lab course ends, coinciding with the end of the lecture period. Afterwards, the grading process starts.</p>"},{"location":"instructor/teaching_english/#grading-of-students","title":"Grading of Students","text":"<p>If you would like to grad the participants of the lab course, we give a few pointers on what you could base this grading on.  We already check the following criteria in the middle of the semester, to spot and help individuals that already struggle at this point.</p>"},{"location":"instructor/teaching_english/#overall-quality-of-the-software","title":"Overall Quality of the Software","text":"<p>This allows for a first impression for grading the group. Central questions are: How much effort was put into the code during the course of the semester? A group that tends to perform bad in battles, but researched and implemented many different approaches should in our opinion not automatically be graded badly.</p>"},{"location":"instructor/teaching_english/#documentation","title":"Documentation","text":"<p>The person responsible for the documentation is of course reliant on the quality and contents provided by their other group members. It is commonly very clearly visible how much each member contributed during each week. We grade students that exclusively focused on one kind of work during the whole semester, e.g. only implementation or only research, worse than others.</p>"},{"location":"instructor/teaching_english/#talks","title":"Talks","text":"<p>If a student was clearly badly prepared for holding a talk, this results in worse grading. A bad preparation commonly coincides with little participation in the task.</p>"},{"location":"instructor/teaching_english/#implementation","title":"Implementation","text":"<p>Since this is a software lab, we do not let anyone pass that did not contribute to the implementation work, be it by pair programming or individual contributions. This is easily checkable by the commit history of a group.</p>"},{"location":"instructor/teaching_english/#further-uses-of-the-software","title":"Further Uses of the Software","text":"<p>We want to emphasize that the <code>algobattle</code>-tool was written with modularity in mind regarding the nature of tasks and the inner nature of battles. While we as the original authors have a strong bias towards problems of theoretical computer science, nothing speaks against other types of battles and problems.</p>"},{"location":"instructor/teaching_english/#other-types-of-battles","title":"Other Types of Battles","text":"<p>So far, we have assumed in our description that a <code>generator</code> and <code>solver</code> battle on ever increasing instance sizes, until one of them fails. Points are then awarded on the relative distance between the largest solved instances. This is however only the description of the default <code>battle type</code>, the <code>iterated</code> type.</p> <p>Another, alternative <code>battle type</code> shipped with the software is the <code>averaged</code> type, in which only instances of a fixed instance size are to be solved a given number of times within a time limit. The points are then awarded based on the average solution quality of a solver.</p> <p>We encourage you to create your own <code>battle type</code> to model different abstractions of <code>generator</code>s and <code>solver</code>s fighting one another.</p>"},{"location":"instructor/teaching_english/#other-types-of-tasks","title":"Other Types of Tasks","text":"<p>In most of our sample tasks, the input and output of <code>generator</code>s and <code>solver</code>s are simple json-files containing text. The I/O specification does however allow for arbitrary file- and folder structures to be passed. Thus, other files such as multimedia content in the form of audio or pictures can be specified as the input and output of <code>generator</code>s and <code>solver</code>s.</p>"},{"location":"instructor/teaching_english/#miscellaneous","title":"Miscellaneous","text":""},{"location":"instructor/teaching_english/#bug-bounties","title":"Bug Bounties","text":"<p>We encourage our students to attack and exploit the <code>algobattle</code>-framework as well as the code of the tasks that we provide them. We are interested in inputs that allow students to crash our code, the <code>solver</code> and <code>generators</code> of other teams (independent of the contents of them) or even exploit the framework to gain access to the code of other groups. As mentioned before, we demand these bugs not to be exploited in order to achieve a better standing. We do however award additional points for finding and reporting the bugs in a reproducible manner. Only the first group to find and report a bug is awarded points for it. The number of points is based on the gravity of the bug found.</p> <p>The big advantage of this approach is to reward the natural curiosity to explore and exploit systems in a constructive way. A positive consequence is that we are then to implement more test cases for the found bugs.</p>"},{"location":"instructor/teaching_english/#known-issues-during-a-lab-course","title":"Known Issues During a Lab Course","text":"<p>At some point, students learn that MIP-solvers exist. This is disadvantageous for many problems, as they are rather efficient in practice and do not encourage further research. We thus recommend creating tasks that make MIP-solvers, or other kinds of efficient, general solvers, unattractive. In the case of MIP-solvers it commonly also helps to reduce the amount of available memory, as they often require a lot of it.</p>"},{"location":"instructor/teaching_english/#additional-resources","title":"Additional Resources","text":"<p>Official Website algobattle-Framework (Github) Collection of problems for algobattle (Github) Web-framework for algobattle (Github) Technical Documentation</p>"},{"location":"instructor/teaching_german/","title":"Praktikum Lehrkonzept","text":"<p>Diese Seite ist auch auf Englisch verf\u00fcgbar</p> <p>Sprache wechseln </p>"},{"location":"instructor/teaching_german/#grundlegendes","title":"Grundlegendes","text":""},{"location":"instructor/teaching_german/#uber-dieses-dokument","title":"\u00dcber dieses Dokument","text":"<p>Dieses Dokument beschreibt ein in der universit\u00e4ren Lehre praktisch erarbeitetes Lehrkonzept. Dieses hat das Ziel, Lehrende dabei zu unterst\u00fctzen, das <code>algobattle</code>-tool sowie dazugeh\u00f6rige Software f\u00fcr die eigene Lehre einzusetzen. Der Fokus liegt hierbei auf dem Lehraspekt. F\u00fcr eine Erkl\u00e4rung der technischen Vorraussetzungen sowie Bedienungdetails, konsultieren Sie bitte die technische Dokumentation.</p>"},{"location":"instructor/teaching_german/#fur-wen-ist-diese-software","title":"F\u00fcr wen ist diese Software?","text":"<p>Das <code>algobattle</code>-Tool wurde seit 2019 am Lehr- und Forschungsgebiet Theoretische Informatik der RWTH Aachen University entwickelt und f\u00fcr den Einsatz im Rahmen eines Softwarepraktikums f\u00fcr Studierende des Bachelor Informatik entworfen. Obwohl die Sammlung der von uns bereitgestellten Aufgaben dies stark widerspiegelt, spricht nichts dagegen, das Tool f\u00fcr andere Studieng\u00e4nge oder sogar f\u00fcr den Schulunterricht in der Oberstufe einzusetzen.</p> <p>Das Projekt richtet sich damit an Lehrende, denen wir es durch unsere Arbeit erleichtern m\u00f6chten, eine kompetitive Lernerfahrung aufzubauen. Die extrem modulare Natur des Projekts erlaubt es, \u00fcber ein Semester entweder viele verschiedene Themen abzudecken oder sich mit ausgew\u00e4hlten Themen intensiv zu befassen.</p>"},{"location":"instructor/teaching_german/#muss-ich-lizenzen-bei-der-verwendung-beachten","title":"Muss ich Lizenzen bei der Verwendung beachten?","text":"<p>Die ganze Software wie auch die dazugeh\u00f6rigen Dokumente sind unter einer freien MIT-Lizenz ver\u00f6ffentlicht, sofern nicht explizit anders angegeben. Sie m\u00fcssen daher kein Einverst\u00e4ndnis einholen, um die Software und die dazugh\u00f6rigen Dokumente und Ver\u00f6ffentlichungen zu verwenden, zu modifizieren, weiterzuentwickeln oder in einem kommerziellen Rahmen (z.B. in privaten Lehrst\u00e4tten) zu verwenden. Wir f\u00e4nden es jedoch nett, wenn Sie dabei auf uns als Quelle verweisen w\u00fcrden.</p>"},{"location":"instructor/teaching_german/#fur-welche-teilnehmerzahl-ist-das-praktikum-geeignet","title":"F\u00fcr welche Teilnehmerzahl ist das Praktikum geeignet?","text":"<p>Wir empfehlen, die Studierenden in mehrere Einzelgruppen einzuteilen; unserer Erfahrung nach ist eine Gruppengr\u00f6\u00dfe von sechs Personen am besten geeignet. Von diesen kann es dann prinzipiell beliebig viele geben. Dabei ist nat\u00fcrlich zu beachten, dass mit mehr Gruppen der Betreuungsaufwand steigt. Wir konnten mit zwei Lehrenden den Praktikumsbetrieb f\u00fcr 18 Studierende gut neben den sonstigen beruflichen T\u00e4tigkeiten managen. Der effektive Zeitaufwand betrug dann nicht mehr als zwei Wochentage.</p>"},{"location":"instructor/teaching_german/#aufbau","title":"Aufbau","text":""},{"location":"instructor/teaching_german/#grundidee","title":"Grundidee","text":"<p>Das Algorithmic Battle hat in seiner urspr\u00fcnglichen Gestaltung als Ziel, Studierenden eine praktische Auseinandersetzung mit sonst theoretischem Vorlesungsstoff zu bieten. Im Informatikstudium ist die Komplexit\u00e4tstheorie ein wichtiger Baustein: Sie besagt, dass wir f\u00fcr viele Probleme nicht erwarten d\u00fcrfen, schnelle, korrekte und allgemeing\u00fcltige Algorithmen finden zu k\u00f6nnen.</p> <p>Dabei wird oft vernachl\u00e4ssigt, dass diese schweren Probleme in der Praxis dennoch gel\u00f6st werden m\u00fcssen und tats\u00e4chlich auch gel\u00f6st werden. Gerade durch den Boom von sogenannten MIP-Solvern wie Gurobi, CPLEX und Konsorten werden praktische Optimierungsprobleme teilweise rasend schnell gel\u00f6st.</p> <p>Dies liegt darin begr\u00fcndet, dass ein Problem als Sammlung von allen m\u00f6glichen Instanzen zwar schwer beherrschbar ist, mitunter aber viele Teilmengen dieser Instanzen trotzdem sehr schnell korrekt l\u00f6sbar sind, wie es bei praktischen Instanzen oft der Fall zu sein scheint.</p>"},{"location":"instructor/teaching_german/#lernziele","title":"Lernziele","text":"<p>Der Fokus des Praktikums liegt daher darin, Studierende beide Perspektiven des L\u00f6sungsprozesses einnehmen zu lassen. Sie sollen im Kern zwei Fragen beantworten:</p> <ul> <li>Was sind \"schwere Instanzen\" eines Problems?</li> <li>Wie schreibe ich Algorithmen, die in den meisten F\u00e4llen schnell und korrekt sind?</li> </ul> <p>Dies bedeutet, dass die Studierenden sowohl einen <code>generator</code> f\u00fcr die Erstellung schwerer Instanzen (f\u00fcr eine gegebene Instanzgr\u00f6\u00dfe) schreiben m\u00fcssen, als auch einen <code>solver</code>, der eine Instanz entgegennimmt und innerhalb eines Zeitlimits eine m\u00f6glichst gute L\u00f6sung ausgibt.</p> <p>Jeder <code>generator</code> eines Teams l\u00e4uft dann gegen jeden <code>solver</code> eines Teams. Im klassischen Setting ist dann die Frage, bis zu welcher Instanzgr\u00f6\u00dfe der Solver des einen Teams noch die Instanzen des anderen Teams l\u00f6sen kann. Bewertet wird dann, wie viel besser die Studierenden sind: Die h\u00f6chste noch gel\u00f6ste Instanzgr\u00f6\u00dfe z\u00e4hlt und wird mit der h\u00f6chsten noch gel\u00f6sten Instanzgr\u00f6\u00dfe des anderen Teams verglichen und entsprechend Punkte vergeben. Um diesen relativen Abstand zu maximieren, ist es also wichtig, dass einerseits der eigene <code>generator</code> stark ist, damit das gegnerische Team nicht sehr weit mit ihrem <code>solver</code> kommen. Es ist aber genauso wichtig, dass der eigene <code>solver</code> stark ist, um \u00fcberhaupt die Instanzen des anderen Teams m\u00f6glichst lange l\u00f6sen zu k\u00f6nnen.</p> <p>Besonders attraktiv f\u00fcr den Lernprozess ist hierbei, dass wir keinerlei Einschr\u00e4nkungen vorgeben, welche externe Software die Studierenden f\u00fcr das Erreichen dieser Ziele verwenden (solange es keine lizenzrechtlichen Probleme o.\u00c4. gibt). Da alle Software in Dockercontainern l\u00e4uft und man sich auch im echten Leben nicht k\u00fcnstlich gei\u00dfelt, sind die Studierenden angehalten, m\u00f6glichst breit zu recherchieren, um Publikationen, Beschreibungen von Algorithmen oder direkt ganze Tools oder Libraries zu finden und zu verwenden. Es gibt lediglich folgende Einschr\u00e4nkungen, die wir forcieren:</p> <ul> <li>Nur Software verwenden, deren Lizenz es erlaubt.</li> <li>Kein Aussp\u00e4hen oder Absprechen zwischen den Teams.</li> <li>Keine Exploits unserer Software ausnutzen (siehe auch Bug Bounties).</li> </ul> <p>Den Code f\u00fcr beides lie\u00dfen wir die Studierenden in einem f\u00fcr uns Betreuer einsehbaren Versionsverwaltungssystem (in unserem Fall gitlab) entwickeln. Damit m\u00fcssen sich die Studierenden als Softwareteam koordinieren und organisieren, sei es \u00fcber einfache Absprachen, Issues oder aggressives Branching mit anschlie\u00dfenden Pull Requests. Au\u00dferdem l\u00e4sst sich bereits w\u00e4hrend des Praktikums gut feststellen, ob Einzelpersonen nur unzureichende Beitr\u00e4ge liefern und man entsprechend fr\u00fchzeitig gegensteuern muss.</p> <p>Dar\u00fcber hinaus ist der gesamte Entwicklungsprozess zu dokumentieren. Jeder recherchierte Ansatz, jede Implementation einer Idee, egal ob gegl\u00fcckt oder nicht, ist festzuhalten. Dazu haben wir sehr erfolgreich das Prinzip verfolgt, dass jede Person einmal im Semester f\u00fcr die Dokumentation verantwortlich ist. Die anderen Personen m\u00fcssen dann dieser Person eigenst\u00e4ndig zutragen, was sie gemacht haben. Die dokumentierende Person ist also nicht verantwortlich f\u00fcr das Einholen von Informationen. Im Gegenteil: Wer nichts meldet, der steht am Ende nicht in der Dokumentation und hat damit - so m\u00fcssen die Betreuenden es annehmen - auch nichts getan.</p>"},{"location":"instructor/teaching_german/#beispiel-fur-den-aufbau-eines-semesters","title":"Beispiel f\u00fcr den Aufbau eines Semesters","text":"<p>Wir beschreiben im Folgenden den Aufbau eines typischen Universit\u00e4tssemesters an der RWTH Aachen University. Dieser Aufbau ist selbstverst\u00e4ndlich nicht bindend und stellt ein Format dar, welches wir seit mehreren Jahren mit sehr positiver R\u00fcckmeldung der Studierenden durchf\u00fchren.</p> <p>In Bezug auf unser Praktikum beginnt jedes Semester bei uns gleich. Kurz vor bzw. zu Beginn der Vorlesungszeit veranstalten wir ein Kickofftreffen, in dem wir die Studierenden \u00fcber das Format und den Aufbau des Praktikums informieren. Anschlie\u00dfend finden wir gemeinsam einen regelm\u00e4\u00dfigen Wochentermin und teilen die Studierenden in 6er-Gruppen auf. Dabei achten wir stark darauf, dass sich in diesen Gruppen maximal 3 Personen bereits kennen, um m\u00f6glichen Ausgrenzungen entgegenzuwirken.</p> <p>Die erste Aufgabe ist stets dieselbe, wir verwenden die <code>pairsum</code>-Aufgabe aus dem <code>algobattle-problems</code>-Repository; die dort erreichten Punkte flie\u00dfen noch nicht in die Gesamtwertung. Diese Aufgabe dient dazu, sich mit einer Entwicklungsumgebung, unserer Software und dem Format der Battles vertraut zu machen. Eine Dokumentation muss hier allerdings bereits erstellt werden. Der Ablauf entspricht dem aller k\u00fcnftigen Aufgaben: Wir fangen nach einer Woche an, t\u00e4glich ein Battle mit dem aktuellen Stand der Software der Studierenden durchzuf\u00fchren. So wird regelm\u00e4\u00dfig reflektiert, wie gut oder schlecht sich der eigene Code gegen\u00fcber dem der anderen Gruppen schl\u00e4gt.</p> <p>An das Ende dieser Aufgabe sowie an das Ende jeder folgenden Aufgabe schlie\u00dft sich ein Abschlusstreffen an. In diesem verlangen wir von zwei in diesem Meeting ausgew\u00fcrfelten Personen, dass sie die zentralen Ideen ihrer <code>solver</code> und <code>generator</code> dem Rest der Studierenden vorstellen. Wir erwarten, dass jede Person \u00fcber die Software und den Fortschritt wie \u00fcber die Bearbeitungszeit informiert sind, was wir durch die zuf\u00e4llige Auswahl der Vortragenden zu forcieren versuchen.</p> <p>Anschlie\u00dfend stellen wir die Gesamtergebnisse der Battles vor, besprechen m\u00f6gliche Bug Bounties und diskutieren in einer offenen Runde, was die Studierenden gelernt haben. Zum Schluss wird der Inhalt der n\u00e4chsten Aufgabe vorgestellt.</p> <p>Der Bearbeitungszyklus ist dann immer gleich: Nach Erhalt der Aufgabenbeschreibung lassen wir die Gruppen f\u00fcr eine Woche lang recherchieren und implementieren. Nach dieser Woche treffen wir uns mit jeder Gruppe separat. Darin besprechen wir die gefundenen Ans\u00e4tze, Ideen und Probleme, die sich eventuell bereits zu diesem Zeitpunkt zeigen. Nach diesem Treffen starten n\u00e4chtliche Battles, wobei das erste dieser Battles unbewertet ist, um noch m\u00f6gliche Softwarebugs auszumerzen. Danach sind alle Battles bepunktet, bis zum n\u00e4chsten Abschlusstreffen.</p> <p>In einem typischen Semester ist somit Zeit f\u00fcr 6-7 Aufgaben nach diesem Format (die <code>pairsum</code>-Aufgabe bereits eingerechnet). Wir empfehlen sehr, bei 6 Aufgaben zu bleiben und die freiwerdenen Wochen als Puffer f\u00fcr andere Aufgaben zu verwenden. Einerseits reduziert sich so der Arbeitsdruck f\u00fcr die Studierenden etwas, andererseits deckt sich dann die Anzahl der anzufertigenden Dokumentationen mit den Gruppengr\u00f6\u00dfen.</p> <p>Bez\u00fcglich des Lernziels der einzelnen Aufgaben arbeiten wir momentan nach grob nach folgendem Schema:</p> <ol> <li><code>pairsum</code> zum Aufw\u00e4rmen.</li> <li>Klassisches NP-vollst\u00e4ndiges Problem um Recherche attraktiv zu machen.</li> <li>Problem in P f\u00fcr starke Optimierungen von Datenstrukturen und Algorithmen.</li> <li>Approximationsproblem mit Approximationsrate, die nicht polynomiell erreichbar ist (z.B. 1.5 an Vertex Cover).</li> <li>Nicht-klassisches NP-vollst\u00e4ndiges Problem, um MIP-Solver attraktiv zu machen.</li> <li>Wildcard, z.B. Problem mit stark beschr\u00e4nktem Speicher, Problem in FPT, ...</li> </ol> <p>Nach der sechsten Aufgabe endet das Praktikum bei uns mit der Vorlesungszeit. Anschlie\u00dfend folgt die Bewertung und Notengebung.</p>"},{"location":"instructor/teaching_german/#bewertung-der-studierenden","title":"Bewertung der Studierenden","text":"<p>Falls man die Teilnehmer des Praktikums am Ende benoten m\u00f6chte, geben wir hiermit noch ein paar Anregungen, worauf diese Bewertung basieren k\u00f6nnte. Wir pr\u00fcfen die folgenden Punkte meist schon einmal in der Mitte des Semesters, um Einzelpersonen zu unterst\u00fctzen, welche in unseren Augen abgeh\u00e4ngt wurden.</p>"},{"location":"instructor/teaching_german/#qualitat-der-software","title":"Qualit\u00e4t der Software","text":"<p>Durch die Qualit\u00e4t der von den Studierenden erstellten Software ergibt sich ein Voreindruck f\u00fcr die Notengebung. Die zentrale Frage hier lautet: Wie viel Aufwand ist in die Erarbeitung der Software \u00fcber das Semester hinweg geflossen? Eine Gruppe, die zwar viele Battles verliert, dabei aber viele verschiedene Ans\u00e4tze recherchiert und ausprobiert hat, ist unserer Meinung nach nicht schlecht zu bewerten, nur weil die Ergebnisse in den Battles nicht sehr gut sind.</p>"},{"location":"instructor/teaching_german/#dokumentation","title":"Dokumentation","text":"<p>Hier ist die f\u00fcr die Dokumentation zust\u00e4ndige Person nat\u00fcrlich davon abh\u00e4ngig, was und in welcher Qualit\u00e4t die anderen Gruppenmitglieder ihr \u00fcber die eigene Arbeit berichtet haben. Daher kann man anhand der Dokumentation sehen, welche Gruppenmitglieder in welchen Wochen Arbeit geleistet haben. Wir werten Personen ab, welche \u00fcber das ganze Semester hinweg nur eine Art von Arbeit geleistet haben, z.B. nur implementiert oder nur recherchiert haben.</p>"},{"location":"instructor/teaching_german/#vortrage","title":"Vortr\u00e4ge","text":"<p>Falls eine Person offensichtlich unvorbereitet ist, f\u00fchrt dies zur Abwertung. Anhand der Vortr\u00e4ge l\u00e4sst sich auch recht gut feststellen, ob die Vortragenden wissen, was in der Gruppenarbeit geleistet wurde.</p>"},{"location":"instructor/teaching_german/#implementationsarbeit","title":"Implementationsarbeit","text":"<p>Da es sich um ein Softwareprojektpraktikum handelt, lassen wir niemanden bestehen, der nicht an Implementierungsarbeit beteiligt war, sei es durch Pair Programming oder eigenst\u00e4ndige Implementationen. Dies l\u00e4sst sich am einfachsten \u00fcber die Commit History der Gruppe feststellen.</p>"},{"location":"instructor/teaching_german/#weitere-anwendungsmoglichkeiten-der-software","title":"Weitere Anwendungsm\u00f6glichkeiten der Software","text":"<p>Wir m\u00f6chten an dieser Stelle betonen, dass wir das <code>algobattle</code>-Tool bewusst sehr modular geschrieben haben, was die Art der Aufgaben und die eigentliche Durchf\u00fchrung der Battles betrifft. W\u00e4hrend wir als Autoren einen sehr theoriegepr\u00e4gten Hintergrund haben und uns daher haupts\u00e4chlich f\u00fcr Probleme interessieren, welche der Theorie nahestehen, spricht nichts dagegen, andere Typen von Aufgaben und Battles durchzuf\u00fchren.</p>"},{"location":"instructor/teaching_german/#andere-arten-von-battles","title":"Andere Arten von Battles","text":"<p>Wir sind in der bisherigen Beschreibung davon ausgegangen, dass ein Battle immer so durchgef\u00fchrt wird, dass sich <code>generator</code> und <code>solver</code> zu immer gr\u00f6\u00dferen Instanzgr\u00f6\u00dfen duellieren. Die Bepunktung ist dann davon abh\u00e4ngig, wie gro\u00df der relative Unterschied zwischen den gr\u00f6\u00dften noch gel\u00f6sten Instanzen ist. Dies ist allerdings nur die Beschreibung eines <code>battle type</code>s, dem <code>iterated</code>-type.</p> <p>Ein von uns mitgelieferter, alternativer <code>battle type</code> ist der <code>averaged</code>-type, in dem nur Instanzen der gleichen Instanzgr\u00f6\u00dfe \u00fcber eine Anzahl an Wiederholungen hinweg zu l\u00f6sen sind. Die Bewertung erfolgt dann \u00fcber die durchschnittliche L\u00f6sungsqualit\u00e4t eines Solvers.</p> <p>Prinzipiell lassen sich alle Arten von Abstraktionen einzelner Fights zwischen <code>generator</code> und <code>solver</code> implementieren.</p>"},{"location":"instructor/teaching_german/#andere-arten-von-aufgaben","title":"Andere Arten von Aufgaben","text":"<p>In den meisten unserer Beispielaufgaben sind Input und Output von <code>generator</code> und <code>solver</code> einfache json-Dateien, welche Text enthalten. Da die Schnittstelle allerdings beliebige Dateien- und Ordnerstrukturen zul\u00e4sst, spricht nichts dagegen, etwa Multimediainhalte wie Musik oder Bilder als Ein- und Ausgaben der <code>generator</code> und <code>solver</code> zu spezifizieren.</p>"},{"location":"instructor/teaching_german/#sonstiges","title":"Sonstiges","text":""},{"location":"instructor/teaching_german/#bug-bounties","title":"Bug Bounties","text":"<p>Wir ermutigen unsere Studierenden, sowohl unser <code>algobattle</code>-Framework als auch die von uns geschriebenen Aufgaben m\u00f6glichst kaputtzumachen. Konkret interessieren wir uns f\u00fcr Eingaben, mit denen Studierende in der Lage sind, unseren Code zu crashen, die <code>solver</code> bzw. <code>generator</code> der anderen Teams zu crashen oder auszunutzen, bis hin zu M\u00f6glichkeiten, \u00fcber das Ausf\u00fchren der Battles an die docker-images der anderen Teams zu gelangen. Wie bereits erw\u00e4hnt, verlangen wir, dass diese Exploits nicht w\u00e4hrend regul\u00e4rer Battles genutzt werden, um eine bessere Punktzahl zu erreichen. Daf\u00fcr belohnen wir das Auffinden solcher Bugs mit Bonuspunkten: Die erste Gruppe, die uns auf einen reproduzierbaren Fehler hinweist, erh\u00e4lt zus\u00e4tzliche Punkte in Abh\u00e4ngigkeit davon, wie gravierend der Fehler ist.</p> <p>Der gro\u00dfe Vorteil dieses Verfahrens ist, dass wir die nat\u00fcrliche Neugier, Systeme zu erkunden, gesteuert belohnen k\u00f6nnen und wir weitere Testcases f\u00fcr unseren eigenen Code erhalten. Gleichzeitig k\u00f6nnen wir die Bem\u00fchungen der Studierenden belohnen.</p>"},{"location":"instructor/teaching_german/#bekannte-fallstricke","title":"Bekannte Fallstricke","text":"<p>Unserer Erfahrung nach stellen Studierende irgendwann fest, dass MIP-Solver existieren. Diese sind f\u00fcr viele Aufgabenstellungen Gift, da sich diese schnell einschleifen und als Allzweckwaffe genutzt werden. Wir empfehlen daher grunds\u00e4tzlich, den Aufgabenpool so zu gestalten, dass das wiederholte Verwenden der gleichen Software unattraktiv wird. Im Falle von MIP-Solvern hilft es bereits, den verf\u00fcgbaren Arbeitsspeicher einzuschr\u00e4nken, da diese meist sehr speicherintensiv arbeiten.</p>"},{"location":"instructor/teaching_german/#weitere-ressourcen","title":"Weitere Ressourcen","text":"<p>Das Algobattle-Framework (Github) Sammlung von Problemen f\u00fcr Algobattle (Github) Webframework f\u00fcr Algobattle (Github) Technische Dokumentation</p>"},{"location":"instructor/problem/advanced/","title":"Advanced Features","text":"<p>This page is a loose collection of various more advanced features of the problem creation process.</p>"},{"location":"instructor/problem/advanced/#submodels","title":"Submodels","text":"<p>So far we've just used tuples to group multiple pieces of data together. For example, we defined an edge as just a tuple of two vertices. This works great for very simple types when it's clear what each element of the tuple means, but can become very confusing quickly. Let's say we want to define a problem where rectangles are placed in a 2D coordinate system. These are then defined by four integers: width, height, and x and y position. We could now define the instances like this</p> <pre><code>class Instance(InstanceModel):\n\n    rectangles: list[tuple[int, int, int, int]]\n</code></pre> <p>but we, and more importantly our students, will then have to always remember the order we put those numbers in. To prevent bugs caused by this we can also define a helper class that inherits from <code>BaseModel</code> in <code>algobattle.util</code>. This will then not have the instance or solution specific stuff added, but will also allow us to create json validation specifications just like in those classes.</p> <pre><code>from algobattle.util import BaseModel\n\n\nclass Rectangle(BaseModel):\n\n    x: int\n    y: int\n    width: int\n    height: int\n\n\nclass Instance(InstanceModel):\n\n    rectangles: list[Rectangle]\n</code></pre> <p>Warning</p> <p>The Pydantic package also exports a class called <code>BaseModel</code> which offers similar functionality. Always inherit from the class Algobattle provides since it includes additional settings that are important for everything to function correctly.</p> <p>Pydantic then expects a json object at the places where you use these types with keys and values matching the attributes found in the class. For example, a valid instance json file for the above class can look like this:</p> instance.json<pre><code>{\n    \"rectanlges\": [\n        {\n            \"x\": 3,\n            \"y\": 2,\n            \"width\": 5,\n            \"height\": 2\n        },\n        {\n            \"x\": 0,\n            \"height\": 17\n            \"width\": 5,\n            \"y\": -2,\n        }\n    ]\n}\n</code></pre>"},{"location":"instructor/problem/advanced/#external-dependencies","title":"External Dependencies","text":"<p>You may want to import some additional python libraries to use in your problem file, such as networkx when implementing a more complicated graph problem. To do this we not only have to add the import statement in the <code>problen.py</code> file, but also include it in the list of dependencies in the project config.</p> algobattle.toml<pre><code>[match]\nproblem = \"Some Graph Problem\"\n\n[problem]\ndependencies = [\n    \"networkx\",\n]\n</code></pre> <p>When initializing the project Algobattle will then make sure that the needed libraries are installed on the user's machine.</p>"},{"location":"instructor/problem/advanced/#hiding-parts-of-the-instance","title":"Hiding Parts of the Instance","text":"<p>Sometimes we want the generator to give us some data we need to verify the instance, but don't want the solver to see this. For example, consider the problem of finding the longest path in a graph with a vertex cover (1) of a specific size. The best way to verify that the instance graph actually contains such a vertex cover is to have it be part of the instance data. But we want the solver to only have access to the information that it exists, not which exact vertices are in it.</p> <ol> <li>A vertex cover is a subset of vertices such that all other vertices in the graph have an edge to a vertex in it.</li> </ol> <p>We can use this using the <code>Field</code> construct from Pydantic. It is a simple marker object that lets us configure various properties of specific fields. One of these settings is the <code>exclude</code> key, which tells Pydantic to exclude this field when serializing the object into json. It will still be parsed and validated normally when reading json data and creating the Python object. We can use it either as the default value of the attribute, or as <code>Annotated[...]</code> metadata.</p> <p>Example</p> <p>In this class</p> <pre><code>from pydantic import Field\n\nclass Instance(InstanceModel):\n    \"\"\"An instance of the Some Example problem.\"\"\"\n\n    normal_attribute: int\n    hidden: float = Field(exclude=True)\n    also_hidden: Annotated[str, Field(exclude=True)]\n</code></pre> <p>the first attribute <code>normal_attribute</code> will be the only that is included in the output that the solver sees. All three attributes are required to be in the instance data the generator creates and will be available on the Python object.</p> <p>Tip</p> <p>The <code>Field</code> specifier lets you do many more things than this! Read the excellently written Pydantic documentation to see more use cases.</p>"},{"location":"instructor/problem/advanced/#using-the-algobattle-graph-classes","title":"Using the Algobattle Graph Classes","text":"<p>Since many problems use graphs as the foundation of their instances we provide several utility classes to make working with these easier. These classes are <code>DirectedGraph</code>, <code>UndirectedGraph</code>, <code>EdgeWeights</code>, and <code>VertexWeights</code>. Using these classes also ensures that multiple graph problems use the same formats and students won't have to worry about changing any boilerplate code.</p> <p>The easiest use case is to just inherit from <code>DirectedGraph</code> or <code>UndirectedGraph</code> instead of <code>InstanceModel</code>. Your instance class will then behave the same as if it also included the <code>num_vertices</code> and <code>edges</code> keys which hold a single number specifying the number of vertices in the graph (numbered <code>0</code> through <code>n-1</code>) and a list of tuples of such vertices respectively. They will also ensure proper validation, with <code>DirectedGraph</code> accepting any graph and <code>UndirectedGraph</code> accepting only those that contain no self loops and where edges are interpreted as being directionless. Both graph's size is the number of vertices in it.</p> <p>Reachability</p> <p>An implementation of the Reachability (1) problem's instance class might look something like this:</p> <ol> <li>Given a graph and two vertices in it, is there a path between them?</li> </ol> <pre><code>class Instance(DirectedGraph):\n    \"\"\"An instance of a Reachability problem.\"\"\"\n\n    start: Vertex\n    end: Vertex\n</code></pre> <p>Which is equivalent to</p> <pre><code>class Instance(InstanceModel):\n    \"\"\"An instance of a Reachability problem.\"\"\"\n\n    num_vertices: u64\n    edges: Annotated[list[tuple[SizeIndex, SizeIndex]], UniqueItems]\n\n    start: Vertex\n    end: Vertex\n\n    @property\n    def size(self) -&gt; int:\n        \"\"\"A graph's size is the number of vertices in it.\"\"\"\n        return self.num_vertices\n</code></pre> <p>Associated Annotation Types</p> <p>As you can see in the example above, we also provide several types that are useful in type annotations of graph problems such as <code>Vertex</code>, <code>Edge</code>, or <code>Path</code>. How these function is explained in more detail in the advanced annotations section.</p> <p>If you want the problem instance to also contain additional information associated with each vertex and/or each edge you can use the <code>VertexWeights</code> and <code>EdgeWeights</code> mix ins. These are added as an additional parent class and must be indexed with the type of the weights you want to use.</p> <p>Labelled Vertices and Weighted Edges</p> <p>Say your problem wants to label each vertex with the name of a city and each edge with the distance it represents. This would be done like this:</p> <pre><code>class Instance(DirectedGraph, VertexWeights[str], EdgeWeights[float]):\n\n    ...\n</code></pre> <p>Both are encoded as lists of the weights where the nth entry corresponds to the weight of the nth vertex or edge. I.e. the above is equivalent to</p> <pre><code>class Instance(DirectedGraph):\n\n    vertex_weights: Annotated[list[str], SizeLen]\n    edge_weights: Annotated[list[float], EdgeLen]\n\n    ...\n</code></pre> <p>Tip</p> <p>These classes also contain some utility methods to easily perform common graph operations. For example, <code>UndirectedGraph.edge_set</code> contains all edges in both directions, and the <code>neighbors</code> methods lets you quickly access a vertex's neighbours.</p>"},{"location":"instructor/problem/advanced/#comparing-floats","title":"Comparing Floats","text":"<p>Abstract</p> <p>This is a somewhat esoteric section that is not strictly needed to use Algobattle. If you're interested in the details this is perfect for you, but the important takeaway for everyone is that we recommend everyone to use the <code>LaxComp</code> class or <code>lax_comp</code> function when working with floats.</p> <p>We use floats to represent real numbers, but these are limited to a certain precision (64 bits). This can lead to annoying corner cases, finicky bugs, and teams being encouraged to put more energy into running into these than actually solving the problem. For example, the equality <code>0.1 + 0.1 + 0.1 == 0.3</code> does not actually hold when using floats. If a problem instance makes use of floats students can then use these inaccuracies to specifically craft instances that can only be solved when carefully keeping track of your exact arithmetical operations and the inaccuracies they introduce. Most of the time this is not actually what we want the focus of a problem to be on, so we'd rather students just ignore these corner cases when working with floats and treat them as close to actual real numbers as possible.</p> <p>Normally we do this by never comparing strict equality between float values and instead just checking if they are close \"enough\" for our use case. This is not enough for us since teams would then just create corner case instances that rely on the exact error bound we use. The solution then is to allow the solving team to introduce bigger errors than the generating team. That means that the generating team cannot create instances right at the edge of precision errors since the solver's solutions will be validated with bigger allowable errors.</p> <p>This sounds complicated, but we've already implemented the hard bits in a utility class and function for you. All you need to keep in mind is that whenever you would be doing a comparison involving equality (<code>==</code>, <code>&lt;=</code>, or <code>&gt;=</code>) to instead use <code>LaxComp</code> or <code>lax_comp</code> from the <code>algobattle.types</code> module. The first acts as a wrapper that will then safely perform these comparisons and the second performs the comparison immediately.</p> <p>Example</p> <p>Here's several usage examples assuming the <code>role</code> variable contains the role of the team we're currently validating something for:</p> <ul> <li><code>LaxComp(0.1 + 0.1 + 0.1, role) == 0.3</code></li> <li><code>LaxComp(0.2, role) &lt;= 0.3</code></li> <li><code>lax_comp(0.1 + 0.1 + 0.1, \"==\", 0.3 role)</code></li> <li><code>lax_comp(0.300001, \"&gt;=\", 0.3 role)</code></li> </ul> <p>The margins for error these introduce are absolutely tiny for all normal applications, about 10<sup>14</sup> times smaller than the values that are being compared, so they can be safely ignored by the application logic. But they are big enough to cover any normal errors introduces by float arithmetic and thus make it safe to naively use them as though they represent actual real numbers.</p>"},{"location":"instructor/problem/advanced/#problems-without-witnesses","title":"Problems Without Witnesses","text":"<p>Most problems require the generator to not only create an instance, but also provide a solution for it. But we can also create problems that expect only the instance in the generator's output. To do this, just set the corresponding argument in the Problem constructor to <code>False</code>.</p> <pre><code>Problem(\n    name=\"Instance Only Problem\",\n    min_size=17,\n    instance_cls=Instance,\n    solution_cls=Solution,\n    with_solution=False,\n)\n</code></pre>"},{"location":"instructor/problem/advanced/#custom-scoring-functions","title":"Custom Scoring Functions","text":"<p>In a match each fight (one execution of the generator followed by the other team's solver) is assigned a score. This is a number in [0, 1] that indicates how well the solver did. Normally it is computed by just dividing the solver's solution score by the generator's (or vice versa, if the goal is to minimize the score). This matches the usual notion of approximation ratios.</p> <p>Example</p> <p>When using the Independent Set (1) problem the generator created a solution with an independent set of size 5. The solver found one of size 4. Since the goal here is to maximize the solution size the score of this fight would be  <code>0.8</code>. But for Vertex Cover (2) the objective is to find the smallest vertex cover, so if the solver found one of size 20 and the generator of size 17, the overall score would be roughly <code>1.18</code>.</p> <ol> <li>Given a graph, find the biggest subset of its vertices that have no edge between any pair of them.</li> <li>Given a graph, find the smalles subset of vertices such that every other vertex has an edge to one in that set.</li> </ol> <p>But this isn't always what we want to do. Consider the problem of finding the three shortest paths between two given vertices in a graph, formalized like this:</p> <pre><code>class Instance(DirectedGraph):\n    \"\"\"Instances of the 3 Shortest Paths problem.\"\"\"\n\n    start: Vertex\n    end: Vertex\n\n\nclass Solution(SolutionModel):\n    \"\"\"Solutions of the 3 Shortest Paths problem.\"\"\"\n\n    paths: tuple[Path, Path, Path] # (2)!\n\n    @minimize\n    def score(self, role: Role) -&gt; float:\n        ...\n\nProblem(\n    name=\"3 Shortest Paths\",\n    min_size=5,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <ol> <li>For clarity, we omit the imports here.</li> <li>You'd need additional validation logic here, but we now want to focus on just the score function.</li> </ol> <p>How do we best implement the <code>score</code> function? We could just add the lengths of all the paths, or just pick the length of the shortest or longest one. But really, what we want is for the final score to not just compare a single number for each solution, but each path individually.</p> <p>We can achieve this by providing a custom scoring function to the Problem constructor. This just is a function that directly receives the instance and both solutions and returns a float in [0, 1]. When we do this, we can drop the <code>score</code> method in the Solution class entirely.</p> <pre><code>class Instance(DirectedGraph):\n    \"\"\"Instances of the 3 Shortest Paths problem.\"\"\"\n\n    start: Vertex\n    end: Vertex\n\n\nclass Solution(SolutionModel):\n    \"\"\"Solutions of the 3 Shortest Paths problem.\"\"\"\n\n    paths: tuple[Path, Path, Path]\n\n\ndef compare_each_path(\n    instance: Instance,\n    generator_solution: Solution,\n    solver_solution: Solution\n) -&gt; float:\n    gen_lens = sorted(len(path) for path in generator_solution.paths) # (1)!\n    sol_lens = sorted(len(path) for path in solver_solution.paths)\n    ratios = [len(gen) / len(sol) for gen, sol in zip(gen_lens, sol_lens)] # (2)!\n    ratios = [min(1, max(0, num)) for num in ratios] # (3)!\n    return sum(ratios) / 3 # (4)!\n\nProblem(\n    name=\"3 Shortest Paths\",\n    min_size=5,\n    instance_cls=Instance,\n    solution_cls=Solution,\n    score_function=compare_each_path,\n)\n</code></pre> <ol> <li>Get each path's length and sort them.</li> <li>Compute the ratio of each corresponding pair of paths.</li> <li>Clamp the ratios to be in [0, 1].</li> <li>Return the average of the ratios.</li> </ol>"},{"location":"instructor/problem/advanced/#test-instances","title":"Test Instances","text":"<p>When running <code>algobattle test</code> the CLI tool first tries to build and run the generator and then the solver. But in order to be able to test run the solver, we need to provide it with an input instance. This means that if your generator does not run successfully you also cannot test your solver. To prevent this issue, we can provide a simple test instance when defining the problem. It will then be passed to the solver instead.</p> <pre><code>Problem(\n    name=\"Pairsum\",\n    min_size=4,\n    instance_cls=Instance,\n    solution_cls=Solution,\n    test_instance=Instance(numbers=[1, 2, 3, 4]),\n)\n</code></pre> <p>Make sure to pass a valid instance</p> <p>This instance will not undergo the usual validation step and does not come with a solution. This means you can accidentally provide a test instance which can't actually be solved correctly.</p>"},{"location":"instructor/problem/annotations/","title":"Advanced Type Annotations","text":"<p>We've already seen how you can use type annotations to declare what shape the I/O data should have and perform basic validation. This page will go over more advanced usages of type annotations that Algobattle and Pydantic provide for us.</p> <p>Note</p> <p>While validation via type annotations can be very useful and much faster than plain python methods, they are not necessary for most problems. Everything covered here can also be done with validation methods (<code>validate_instance</code> / <code>validate_solution</code>). If you're more comfortable with those rather than type annotations, feel free to use them instead.</p>"},{"location":"instructor/problem/annotations/#type-aliases","title":"Type Aliases","text":"<p>Note</p> <p>This section is not specific to Algobattle and just covers general Python techniques, feel free to skip it if you're already familiar with it.</p> <p>When using complicated types our annotations can get very complicated quickly. We can simplify the code by defining type aliases, which basically just are variables but for types. For example, consider this class</p> <pre><code>class Example(InstanceModel):\n\n    edges: list[tuple[int, int]]\n    matchings: list[set[tuple[int, int]]]\n</code></pre> <p>Its attributes are rather terse and hard to understand what exactly a list of sets of tuples of integers is supposed to represent. This can be simplified by creating a couple of type aliases. The syntax used depends a bit on your Python version and how explicit you want (and have) to be, but they all do the same thing.</p> 3.11 implicit3.11 explicit&gt;= 3.12 <pre><code>Edge = tuple[int, int]\nMatching = set[Edge]\n\nclass Example(InstanceModel):\n\n    edges: list[Edge]\n    matchings: list[Matching]\n</code></pre> <pre><code>Edge: TypeAlias = tuple[int, int]\nMatching: TypeAlias = set[Edge]\n\nclass Example(InstanceModel):\n\n    edges: list[Edge]\n    matchings: list[Matching]\n</code></pre> <pre><code>type Edge = tuple[int, int]\ntype Matching = set[Edge]\n\nclass Example(InstanceModel):\n\n    edges: list[Edge]\n    matchings: list[Matching]\n</code></pre> <p>This is particularly useful if you want to reuse a type definition, or one is very long. But it's also great to tell others reading your code what you actually intended each piece to mean by just giving things more descriptive names. For example, the <code>Vertex</code> type in <code>algobattle.types</code> actually just is a descriptive alias for the more general <code>SizeIndex</code>.</p>"},{"location":"instructor/problem/annotations/#forward-references","title":"Forward References","text":"<p>Note</p> <p>This section is not specific to Algobattle and just covers general Python techniques, feel free to skip it if you're already familiar with it.</p> <p>Python files are executed from top to bottom and this also includes type hints. This means that you cannot use types and classes that you define later in a type hint. In practice, this is not something you very often want to do in problem definitions anyway, but it's worth keeping in mind. For example, let's say we want to specify a type which emulates the way paths in a file system work. That is, it can either just be the name of a file, or correspond to folder containing more files and folders. Ideally, we'd want just recursively define it like this:</p> 3.11 implicit3.11 explicit&gt;= 3.12 <pre><code>Path = str | dict[str, Path]\n</code></pre> <pre><code>Path: TypeAlias = str | dict[str, Path]\n</code></pre> <pre><code>type Path = str | dict[str, Path]\n</code></pre> <p>But at the time that the <code>Path</code> on the right-hand side gets evaluated it will be an undefined variable and thus throw an error. We can solve that by wrapping the entire expression in a string. The Python interpreter will then not evaluate the individual variables, but type checkers and Pydantic will still interpret them correctly. The problem then is that if we use the implicit version type checkers think that we just mean some meaningless string and not a type hint. Because of this we actually have to use the explicit version when quoting forward references.</p> 3.11 explicit&gt;= 3.12 <pre><code>Path: TypeAlias = \"str | dict[str, Path]\"\n</code></pre> <pre><code>type Path = \"str | dict[str, Path]\"\n</code></pre> <p>Info</p> <p>The <code>type</code> syntax introduced in 3.12 actually allows you to write this specific example without the quotes. But it only allows for forward references to the type you're defining itself to be unquoted, all other uses of forward references still need to be quoted.</p> <p>You can also use quoted forward references in any other place you'd use a type hint, though for the types used in a problem definition we can usually prevent them altogether by just reordering the code.</p> <pre><code>class Example(InstanceModel):\n\n    some_attr: \"CoolNumber\"\n\nCoolNumber = int\n</code></pre>"},{"location":"instructor/problem/annotations/#annotated-metadata","title":"Annotated Metadata","text":"<p>Type Hints and Annotations</p> <p>Usually type hint and type annotation are used interchangeably, they just refer to the thing after the colon following an attribute name. Since this section also deals with the <code>Annotated[...]</code> type construct we will use type hints here when talking about the general construct to differentiate it from this specific object.</p> <p>In the basic tutorial we've already seen that we can add validation to a field using <code>Annotated[...]</code> metadata. This is a very powerful construct that is heavily used by Algobattle and Pydantic, so we'll take a deeper look at it now. In Python type hints are not only used by linters and type checkers to make sure your code does what you want it to, but can also be examined at runtime. This is how Pydantic (and thus Algobattle) knows what you want the json files to look like, it sees an attribute that's been marked as an <code>int</code>, so it will expect an integer at that place of the json file. This is a really clever method because it will automatically validate the json without us explicitly telling us what it should do, it just gets all the info it needs from the type hints.</p> <p>But sometimes we would want to tell the validator more than we can express in a type hint. For example, we might want to only allow positive numbers, but Python does not have a type specifically for that. In earlier versions of Pydantic you would then specify this using its <code>Field</code> specifier like this</p> <pre><code>class Example(InstanceModel):\n\n    positive_int: int = Field(gt=0)\n</code></pre> <p>where the <code>gt</code> key tells Pydantic that it should validate this field as being greater than 0. This works great when you want to have this behaviour on only a single attribute, but leads to a lot of code duplication when you want it in more places and lets you forget it easily.</p> <p>The idea behind <code>Annotated[...]</code> is that it lets us annotate a Python type with some additional metadata that is irrelevant for type checkers, but tells other tools like Pydantic what they should do. It receives at least two arguments, the first of which must be a type and all the others are arbitrary metadata. This lets easily specify how several fields should be validated with a single <code>Field</code>.</p> <pre><code>PositiveInt = Annotated[int, Field(gt=0)]\n\nclass Example(InstanceModel):\n\n    first: PositiveInt\n    second: PositiveInt\n    third: PositiveInt\n    fourth: PositiveInt\n</code></pre> <p>The Python standard library <code>annotated_types</code> also contains a collection of basic metadata types such as <code>Gt</code>, <code>Ge</code>, <code>Lt</code>, <code>Le</code> that Pydantic will also interpret the same way as a <code>Field</code> with the corresponding key set.</p> <p>Example</p> <p>In this class, all attributes will be validated as an integer between 3 and 17 inclusive.</p> <pre><code>class Example(InstanceModel):\n\n    first: int = Field(ge=3, lt=18)\n    second: Annotated[int, Field(ge=3, lt=18)]\n    third: Annotated[int, Ge(3), Lt(18)]\n    fourth: Annotated[int, Interval(ge=3, lt=18)]\n</code></pre> <p>The <code>algobattle.types</code> module also contains versions of these that behave identically for these use cases. We will later see some capabilities of the Algobattle metadata that neither other option can do, but for most problems you can use whichever method you prefer.</p> <p>The full list of available <code>Field</code> keys can be found in the Pydantic documentation. The available <code>algobattle.types</code> metadata is:</p> <ul> <li><code>Gt</code>, <code>Ge</code>, <code>Lt</code>, <code>Le</code>, and <code>Interval</code>: All specify a constraint on numeric data. The first four provide the     corresponding inequality and <code>Interval</code> lets you group multiple of them together by using its keyword arguments.</li> <li><code>MultipleOf</code>: Specifies that a numeric value is a multiple of some value. E.g. a field using     <code>Annotated[int, MultipleOf(2)]</code> validates that the number in it is even.</li> <li><code>MinLen</code>, <code>MaxLen</code>, and <code>Len</code>: Specifies that some collection's length has the corresponding property. <code>Len</code> again     serves to group the other two into a single object. E.g. <code>Annotated[set, MinLen(17)]</code> allows only sets that have     at least 17 elements.</li> <li><code>UniqueItems</code>: Specifies that a collection contains no duplicate elements. E.g. <code>Annotated[list, UniqueItems]</code>     validates that the list contains no element twice.</li> <li><code>In</code>: Specifies that some value is contained in a collection. E.g. <code>Annotated[int, In({1, 3, 17, 95})]</code>     allows only 1, 3, 17, or 95.</li> <li><code>IndexInto</code>: Specifies that a value is a valid index into some list. E.g.     <code>Annotated[int, IndexInto([\"a\", \"b\", \"c\"])]</code> only allows numbers between 0 and 2.</li> </ul>"},{"location":"instructor/problem/annotations/#attribute-references","title":"Attribute References","text":"<p>The <code>Field</code> specifiers and default metadata options cover a wide variety of use cases, but there are some validations that cannot be done with it. For example, consider the simple problem of finding the biggest number in a list. We can easily validate that the number actually is an element of the list with a <code>validate_solution</code> method like this:</p> <pre><code>class Instance(InstanceModel):\n\n    numbers: list[int]\n\n\nclass Solution(InstanceModel):\n\n    biggest: int\n\n    def validate_solution(self, instance: Instance, role: Role) -&gt; None\n        if self.biggest not in instance.numbers:\n            raise ValidationError(\"The given number is not in the instance\")\n</code></pre> <p>But we cannot do this with the <code>In</code> annotation metadata since there we need to provide the list of items to check against at the time we write the type hint, but we only actually get that list when we validate the solution. The <code>InstanceRef</code> and <code>SolutionRef</code> types in the <code>algobattle.problem</code> module fix this issue. They can be used to tell Algobattle that we do not actually want to compare against a value we have right now, but with a value that we know will be found in the instance or solution. Our example problem then becomes simplified to this.</p> <pre><code>class Instance(InstanceModel):\n\n    numbers: list[int]\n\n\nclass Solution(InstanceModel):\n\n    biggest: Annotated[int, In(InstanceRef.numbers)]\n</code></pre> <p>Warning</p> <p>We cannot statically ensure that the attributes you reference actually exist on the instance or solution. This means that if you e.g. have a typo or change a definition without updating a reference to it, the validation step will throw an error at runtime even though type checkers and linters do not raise any warnings.</p> <p>You also need to make sure you always use these in contexts where the referred to value actually makes sense. For example, referring to an attribute of a solution when validating an instance or self-referential attributes can lead to issues during validation. Especially in the latter case we also cannot guarantee that an error is raised in cases where the references do not behave in the way you intended and instead will just fail silently.</p> Performance <p>Due to implementation details references to the object that is being validated itself (i.e. <code>SolutionRef</code> in a solution or <code>InstanceRef</code> in an instance) will lead to two separate invocations of Pydantic's validation logic. This is perfectly fine in basically all use cases, but when you implement very slow custom logic using it, are validating truly massive amounts of data (several gigabytes at a time) it can lead to slowdowns.</p>"},{"location":"instructor/problem/annotations/#further-pydantic-features","title":"Further Pydantic Features","text":"<p>There are many more Pydantic features that can be very useful when designing problems. They are all explained very well in their official documentation. In particular, annotated validators, model validators, field specifiers, tagged unions, and custom types are very useful for Algobattle problems.</p>"},{"location":"instructor/problem/annotations/#attribute-reference-validators","title":"Attribute Reference Validators","text":"<p>Abstract</p> <p>This is an advanced feature and will make most sense to you if you already understand  annotated validators.</p> <p>Similar to the <code>algobattle.types</code> versions of metadata annotations, <code>algobattle.problem</code> also contains the <code>AttributeReferenceValidator</code>. It functions just like a Pydantic <code>AfterValidator</code> (and is implemented using it), but the validation function also receives the value of a referenced attribute.</p> <p>Example</p> <p>If we wanted to confirm that a line of text is indented by as many spaces as are given in the instance we can create this annotated type:</p> <pre><code>def check_indentation(val: str, indent_level: int) -&gt; str:\n    if not val.startswith(\" \" * indent_level):\n        raise ValueError\n\nIndentedLine = Annotated[str, AttributeReferenceValidator(check_indentation, InstanceRef.indentation)]\n</code></pre>"},{"location":"instructor/problem/annotations/#validation-context","title":"Validation Context","text":"<p>Abstract</p> <p>This is an advanced feature and will make most sense to you if you already understand  validation context.</p> <p>Algobattle will include certain useful data in the validation context. The full list of available keys is:</p> <code>max_size</code> <p>Contains the maximum allowed instance size of the current fight. Will always be present.</p> <p>Tip</p> <p>Keep in mind that this is a different value from the current instance's size. You usually want to use the latter when validating data.</p> <code>role</code> Contains the role of the program whose output is currently being validated. Will always be present. <code>instance</code> Contains the current instance. Optional key. <code>solution</code> Contains the current solution. Optional key. <code>self</code> Contains the object that is currently being validated. Optional key. <p>Warning</p> <p>Due to implementation details we sometimes need to validate data multiple times, with intermediate runs only receiving partial validation contexts. Because of this always make sure that you check if the keys you are accessing are currently present and do not raise an error if they aren't.</p> <p>When using the references to the object that is currently being validated keep in mind that you are accessing an intermediate representation of it that is not guaranteed to have the properties enforced by any other functions that rely on references to the object itself.</p>"},{"location":"instructor/problem/example/","title":"A Complex Example","text":""},{"location":"instructor/problem/example/#the-2d-knapsack-problem","title":"The 2D Knapsack Problem","text":"<p>In this section, we implement the so called 2D Knapsack Problem in its entirety, starting from scratch and ending with a packaged problem archive that can be handed out to others.</p> <p>Usage of Complex Features</p> <p>In parts of this we will use rather advanced features of Algobattle. We recommend looking up the more detailed explanations of anything you're unsure about in its corresponding section.</p> <p>To start, let us define the problem. We are given a two-dimensional, rectangular space with an integer length and width, each of size at least one. We now want to pack a number of smaller rectangles into this space, such that no two  pieces overlap and such that as much space is covered as possible. Each piece may be rotated by 90 degrees.</p> <p>An instance for this problem thus consists of the dimensions of the knapsack as well as a limited set of rectangular items. A solution for this problem then describes where which piece should be placed and if it should be rotated by 90 degrees before being placed. The size of the solution is then the total area covered.</p>"},{"location":"instructor/problem/example/#starting-off","title":"Starting Off","text":"<p>As in the previous section, we use the <code>algobattle</code> cli to construct a dummy problem folder for us. Since we are interested in later writing a dummy generator and dummy solver in python, we let the cli generate a stub of them for us as well as follows:</p> <pre><code>~ algobattle init --new -p \"2D Knapsack\" -l python\nCreated a new problem file at 2D Knapsack/problem.py\nCreated a python generator in 2D Knapsack/generator\nCreated a python solver in 2D Knapsack/solver\nInitialized algobattle project in 2D Knapsack\n</code></pre> <p>We navigate into the newly created folder named <code>2D Knapsack</code>, which has the following file structure:</p> <pre><code>.\n\u2514\u2500 2D Knapsack\n   \u251c\u2500 generator/\n   \u2502  \u251c\u2500 .gitignore\n   \u2502  \u251c\u2500 Dockerfile\n   \u2502  \u251c\u2500 generator.py\n   \u2502  \u2514\u2500 pyproject.toml\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u251c\u2500 .gitignore\n   \u2502  \u251c\u2500 Dockerfile\n   \u2502  \u251c\u2500 pyproject.toml\n   \u2502  \u2514\u2500 solver.py\n   \u251c\u2500 .gitignore\n   \u251c\u2500 problem.py\n   \u2514\u2500 algobattle.toml\n</code></pre> <p>Before we implement anything, we should take the time to specify exactly how an instance should look like. This means specifying the names of each key, their function and which values are legal for each.</p> <p>First of all, an instance should contain the dimensions of the knapsack that is to be packed. For this, we introduce two keys <code>height</code> and <code>width</code>, and would like each to be an integer of value at least one and at most of value <code>2**64</code>.</p> <p>Secondly, we need to describe the items that are to be packed. Each item itself has a height and a width, which should again each be of integer size at least one. As an added restriction, we only want to allow items that are at all able to fit into the knapsack, so as not to allow spamming a solver with items that can never be part of a valid solution. To spare us some headache in the validation step of the instance, we demand each item to fit into the knapsack without any  rotation, as a sort of normalization of the instance.</p> <p>Next, we need to specify the contents of a valid solution file. This is in principle quite simple: We are interested in a list specifying which of  the items of the instance * should be placed in the knapsack * at which position * being rotated or not.</p> <p>We will be lazy and define a dictionary <code>packing</code> that maps the index of items to a three-tuple, as described.</p>"},{"location":"instructor/problem/example/#writing-a-mock-generator-and-solver","title":"Writing a Mock Generator and Solver","text":"<p>Before we start writing any problem code, we write a mock generator and a mock solver. This helps us do plausibility checks while writing the actual problem file and is not required for the finished problem file.</p> <p>We start with filling in the generator.</p> generator/generator.py<pre><code>\"\"\"Main module, will be run as the generator.\"\"\"\nimport json\nfrom pathlib import Path\n\n\nmax_size = int(Path(\"/input/max_size.txt\").read_text())\n\ninstance = {\n    'height': 4,\n    'width': 3,\n    'items': [\n        [1, 3],\n        [4, 3],\n        [3, 3],\n        [3, 2],\n        [1, 3]\n    ]\n}\n\nsolution = {\n    'packing': {\n        0: [0, 0, 'unrotated'],\n        3: [1, 0, 'unrotated'],\n        4: [1, 2, 'rotated']\n    }\n}\n\n\nPath(\"/output/instance.json\").write_text(json.dumps(instance))\nPath(\"/output/solution.json\").write_text(json.dumps(solution))\n</code></pre> <p>We made sure that the solution is not unique for the given instance to make sure that the framework is able to compare two different solutions. We next fill in the solver.</p> generator/solver.py<pre><code>\"\"\"Main module, will be run as the solver.\"\"\"\nimport json\nfrom pathlib import Path\n\n\ninstance = json.loads(Path(\"/input/instance.json\").read_text())\n\nsolution = {\n    'packing': {\n        1: [0, 0, 'rotated']\n    }\n}\n\n\nPath(\"/output/solution.json\").write_text(json.dumps(solution))\n</code></pre> <p>We are now able to immediately test any code that we write.</p>"},{"location":"instructor/problem/example/#handling-instances","title":"Handling Instances","text":"<p>We already know that we expect three keys in any instance: A <code>height</code>, a <code>width</code> and a list of <code>items</code>.</p> <p>Note</p> <p>For brevity, the following code snippets do not include all necessary imports. We provide the complete content of the <code>problem.py</code> at the end of this section.</p> <p>Our first approach uses only very rough type annotations for our expected keys and does a lot of the validation of the instance explicitly.</p> <pre><code>\"\"\"The 2D Knapsack problem module.\"\"\"\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, maximize\nfrom algobattle.util import Role, ValidationError\nfrom algobattle.types import u64\n\n\nclass Instance(InstanceModel):\n    \"\"\"Instances of 2D Knapsack.\"\"\"\n\n    height: u64\n    width: u64\n\n    items: list[u64, u64]\n\n    def validate_instance(self) -&gt; None:\n        super().validate_instance()\n        if self.height &lt; 1 or self.width &lt; 1:\n            raise ValidationError(\"The knapsack is smaller than allowed!\")\n        if any(item[0] &lt; 1 or item[1] &lt; 1 for item in self.items):\n            raise ValidationError(\"An item of the instance is smaller than 1x1!\")\n        if any((item[0] &gt; self.height or item[1] &gt; self.width) for item in self.items):\n            raise ValidationError(\"An item of the instance cannot fit in the knapsack!\")\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.items)\n</code></pre> <p>We can clean this code up by tightening up the annotations a bit. </p> <pre><code>\"\"\"The 2D Knapsack problem module.\"\"\"\nfrom pydantic import Field\nfrom typing import Annotated\n\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, maximize\nfrom algobattle.util import Role, ValidationError\nfrom algobattle.types import u64, Interval, InstanceRef\n\n\nitem_height = Annotated[int, Interval(ge=1, le=InstanceRef.height)]\nitem_width = Annotated[int, Interval(ge=1, le=InstanceRef.width)]\npoint = tuple[item_height, item_width]\n\n\nclass Instance(InstanceModel):\n    \"\"\"Instances of 2D Knapsack.\"\"\"\n\n    height: u64 = Field(ge=1)\n    width: u64 = Field(ge=1)\n\n\n    items: list[point]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.items)\n</code></pre> <p>As you can see, we have moved all explicit checks from the <code>validate_instance</code> method into the annotations. Do note that by using the <code>InstanceRef</code> import, we are able to use the values of some keys to annotate other keys!</p> <p>Note</p> <p>If you are not familiar with pydantics annotations, we recommend using the pydantic documentation as a reference. As you have seen in the previous iteration of the code, they are not essential, but very helpful to reduce code clutter and potential mistakes.</p> <p>This is already everything we need to implement for the instance. The <code>size</code> method ensures that the number of items does not exceed the allowed limit given by the instance size. We next turn to the solutions.</p>"},{"location":"instructor/problem/example/#handling-solutions","title":"Handling Solutions","text":"<p>The <code>packing</code> key is slightly more involved to construct. To recapitulate, we would like this key to be a dictionary that maps indices of items to a two-dimensional position and an indicator whether they should be rotated. We use a similar approach as for the <code>items</code> list. We additionally import the <code>Literal</code> class from the <code>typing</code> module as well as the <code>SizeIndex</code> type alias from <code>algobattle.types</code>.</p> <pre><code>position_height = Annotated[int, Interval(ge=0, lt=InstanceRef.height)]\nposition_width = Annotated[int, Interval(ge=0, lt=InstanceRef.width)]\nrotation = Literal[\"unrotated\", \"rotated\"]\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of 2D Knapsack.\"\"\"\n\n    packing: dict[SizeIndex, tuple[position_height, position_width, rotation]]\n</code></pre> <p>This of course does not at all ensure that the given solution is valid, yet. We did not yet check whether items overlap or extend beyond the boundaries of the knapsack. Since these checks are arguably beyond the scope of simple type checking, we implement these tests explicitly in the <code>validate_solution</code> method. For convenience, we import the <code>itertools</code> library.</p> <pre><code>    def validate_solution(self, instance: Instance, role: Role) -&gt; None:\n        flattened_packing = []\n        for index, (pos_height, pos_width, rotation) in self.packing.items():\n            item_height = instance.items[index][0 if rotation == \"unrotated\" else 1]\n            item_width = instance.items[index][1 if rotation == \"unrotated\" else 0]\n\n            height_endpoint = pos_height + item_height\n            width_endpoint = pos_width + item_width\n            flattened_packing.append(\n                (index, pos_height, height_endpoint, pos_width, width_endpoint)\n            )\n\n        if height_endpoint &gt; instance.height or width_endpoint &gt; instance.width:\n            raise ValidationError(\n                \"Item extends the knapsack boundaries.\",\n                detail=f\"Item {index} was placed at position ({pos_height, pos_width}), extending the knapsack boundaries.\"\n            )\n\n        for item, other_item in itertools.combinations(flattened_packing, 2):\n            if item[1] &lt; other_item[2] and item[2] &gt; other_item[1]:\n                if item[3] &lt; other_item[4] and item[4] &gt; other_item[3]:\n                    raise ValidationError(\n                        \"Two items overlap.\",\n                        detail=f\"Items {item[0]} and {other_item[0]} overlap.\"\n                    )\n</code></pre> <p>We are almost done writing the problem class. The next step is to tell the framework what the quality of a solution is, i.e. which values it should compare when given two solutions to determine which is the better one.</p> <p>For this, we overwrite the <code>score</code> method. We have access to the solution via the <code>self</code> argument, access to the instance via the <code>instance</code> argument and can even decide to judge the certificate solution of the generator and a solvers solution differently, via the <code>role</code> argument, e.g. to give the solver some additional slack.</p> <pre><code>    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        area = 0\n        for index in self.packing:\n            area += instance.items[index][0] * instance.items[index][1]\n        return area\n</code></pre> <p>You can find the complete contents of the <code>problem.py</code> at the end of this tutorial section.</p>"},{"location":"instructor/problem/example/#best-practice-writing-tests","title":"Best Practice: Writing Tests","text":"<p>Now that we have created a problem file, it is time to see if it does what we want it to do. The most straightforward sanity check is to run the mock generator and solver that we have written previously.</p> <p>Note</p> <p>If you did not generate the problem folder as we did in this tutorial, make sure that a team is entered in the <code>algobattle.toml</code> file that utilizes the solver and generator that we wrote!</p> <p>For this, we can use the <code>algobattle test</code> command. This command builds the generators and solvers of the configured teams and executes a single run of them at the minimum size that was configured for the problem.</p> <p>Running this command does however produce an issue: <pre><code>~ algobattle test\nTesting programs of team Rats\nGenerator built successfully\nGenerator didn't run successfully\nSolver built successfully\nCannot test running the solver\nYou can find detailed error messages at results/test-2024-01-01_12-35-10.json\n</code></pre></p> <p>So what went wrong? Looking into the log files reveals the issue.</p> <pre><code>{\n    \"Rats\": {\n        \"generator_run\": {\n            \"type\": \"ValidationError\",\n            \"message\": \"Instance is too large.\",\n            \"detail\": \"Generated: 5, maximum: 1\"\n        }\n    }\n} \n</code></pre> <p>We wrote a generator and solver that run on an instance with five items, but proclaimed in the <code>problem.py</code> that any instance with at least one  item is valid:</p> <pre><code>Problem(\n    name=\"2D Knapsack\",\n    min_size=1,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <p>Should we thus change our generator and solver? We do not have to, as the <code>algobattle test</code> command allows us to run the test on a specific instance size:</p> <pre><code>~ algobattle test --size 5\nTesting programs of team Rats\nGenerator built successfully\nGenerator ran successfully\nSolver built successfully\nSolver ran successfully\n</code></pre> <p>This tells us that the combination of our problem description with a small, hand-crafted instance behaves as expected. It is at this stage where most of the errors in the code come to light. You can use the log files written into the <code>results</code> folder to assist you in debugging your code. You may find at this stage that it does pay off to write detailed <code>ValidationError</code> exception messages.</p> <p>Just because our single, hand-crafted test ran through, this does not mean that our code is without any conceptual errors. Especially when giving your problem file to other people, who will likely spend much more time dissecting your code and descriptions to learn how to write their own programs, many unexpected issues with your code may come to light.</p> <p>To mitigate some of the reports of illegal inputs that are nevertheless accepted by your code, legal inputs that are rejected by your code, or worst -- code that crashes your validation code -- it is a good idea to write a few unittests.</p> <p>We do not want to dive into too much detail on how you could test your code, how much coverage may be desirable and related topics, as this goes well beyond the scope of this tutorial. Testing code is a topic about which volumes have been written by authors who are much more knowledgeable about the topic as we could claim to be.</p> <p>Thus, we only talk about how to best interface the problem that we have designed, so that you can then use this knowledge to write your own tests. We use the <code>unittest</code> module from the standard library for this part of the tutorial.</p> <p>We create a file <code>tests.py</code> in the <code>2D Knapsack</code> folder, with generic scaffolding.</p> tests.py<pre><code>\"\"\"Tests for the 2D Knapsack problem.\"\"\"\nimport unittest\n\nfrom algobattle.util import Role\n\nfrom problem import Instance, Solution, ValidationError\n\n\nclass Tests(unittest.TestCase):\n    \"\"\"Tests for the 2D Knapsack problem solution class.\"\"\"\n\n    ...\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n</code></pre> <p>You can then access all additional helper methods that you may have added to the <code>Instance</code> and <code>Solution</code> classes as you would normally do.</p> <p>If you would like to test the validation methods, i.e. <code>validate_instance</code> and <code>validate_solution</code>, you could do so as follows.</p> <p>Assume, just for the sake of being able to give an example, that we would have added a <code>validate_instance</code> method to the <code>Instance</code> class with the following, rather nonsensical content:</p> <pre><code># This method is just for demonstration purposes.\ndef validate_instance(self) -&gt; None:\n    super().validate_instance()\n    if self.height != 1:\n        raise ValidationError(\"The knapsack is not of height 1!?\")\n</code></pre> <p>This rather silly method raises a validation error whenever the height of the knapsacks is unequal to one.</p> <pre><code># Sample test for the validate_instance method\ndef test_knapsack_height_not_silly(self):\n    with self.assertRaises(ValidationError):\n        faulty_instance = Instance.model_validate({\"height\": 2, \"width\": 1, \"items\": [(1, 1)]})\n        faulty_instance.validate_instance()\n\n# Sample test for the validate_solution method\ndef test_item_overlap(self):\n    instance = Instance(height=1, width=1, items=[(1, 1), (1, 1)])\n    with self.assertRaises(ValidationError):\n        faulty_solution = Solution.model_validate({\"packing\": {0: (0, 0, \"unrotated\"), 1: (0, 0, \"unrotated\")}})\n        faulty_solution.validate_solution(instance, Role.generator)\n</code></pre> <p>You can test the <code>size</code> function of the <code>Instance</code> class and the <code>score</code> function of the <code>Solution</code> class as you would test any other method.</p> <p>If you use the <code>unittest</code> module, you can then run these tests by executing <code>python -m unittest</code> in the <code>2D Knapsack</code> folder.</p>"},{"location":"instructor/problem/example/#writing-a-description","title":"Writing a Description","text":"<p>We are done writing code for the problem. Now, it is a good idea to write a description file that tells the users that should work on the problem what it is about. This includes explaining the general idea and, more importantly, how the expected I/O is defined.</p> <p>We recommend creating a file in the <code>2D Knapsack</code> folder named <code>description.md</code>, as this file name is automatically picked up by the packaging step  that we will handle in the next step.</p> <p>Note</p> <p>If you use the <code>algobattle-web</code> framework, the contents of this file will be displayed to your users when they click on the respective problem tab.</p>"},{"location":"instructor/problem/example/#packaging-everything-together","title":"Packaging Everything Together","text":"<p>Now that our code is tested and documented, we are ready to hand it out! For this, we can again use the <code>algobattle</code> cli, which wraps up the <code>problem.py</code>, the <code>algobattle.toml</code> and the <code>description.md</code> into a file that others can work on.</p> <pre><code>~ algobattle package problem\nPackaged Algobattle project into /path/to/working/dir/2D Knapsack/2d_knapsack.algo\n</code></pre> <p>Note</p> <p>The <code>algobattle.toml</code> gets truncated during the packaging step. Only the <code>[match]</code> entries remain.</p>"},{"location":"instructor/problem/example/#the-completed-problempy-file","title":"The Completed problem.py File","text":"<p>This is the final content of the <code>problem.py</code> that we have created.</p> problem.py<pre><code>\"\"\"The 2D Knapsack problem module.\"\"\"\nimport itertools\nfrom pydantic import Field\nfrom typing import Annotated, Literal\n\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, maximize\nfrom algobattle.util import Role, ValidationError\nfrom algobattle.types import u64, Interval, InstanceRef, SizeIndex\n\n\nitem_height = Annotated[int, Interval(ge=1, le=InstanceRef.height)]\nitem_width = Annotated[int, Interval(ge=1, le=InstanceRef.width)]\npoint = tuple[item_height, item_width]\n\n\nclass Instance(InstanceModel):\n    \"\"\"Instances of 2D Knapsack.\"\"\"\n\n    height: u64 = Field(ge=1)\n    width: u64 = Field(ge=1)\n\n    items: list[point]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.items)\n\n\nposition_height = Annotated[int, Interval(ge=0, lt=InstanceRef.height)]\nposition_width = Annotated[int, Interval(ge=0, lt=InstanceRef.width)]\nrotation = Literal[\"unrotated\", \"rotated\"]\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of 2D Knapsack.\"\"\"\n\n    packing: dict[SizeIndex, tuple[position_height, position_width, rotation]]\n\n    def validate_solution(self, instance: Instance, role: Role) -&gt; None:\n        flattened_packing = []\n        for index, (pos_height, pos_width, rotation) in self.packing.items():\n            item_height = instance.items[index][0 if rotation == \"unrotated\" else 1]\n            item_width = instance.items[index][1 if rotation == \"unrotated\" else 0]\n\n            height_endpoint = pos_height + item_height\n            width_endpoint = pos_width + item_width\n            flattened_packing.append(\n                (index, pos_height, height_endpoint, pos_width, width_endpoint)\n            )\n\n        if height_endpoint &gt; instance.height or width_endpoint &gt; instance.width:\n            raise ValidationError(\n                \"Item extends the knapsack boundaries.\",\n                detail=f\"Item {index} was placed at position ({pos_height, pos_width}), extending the knapsack boundaries.\"\n            )\n\n        for item, other_item in itertools.combinations(flattened_packing, 2):\n            if item[1] &lt; other_item[2] and item[2] &gt; other_item[1]:\n                if item[3] &lt; other_item[4] and item[4] &gt; other_item[3]:\n                    raise ValidationError(\n                        \"Two items overlap.\",\n                        detail=f\"Items {item[0]} and {other_item[0]} overlap.\"\n                    )\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        area = 0\n        for index in self.packing:\n            area += instance.items[index][0] * instance.items[index][1]\n        return area\n\n\nProblem(\n    name=\"2D Knapsack\",\n    min_size=1,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre>"},{"location":"instructor/problem/intro/","title":"Introduction","text":"<p>Brush up on the basics</p> <p>This page assumes you're already familiar with the basics of how Algobattle works. If that's not you yet, you can read up on it in the student tutorial.</p> <p>In each Algobattle course the student teams are given a few problems that they will then need to solve. This means that we need to first come up with what those problems are and then how to tell Algobattle about them.</p>"},{"location":"instructor/problem/intro/#using-a-prebuilt-problem","title":"Using a Prebuilt Problem","text":"<p>The fastest way to get up and running is to use one of the problems we've already developed in the Algobattle Problems repository. These contain everything you need to use them in a course and have been tested already. But of course half the fun is coming up with your own ideas and tailoring the problems to your students!</p>"},{"location":"instructor/problem/intro/#coming-up-with-a-problem-idea","title":"Coming up with a Problem Idea","text":"<p>Before we start to write any code, we need to come up with the abstract problem that students should solve.  For this, it may be easiest to first review what a problem actually is. Abstractly it's just a specification of instances and solutions, and a mapping of instances to valid solutions. But of course, that doesn't really tell us much. What's more helpful is to look at some examples of well known problems:</p> <ul> <li> <p>Satisfiability. Given a formula of propositional logic (e.g. <code>(A \u2228 \u00acC) \u2227 (\u00acA \u2228 B)</code>), determine if there is some truth     assignment to the variables that make it true.</p> </li> <li> <p>Reachability. Given a graph and two vertices <code>v</code>, <code>w</code> in it, determine if there is some path from <code>v</code> to <code>w</code>.</p> </li> <li> <p>Independent Set. Given a graph, compute the largest set of its vertices that have no edges between any two of them.</p> </li> <li> <p>Subset Sum. Given a list of numbers and a target, determine if there is some subset of the list that sums to the     target.</p> </li> <li> <p>Pairsum. Given a list of numbers, find two pairs <code>a, b</code> and <code>c, d</code> of numbers in it that have the same sum     <code>a + b = c + d</code>.</p> </li> </ul> <p>We can see that each of these uses some fairly common mathematical structure (a formula, a graph, a list of numbers, etc.) to specify instances and then specifies some goal that the solver needs to achieve. Sometimes this can be a simple yes or no answer, but it can also be a more complicated solution.</p> <p>Validation vs Verification</p> <p>We use the terms validation and verification to refer to two distinct things. To validate an instance or solution is to check whether it is, in principle, valid and well-formed. For example, in the Subset Sum problem the validation process confirms that the instance is indeed a properly formatted list of numbers and a target or that the solution is a subset of the numbers in the instance that was given. On the other hand verification actually checks whether a solution correctly solves the given instance.</p> <p>Put shortly: <code>Otters</code> is an invalid solution to <code>5 + 3</code>, <code>17</code> is valid but does not pass verification, and <code>8</code> is the actually correct solution that is valid and passes verification.</p>"},{"location":"instructor/problem/intro/#conceptual-requirements","title":"Conceptual Requirements","text":"<p>Algobattle is very flexible, so we can let our creativity run almost completely free here! But there still are some considerations that make some types of problems more well-suited for Algobattle framework. Essentially, we are interested in two characteristics, both which revolve around the solutions of a problem:</p> <ol> <li> <p>It is fairly fast (say, at most quadratic asymptotic runtime) to check if a proposed instance or solution is valid.     This does not impact most problems since the requirements for valid instances and solutions are very direct and     easy to verify. But there are some tricky cases where a simple sounding requirement ends up being costly to     validate.</p> </li> <li> <p>The solution of an instance can be verified significantly faster than it would take to actually solve it.     In particular, the solution should contain all the information needed to determine if it is correct. Problem     solutions that are simple yes or no answers or that rely on hard to compute outside information are hard to verify     quickly and thus should be avoided.</p> </li> </ol> <p>Both are soft requirements which you can technically ignore. This may, however, impact your match runtime significantly. The validation and verification process does not have a built-in timeout, meaning that if you try to solve an instance during it, the framework will not continue until this solution was found or an error is encountered.</p> <p>There is no restriction on the data encoding format that problems use. We only enforce that all data is passed in the form of files, regardless of their encoding or even how many a single instance/solution uses. However, almost all problems we use in our courses use a single <code>.json</code> file since this is such a universally supported file format, there is great support built into Algobattle itself, and you can encode most things into it fairly well. For a deeper dive into how <code>json</code> or other I/O formats work, have a look at the I/O Section.</p>"},{"location":"instructor/problem/intro/#phrasing-problems-for-algobattle","title":"Phrasing Problems for Algobattle","text":"<p>We can now look back at the problems defined above to see if they're suited for Algobattle and how we can best phrase them. In particular, let's look at the Satisfiability and Independent Set problems.</p> <p>Satisfiability instances are very easy and fast to validate since you just need to do some basic syntax checks. Solutions are yes or no answers, also trivial to validate. But verifying them is hard. There is currently no known algorithm that can do this efficiently, meaning we would have to spend a lot of time solving every instance. A better way to phrase this problem would be to instead ask for the variable assignment itself, not just whether it exists. Then you can simply fill in the truth values and confirm that the formula evaluates to true. However, this does not work for the negative case where no such assignment exists.</p> <p>Independent Set uses a graph for its instances, which have various common and simple to validate encodings. Algobattle even comes with an easy-to-use one built in. Solutions are more complicated than just a yes or a no, but it still is no issue to check that a set of vertices does not have any edges between them. But there is a different problem with verifying the solutions, we can't easily know if a proposed independent set actually is the biggest.</p> <p>Both of these can be solved in the same way. By having each instance come with a valid solution. In the case of Satisfiability we then guarantee that there is indeed some satisfying variable assignment. And for Independent Set we slightly relax our problem so that we don't ask for the biggest independent set but just one that is at least as big as the one we already know exists. Since this very commonly what we want it is the default in Algobattle. We do this by having the generator also output a solution in addition to the instance. You can change this behaviour when creating your problem later.</p>"},{"location":"instructor/problem/intro/#formalizing-the-problem","title":"Formalizing the Problem","text":"<p>Now that we have the broad idea of how our problem should work we need to formalize it so that Algobattle can work with it. To do this we make a problem file.</p>"},{"location":"instructor/problem/io/","title":"Arbitrary I/O Formats","text":"<p>So far we've always encoded our problem instances and solutions as json files, but Algobattle lets you also use whatever other data types you want for your problems. This page will go through the implementation of such a problem and explain every step in detail.</p>"},{"location":"instructor/problem/io/#inheriting-from-instance-or-solution","title":"Inheriting from Instance or Solution","text":"<p>To define a problem that uses json encoding we just inherit from <code>InstanceModel</code> or <code>SolutionModel</code>, these are actually subclasses of <code>Instance</code> and <code>Solution</code> that combine their functionality with the Pydantic json parsing and data validation. This means that if we want to use our own encoding or decoding logic, we can just inherit from the base classes instead.</p> <p>Throughout this page we will work on an example problem where instances are pictures and the task is to identify which animal is in it. This means that we will use a json based solution and a custom encoding for the instances. The starting point of our problem file then looks like this:</p> problem.py<pre><code>from typing import Literal\n\nfrom algobattle.problem import Problem, Instance, SolutionModel\n\nAnimal = Literal[\"Cat\", \"Dog\", \"Duck\", \"Stingray\", \"Albatross\", \"Snake\"]\n\nclass MyInstance(Instance):\n    \"\"\"Instances of Animal Detection.\"\"\"\n\n    ...\n\n    @property\n    def size(self) -&gt; int:\n        ...\n\n\nclass MySolution(SolutionModel[MyInstance]):\n    \"\"\"Solutions of Animal Detection.\"\"\"\n\n    found: Animal\n\n\nProblem(\n    name=\"Animal Detection\",\n    min_size=64,\n    instance_cls=MyInstance,\n    solution_cls=MySolution,\n    with_solution=False,\n)\n</code></pre> Class Names <p>In this example we call our instance and solution classes different names to avoid clashes with the base classes from <code>algobattle.problem</code>. You could instead also import them under different names or use dotted imports.</p> No Generator Solution <p>The way we will implement this problem is by not requiring the generator to also submit a solution. This is just a choice we make for this particular example, you can also use custom data formats for problems that also require a generator solution.</p>"},{"location":"instructor/problem/io/#implementing-the-python-data","title":"Implementing the Python Data","text":"<p>Every <code>MyInstance</code> object needs to hold the info it needs to encode the instance for the solver, score it, etc. In our example this means that we need to somehow store the image in these Python objects and implement things like the size property or validation and scoring methods using that. We will just use a basic data class and the pillow image library.</p> problem.py<pre><code>from typing import Literal\nfrom dataclasses import dataclass\n\nfrom algobattle.problem import Problem, Instance, SolutionModel\nfrom algobattle.util import Role\nfrom PIL import Image\n\n\nAnimal = Literal[\"Cat\", \"Dog\", \"Duck\", \"Stingray\", \"Albatross\", \"Snake\"]\n\n@dataclass\nclass MyInstance(Instance):\n    \"\"\"Instances of Animal Detection.\"\"\"\n\n    image: Image.Image\n\n    @property\n    def size(self) -&gt; int:\n        return max(self.image.width, self.image.width)\n\n\nclass MySolution(SolutionModel[MyInstance]):\n    \"\"\"Solutions of Animal Detection.\"\"\"\n\n    found: Animal\n\n    def validate_solution(self, instance: MyInstance, role: Role) -&gt; None:\n        super().validate_solution(instance, role)\n        ... # check that the correct animal is pictured\n\n\nProblem(\n    name=\"Animal Detection\",\n    min_size=64,\n    instance_cls=MyInstance,\n    solution_cls=MySolution,\n    with_solution=False,\n)\n</code></pre>"},{"location":"instructor/problem/io/#the-encodable-protocol","title":"The <code>Encodable</code> Protocol","text":"<p>We now need to tell Algobattle how it should encode our instances into files and how it should decode them from the output of a program. For the first we just implement an <code>encode</code> method that takes the location on the file system where the data needs to end up, and the role of the team that will read this data. We can either create a new folder at the given path and then place as many files as we want in it, or create a single file at that path. You should never create any files that aren't rooted at the given path, or are siblings of it, etc. The path we are given will have a plain name without any file extension, the name itself cannot be changed, but an appropriate file extension should be added.</p> <pre><code>@dataclass\nclass MyInstance(Instance):\n    \"\"\"Instances of Animal Detection.\"\"\"\n\n    image: Image.Image\n\n    @property\n    def size(self) -&gt; int:\n        return max(self.image.width, self.image.width)\n\n    def encode(self, target: Path, role: Role) -&gt; None:\n        full_path = target.with_suffix(\".png\") # (1)!\n        self.image.save(full_path) # (2)!\n</code></pre> <ol> <li>Add the <code>.png</code> file extension</li> <li>Write the image to the target location using pillow.</li> </ol> <p>Super Call</p> <p>Do not call <code>super().encode()</code> in this method. The <code>Instance</code> class's <code>encode</code> method is abstract and will just raise an error. This is different to the validation methods.</p> Role <p>We can use the role argument to encode data differently based on who is going to read it. Most of the time this argument won't be used, but it can be helpful when working with advanced battle types and problems.</p> <p>The other method we need to implement is the <code>decode</code> class method. It takes a path pointing to where the program should have placed its output and then returns a problem instance object. It also again takes the role argument and an additional one specifying the maximum allowable size in this fight.</p> <p>Maximum Size</p> <p>You do not need to validate that the size of the instance actually is smaller than the maximum allowed size. This will be done in a later step by Algobattle itself. In most use cases the <code>max_size</code> argument won't be needed, but it can be helpful to e.g. prevent stalling in the decoding process when trying to read abnormally large files.</p> <pre><code>@dataclass\nclass MyInstance(Instance):\n    \"\"\"Instances of Animal Detection.\"\"\"\n\n    image: Image.Image\n\n    @property\n    def size(self) -&gt; int:\n        return max(self.image.width, self.image.width)\n\n    def encode(self, target: Path, role: Role) -&gt; None:\n        full_path = target.with_suffix(\".png\")\n        self.image.save(full_path)\n\n    @classmethod\n    def decode(cls, source: Path, max_size: int, role: Role) -&gt; Self:\n        full_path = source.with_suffix(\".png\") # (1)!\n        try:\n            image = Image.open(full_path) # (2)!\n        except FileNotFoundError:\n            raise EncodingError(\"The image file does not exist.\")\n        except UnidentifiedImageError:\n            raise EncodingError(\"The image cannot be decoded.\")\n        return cls(image) # (3)!\n</code></pre> <ol> <li>Add the same file extension we used when encoding the data.</li> <li>Read the image using pillow.</li> <li>Return a new object of the instance class.</li> </ol> <p>Super Call</p> <p>Do not call <code>super().decode()</code> in this method. The <code>Instance</code> class's <code>decode</code> method is abstract and will just raise an error. This is different to the validation methods.</p> Generator Solution <p>If your problem does use generator solutions then you do not need to decode them in this method. The path you receive points only to the instance data and the generator's solution will be decoded using the solution class's <code>decode</code> method.</p> <p>When the data cannot be decoded properly or is missing you should always raise an <code>EncodingError</code> from <code>algobattle.util</code> with appropriate error messages. This can also be in cases where you can in principle decode the data, but it does not conform to some specification that's part of your problem. For example, when using the usual base classes to decode json files we also apply Pydantic validation as part of this step.</p> <p>Decoding Solutions</p> <p>Solutions follow exactly the same encoding protocol, but additionally receive an argument on their decode method that contains the instance this solution is for. This means that you need to implement a <code>decode</code> method like this:</p> <pre><code>class ExampleSolution(Solution[ExampleInstance]):\n\n    @classmethod\n    def decode(cls, source: Path, max_size: int, role: Role, instance: ExampleInstance) -&gt; Self:\n        ...\n</code></pre>"},{"location":"instructor/problem/io/#specifying-the-io-schema","title":"Specifying the I/O Schema","text":"<p>We optionally can also add a class method that specifies what exactly our instances should look like. This information will not be used by the Algobattle framework itself, but can be used by your students. It should be a textual and machine-readable description of what this instance's or solution's data needs to conform to. In the case of the usual json data it is their OpenAPI schema. What exactly this should look like depends heavily on the data encoding techniques you are using and in many cases there simply is no reasonable schema. In those cases it's best to just not implement this method.</p> <p>This is the signature of this method:</p> <pre><code>class ExampleInstance(Instance):\n\n    @classmethod\n    def io_schema(cls) -&gt; str | None:\n        ...\n</code></pre>"},{"location":"instructor/problem/problem_file/","title":"Creating a Problem File","text":"<p>Algobattle uses Problem files to specify all the details of a problem formally, i.e. what instances and solutions should look like, how to score them, how to decode and encode them, etc. These are Python files and leave a lot of room for you to write them however you like. This overview will cover the basic structure of them and common use cases, for more advanced features refer to later sections of the problem creation guide.</p> <p>Pairsum</p> <p>Throughout this page we will use the Pairsum problem as our working example.</p>"},{"location":"instructor/problem/problem_file/#initializing-the-project-folder","title":"Initializing the Project Folder","text":"<p>When students develop their programs they are typically working within an Algobattle project folder created by the CLI tool from a <code>.algo</code> file. Our goal now is to create a brand-new project folder with problem files for our new problem. Once we're done we can then package this into a <code>.algo</code> file and distribute it to our students.</p> <p>To initialize the folder we also use the <code>algobattle init</code> command, but this time specify that we want to create a new problem and its name.</p> <pre><code>algobattle init --new --problem \"Pairsum\"\n</code></pre> <p>This creates a new folder named <code>Pairsum</code> with the following contents:</p> <pre><code>.\n\u2514\u2500 Pairsum\n   \u251c\u2500 generator/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 .gitignore\n   \u251c\u2500 problem.py\n   \u2514\u2500 algobattle.toml\n</code></pre> <p>Let us take a look at the contents of the <code>problem.py</code> file, which is where we will implement the problem logic.</p> <pre><code>\"\"\"The Pairsum problem module.\"\"\"\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel, maximize # (1)!\nfrom algobattle.util import Role\n\n\nclass Instance(InstanceModel): # (2)!\n    \"\"\"Instances of Pairsum.\"\"\"\n\n    ...\n\n    @property\n    def size(self) -&gt; int:\n        ...\n\n\nclass Solution(SolutionModel[Instance]): # (3)!\n    \"\"\"Solutions of Pairsum.\"\"\"\n\n    ...\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        ...\n\n\nProblem( # (4)!\n    name=\"Pairsum\",\n    min_size=1,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <ol> <li>These lines import the needed parts of the Algobattle framework.</li> <li>This class specifies what instances of the problem look like.</li> <li>This class specifies what solutions of the problem look like.</li> <li>The <code>Problem</code> constructor ties all the information together and creates the problem.</li> </ol> <p>As you can see, the file is mostly empty now and only contains some bare-bones structure. The ellipses tell us where we need to implement the basic problem specific code, though there also are more options for us to customize later on.</p> <p>Type Checking</p> <p>The Algobattle module is fully typed, but Python doesn't actually require you do include type hints in your own code. We strongly recommend still using type hints as much as possible since they prevent many bugs and make code easier to read. We will also make heavy use of type annotations to easily specify data formats.</p>"},{"location":"instructor/problem/problem_file/#the-instance-class","title":"The Instance Class","text":"<p>Let's start by looking at the <code>Instance</code> class. This will specify what every instance of your problem should look like. As you can see this class inherits from the <code>InstanceModel</code> utility class, which uses Pydantic to make instances that can easily be decoded to and from json files.</p> Advanced Usage <p>In the most general case they need to only inherit from the <code>Instance</code> class and implement the <code>Encodable</code> protocol, but doing so manually is much more complicated and not needed for most problems. We will see how to use these classes in the arbitrary i/o formats guide.</p> <p>Pydantic</p> <p>Pydantic is a very powerful library with excellent support for many use cases. This can also make it harder to understand how exactly everything works and what the \"best\" way of doing something is. For now, we recommend just staying here and focusing on how Algobattle lets us use it. If you're curious and want to see how it works under the hood you can then go back to its documentation later.</p>"},{"location":"instructor/problem/problem_file/#instance-data","title":"Instance Data","text":"<p>First we need to specify what an instance actually looks like. In our case it just is a list of natural numbers. This means we want the json file of an instance to look something like this:</p> <pre><code>{\n    \"numbers\": [1, 3, 17, 95, 0, 24, 6]\n}\n</code></pre> <p>I.e. it contains a single field called <code>numbers</code> which contains a list of non-negative integers. This can be copied to the first ellipsis of the Instance class almost verbatim!</p> <pre><code>class Instance(InstanceModel):\n    \"\"\"Instances of Pairsum.\"\"\"\n\n    numbers: list[int]\n\n    @property\n    def size(self) -&gt; int:\n        ...\n</code></pre> <p>Here we create a Python class attribute named after the key we want in the json file, and give it a type annotation that matches the kind of data we want at that key. If a json file contains a key that is not listed here, or if it is missing one of the keys listed here, the framework will assume that the given instance is malformed and reject it. Pydantic also ensures that the values at each key also match the types specified in the class!</p> Unfamiliar with Python type annotations? <p>Here's some more examples of type annotations and what they mean:</p> <ul> <li><code>float</code>: a single real number.</li> <li><code>Literal[\"Ice Cream\", \"Cake\", \"Donuts\"]</code>: one of <code>Ice Cream</code>, <code>Cake</code>, or <code>Donuts</code>, no other strings or any other     values are permitted.</li> <li><code>tuple[int, str]</code>: a tuple of an integer and a string. Since json only knows lists this will look like     <code>[123, \"Cats\"]</code> or <code>[-17, \"Dogs\"]</code>, but never something like <code>[1, 2]</code> or <code>[\"Wombats\", \"are\", \"great\"]</code>.</li> <li><code>dict[str, int]</code>: a mapping of strings to integers, e.g. <code>{\"Pasta\": 1, \"Pizza\": 17, \"Sushi\": 5}</code>.</li> <li><code>set[list[str]]</code>: a set of lists of strings. Similar to tuples, json does not support sets so they will be encoded     as plain lists, but with the requirement that no elements are duplicated and that order does not matter.</li> </ul> <p>In general, you can use most basic types on their own, with collections having the type they contain in square brackets after them.</p> <p>Example Instances</p> <p>Here are some valid example instances:</p> <ul> <li><code>{\"numbers\": [1, 2, 3]}</code></li> <li><code>{\"numbers\": [17, 0, 0]}</code></li> <li><code>{\"numbers\": [95, 74694, 65549, 6486681, 6513232135186, 651344168]}</code></li> </ul> <p>These are invalid and will be rejected automatically:</p> <ul> <li><code>{\"numbers\": [1, 2, 3], \"other\": 5}</code></li> <li><code>{}</code></li> <li><code>{\"nums\": [1, 2, 3]}</code></li> <li><code>{\"numbers\"</code></li> <li><code>{\"numbers\": [1.5, 2, 3]}</code></li> <li><code>{\"numbers\": 17}</code></li> </ul>"},{"location":"instructor/problem/problem_file/#additional-validation","title":"Additional Validation","text":"<p>But there still is an issue with this instance definition, it says that the numbers can be any integers and not just natural numbers. This means that <code>{\"numbers\": [-1, -2, -3]}</code> would also be accepted! Another potential issue is that Python allows arbitrarily large numbers in its <code>int</code> type, but many other languages make very large numbers hard to work with. To make everything a bit fairer for different teams using different languages and not make winning a match be based on exploiting corner case overflow bugs, we recommend also limiting the maximum size of the numbers, so they can fit in a 64-bit integer. This can be done very easily by using the Algobattle utility types we provide in the <code>algobattle.types</code> module. In our case we want <code>u64</code> for an unsigned 64-bit integer.</p> <pre><code>from algobattle.types import u64 # (1)!\n\nclass Instance(InstanceModel):\n    \"\"\"Instances of Pairsum.\"\"\"\n\n    numbers: list[u64]\n\n    @property\n    def size(self) -&gt; int:\n        ...\n</code></pre> <ol> <li>Always remember to add imports at the top of the file for everything you use from an external module.</li> </ol> <p>Integer Types</p> <p>The <code>algobattle.types</code> module contains predefined types for all commonly found integer types. These are <code>u64</code>, <code>u32</code>, <code>u16</code> for unsigned integers that fit in 64, 32, and 16 bits and <code>i64</code>, <code>i32</code>, <code>i16</code> for the corresponding signed variants.</p> <p>But there also are some properties that we cannot validate by just using one of the predefined types. The easiest way to do that is to implement the <code>validate_instance</code> method. It will be called after all the basic properties of the types have been validated and can then perform more complicated checks. For example, if we wanted to also add the constraint that all the numbers are even we could add this:</p> <pre><code>from algobattle.util import ValidationError\n\nclass Instance(InstanceModel):\n    \"\"\"Instances of Pairsum.\"\"\"\n\n    numbers: list[u64]\n\n    def validate_instance(self) -&gt; None: # (1)!\n        super().validate_instance() # (1)!\n        for number in self.numbers:\n            if number % 2 != 0:\n                raise ValidationError(\n                    \"A number in the instance is not even!\",\n                    detail=f\"Odd number {number} was passed.\",\n                )\n\n    @property\n    def size(self) -&gt; int:\n        ...\n</code></pre> <ol> <li>The <code>validate_instance</code> method takes only the instance itself as an argument, and returns nothing.</li> <li>Always include this line at the top of this method. It will call the parent's class validation logic to make sure     that properties assured by it are actually enforced.</li> </ol> <p>If the instance is valid this method should simply return nothing, if it is invalid it needs to raise a <code>ValidationError</code>.</p> <p>Error Messages</p> <p>You may notice the optional <code>detail</code> argument of the <code>ValidationError</code> exception.  When the logs are visible for everyone, accidentally leaking information about parts of an instance, may reveal the strategy of a team. On the other hand, when developing code, a team may nevertheless want to see exactly what went wrong.</p> <p>The first argument will always be visible to everyone, while the <code>detail</code> field is hidden in match logs but visible in local test runs. This means that the first argument should only contain a basic description of the general error and detailed info should be in the <code>detail</code> argument.</p> <p>Implementing this method is entirely optional. Many simpler problems like Pairsum do not need it at all since their properties are easily encoded in just the predefined types.</p>"},{"location":"instructor/problem/problem_file/#instance-size","title":"Instance Size","text":"<p>Each instance also has a specific size that is used to limit the generating team so that it actually needs to produce hard instances and not just big ones. In our case the size naturally just is the length of the list of numbers. We specify what a specific instance's size is by implementing the <code>size</code> property in the Instance class.</p> <pre><code>class Instance(InstanceModel):\n    \"\"\"Instances of Pairsum.\"\"\"\n\n    numbers: list[u64]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.numbers)\n</code></pre> <p>There are many more things you can customize here, but this is all you need to know to get started. If you want to take a deeper dive, check out the advanced problem creation pages once you've got a feeling for everything.</p>"},{"location":"instructor/problem/problem_file/#the-solution-class","title":"The Solution Class","text":"<p>The Solution class works very similar to the Instance class. Its job is to specify what solutions look like and how to score them. The data encoding and decoding can again be done using Pydantic:</p> <pre><code>class Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of Pairsum.\"\"\"\n\n    indices: tuple[u64, u64, u64, u64]\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        ...\n</code></pre> <p>But note that we're actually looking for four different indices into the list in the input, not just any four numbers. That means we need to validate that the numbers are valid indices (i.e. smaller than the length of the list) and are all different from each other. We could again do that with a custom validation method, but we can also use some more advanced utility types.</p> <pre><code>class Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of Pairsum.\"\"\"\n\n    indices: Annotated[tuple[SizeIndex, SizeIndex, SizeIndex, SizeIndex], UniqueItems]\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        ...\n</code></pre> <p>The first change is to use <code>SizeIndex</code> instead of a <code>u64</code>. This ensures that the numbers are valid indices into a list of the length of the <code>size</code> of the instance. In our case the size is defined to be exactly the length of the list we want to index, so this works perfectly. The other change is that we add a <code>Annotated[..., UniqueItems]</code> wrapped around the actual type. This is a Python construct that lets us add some metadata to a type annotation. The <code>UniqueItems</code> data will instruct Algobattle (again using Pydantic) to also validate that the items in the wrapped collection are different from each other.</p> <p>Annotated Metadata</p> <p>Using the <code>Annotated[...]</code> construct to add metadata is a powerful way to define validation, but can also be very confusing to people new to the Python type system. We go over it in much more detail in the advanced types section.</p> <p>We also need to check that the first two numbers actually have the same sum as the second two. This is best done with a custom validation method:</p> <pre><code>class Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of Pairsum.\"\"\"\n\n    indices: Annotated[tuple[SizeIndex, SizeIndex, SizeIndex, SizeIndex], UniqueItems]\n\n    def validate_solution(self, instance: Instance, role: Role) -&gt; None:\n        super().validate_solution(instance, role)\n        first = instance.numbers[self.indices[0]] + instance.numbers[self.indices[1]]\n        second = instance.numbers[self.indices[2]] + instance.numbers[self.indices[3]]\n        if first != second:\n            raise ValidationError(\"Solution elements don't have the same sum.\")\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        ...\n</code></pre> <p>Note that this is now called <code>validate_solution</code> and takes not only the solution itself, but also the instance it is trying to solve and the role of the team that created this solution as arguments.</p> <p>Role Argument</p> <p>Most of the time the role argument won't be used to validate a solution. You must still have it listed in the argument list of the method for everything to work smoothly. Some problems use this to e.g. relax some condition for the solving team.</p>"},{"location":"instructor/problem/problem_file/#solution-score","title":"Solution Score","text":"<p>Many problems not only care about a team providing a valid solution but also want them to compute the best solution they can. For example, we might modify to not just want any four such numbers, but want the sum of each pair to be as big as possible. For these problems we implement the <code>score</code> function. If we leave it out all solutions will be scored equally.</p> <pre><code>class Solution(SolutionModel[Instance]):\n    \"\"\"Solutions of Pairsum.\"\"\"\n\n    indices: Annotated[tuple[SizeIndex, SizeIndex, SizeIndex, SizeIndex], UniqueItems]\n\n    def validate_solution(self, instance: Instance, role: Role) -&gt; None:\n        super().validate_solution(instance, role)\n        first = instance.numbers[self.indices[0]] + instance.numbers[self.indices[1]]\n        second = instance.numbers[self.indices[2]] + instance.numbers[self.indices[3]]\n        if first != second:\n            raise ValidationError(\"Solution elements don't have the same sum.\")\n\n    @maximize\n    def score(self, instance: Instance, role: Role) -&gt; float:\n        return instance.numbers[self.indices[0]] + instance.numbers[self.indices[1]]\n</code></pre> <p>This method again receives the solution itself, the instance it solves, and the role of the team that generated it. It needs to return a non-negative real number indicating how good the solution is. When using the <code>@maximize</code> decorator (or using no decorator at all) bigger scores are considered better, if the problem instead asks for the smallest of some value instead import and use the <code>@minimize</code> decorator.</p>"},{"location":"instructor/problem/problem_file/#constructing-the-problem","title":"Constructing the Problem","text":"<p>Now that we have an Instance and a Solution class we can tie everything together using the Problem constructor.</p> <pre><code>Problem(\n    name=\"Pairsum\",\n    min_size=4,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre> <p>In its most basic form it just takes the name of the problem, and both classes we defined above. Finally, it also takes a number that defines what the smallest reasonable instance size for this problem can be. This is needed because in our case there aren't any sensible problem instances that only contain 3 numbers since we're looking for two pairs of two numbers in the list. So if a generator was asked to create an instance of size 3 they couldn't possibly do this and would fail immediately. To prevent bugs like that fill in <code>min_size</code> with whatever the smallest size your problem can properly operate at is.</p> <p>In summary, our final Pairsum problem file looks like this</p> problem.py<pre><code>from typing import Annotated\n\nfrom algobattle.problem import Problem, InstanceModel, SolutionModel\nfrom algobattle.util import Role, ValidationError\nfrom algobattle.types import u64, MinLen, SizeIndex, UniqueItems\n\n\nclass Instance(InstanceModel):\n    \"\"\"An instance of a Pairsum problem.\"\"\"\n\n    numbers: Annotated[list[u64], MinLen(4)]\n\n    @property\n    def size(self) -&gt; int:\n        return len(self.numbers)\n\n\nclass Solution(SolutionModel[Instance]):\n    \"\"\"A solution to a Pairsum problem.\"\"\"\n\n    indices: Annotated[tuple[SizeIndex, SizeIndex, SizeIndex, SizeIndex], UniqueItems]\n\n    def validate_solution(self, instance: Instance, role: Role) -&gt; None:\n        super().validate_solution(instance, role)\n        first = instance.numbers[self.indices[0]] + instance.numbers[self.indices[1]]\n        second = instance.numbers[self.indices[2]] + instance.numbers[self.indices[3]]\n        if first != second:\n            raise ValidationError(\"Solution elements don't have the same sum.\")\n\n\nProblem(\n    name=\"Pairsum\",\n    min_size=4,\n    instance_cls=Instance,\n    solution_cls=Solution,\n)\n</code></pre>"},{"location":"instructor/problem/problem_file/#creating-a-description","title":"Creating a Description","text":"<p>Now that we've made the problem file to tell the framework how our problem works, we need to create a description file to tell our students the same. This can be any file that just describes the problem in human-readable terms. It will be packaged together with the problem file and distributed to the students. By default, Algobattle expects this file to be named <code>description</code> with an appropriate file ending, e.g. <code>description.md</code>, <code>description.pdf</code>, etc.</p> <p>Web Framework</p> <p>When using the Algobattle web framework, Markdown files work best for this since they can be displayed inline on the problem page.</p> description.md<pre><code># The Pairsum Problem\n\nThe Pairsum problem asks you to find two pairs of numbers in a list that have the same sum. I.e.:\n\n**Given**: List `L = [z_1,...,z_n]`\n**Question**: Are there pairwise different `a, b, c, d in [0,...,n-1]` such that `L[a] + L[b] = L[c] + L[d]`?\n\nI.e. given a list of natural numbers the task is to find two pairs of these numbers with the same sum.\nThe `size` of an instance limits the length of the list of numbers.\n\nThe generator should create a hard to solve instance and a certificate solution to prove that such a pair of pairs\nindeed exists. The generator should be able to efficiently find the solution for any input list.\n\n## Instances\nAn instance just contains the list of numbers. For example:\n```json\n{\n    \"numbers\": [1, 2, 3, 4, 5]\n}\n```\n\n## Solutions\nA solution contains a list with the four indices `a, b, c, d` in this order. For example:\n```json\n{\n    \"indices\": [1, 4, 2, 3]\n}\n```\nThis is a valid solution since `L[1] + L[4] = 2 + 5 = 3 + 4 = L[2] + L[3]`.\n</code></pre>"},{"location":"instructor/problem/problem_file/#packaging","title":"Packaging","text":"<p>To easily distribute your problem to your students you can use the Algobattle CLI like this:</p> <pre><code>algobattle package problem\n</code></pre> <p>This creates a <code>pairsum.algo</code> file which contains all the info Algobattle needs to initialize a new project folder on the student's computer with your problem. Note that it will then not only contain the problem file, but also the description, and the Algobattle config file.</p> <p>A peek behind the curtain</p> <p>This file really just is a zip file containing the mentioned files that have been preprocessed slightly. The file extension is there to indicate that you shouldn't pack or unpack these files manually since the CLI tool expects them to be formatted in a precise way.</p> <p>Web Framework</p> <p>This file is what the web framework expects you to upload, it will then be used to run matches on the server and be distributed to the students.</p>"},{"location":"tutorial/","title":"Student Tutorial","text":"<p>The Algobattle tutorial goes over everything needed to understand how the package works and the most common ways to use it. It's aimed at students participating in a course and course instructors that want to learn how to work with the framework.</p> <p>The tutorial pages build on each other and are best read in sequence. It assumes almost no prerequisite knowledge of specific topics, but an understanding of basic theoretical computer science ideas like algorithmic problems and of the Python language will make things a lot easier.</p>"},{"location":"tutorial/#quick-overview","title":"Quick overview","text":"<p>If you're dying to get started coding then the full tutorial might be a bit long for you. Here's all the steps you need to get going, each also linking to corresponding part of the in depth tutorial.</p> <ol> <li> <p>Install everything we need</p> </li> <li> <p>Download the problem spec file your course instructors gave you</p> </li> <li> <p>Run <code>algobattle init --problem path/to/spec.algo --language someLanguage</code>     with the first parameter being the file you just downloaded and the second being the programming language you     want to use</p> </li> <li> <p>Write your programs</p> </li> <li> <p>Run <code>algobattle run</code> and watch your programs battle against each other</p> </li> </ol>"},{"location":"tutorial/getting_started/","title":"Getting Started","text":""},{"location":"tutorial/getting_started/#getting-a-problem","title":"Getting a problem","text":"<p>The idea behind the Algobattle framework is that course instructors will come up with some problem (in the theoretical computer science meaning) that students will then write code to solve. The Algobattle program can then take the problem definition and the code from all the student teams and score how good each team is at solving the problem.</p> <p>Tip</p> <p>Now's a great time to remember to activate the Python environment you installed Algobattle into (<code>conda activate algobattle</code>).</p>"},{"location":"tutorial/getting_started/#problem-spec-files","title":"Problem spec files","text":"<p>The most common way your instructors will give you problem definitions is by uploading them to your Algobattle website. On the specific problem's page you can then download an Algobattle problem spec file with the <code>.algo</code> extension. This file contains all the information we need.</p> <p>A peek behind the curtain</p> <p>Despite their very fancy looking extension, <code>.algo</code> files really just zip files with a few files inside. Algobattle uses these to set up your project folders for you, but it doesn't handle things very well if you feed it data that doesn't have that structure, so the file extension is there to remind you that you're not meant to process these files manually. If you're curious you can unzip them and take a look inside yourself.</p>"},{"location":"tutorial/getting_started/#installed-problems","title":"Installed problems","text":"<p>Another way is to install a Python package that provides one or more problems. For example, our Algobattle Problem package which contains a selection of basic problems. We can install it with pip just like the Algobattle base package:</p> <pre><code>pip install algobattle-problems\n</code></pre>"},{"location":"tutorial/getting_started/#setting-up-the-workspace","title":"Setting up the workspace","text":"<p>Now we can set up our dev environment where we write the code to solve the problem. I'll be showing you some folder structures throughout but obviously the exact structure and names aren't mandatory. Let's start with a base folder which should probably contain a <code>.git</code> folder and not much else.</p> <p>With the console in our base folder we can use Algobattle to initialize our project for us, you can use either a problem spec or an installed problem for this.</p> Problem specInstalled problem <pre><code>algobattle init -p path/to/spec/file.algo\n</code></pre> <pre><code>algobattle init -p \"Problem Name\"\n</code></pre> <p>Note</p> <p>This tutorial will use the Pairsum problem as an example, if you're following along your project folder will look slightly different depending on which problem you chose and what your course instructors decided to include with it.</p> <p>Once this has run the folder should look something like this</p> Problem specInstalled problem <pre><code>.\n\u2514\u2500 Pairsum\n   \u251c\u2500 generator/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 .gitignore\n   \u251c\u2500 algobattle.toml\n   \u251c\u2500 description.md    # this file may be missing, don't worry if it is!\n   \u2514\u2500 problem.py\n</code></pre> <pre><code>.\n\u2514\u2500 Pairsum\n   \u251c\u2500 generator/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 .gitignore\n   \u2514\u2500 algobattle.toml\n</code></pre> <p>What Algobattle has done is make a new project directory specific to this problem we're working with, and then initialized all the required files and folders in it. Let's navigate into it for the rest of the tutorial.</p> <pre><code>cd Pairsum\n</code></pre>"},{"location":"tutorial/getting_started/#the-algobattletoml-config-file","title":"The <code>algobattle.toml</code> config file","text":"<p>Project level configuration is done inside the <code>algobattle.toml</code> file so let's take a look at what's in there already.</p> Problem specInstalled problem <pre><code>[match]\nproblem = \"Pairsum\"\n# there might be more settings here\n\n[teams.\"Red Pandas\"]\ngenerator = \"generator\"\nsolver = \"solver\"\n</code></pre> <pre><code>[match]\nproblem = \"Pairsum\"\n\n[teams.\"Red Pandas\"]\ngenerator = \"generator\"\nsolver = \"solver\"\n</code></pre> <p>The config file is split into a few tables, <code>match</code> specifies exactly what each Algobattle match is going to look like. This means that you will probably never want to change things in there since you want to develop your programs for the same conditions they're going to see during the scored matches run on the server. Feel free to play with the <code>teams</code>, <code>problem</code>, and <code>project</code> tables as much as you want, nothing in them affects the structure of the match or anything on the server. In particular, the team name used here doesn't need to match the one used on your Algobattle website. The filled in settings so far all just are paths to where Algobattle can find certain files or folders. There's a lot more things you can configure, but we're happy with the default values for now.</p> <p>Tip</p> <p>If you're curious what exactly everything in here means you can read the config docs. But for now we recommend staying here since things will be much clearer after you're familiar with things here.</p>"},{"location":"tutorial/getting_started/#the-problempy-file","title":"The <code>problem.py</code> file","text":"<p>Note</p> <p>This will only exist if you used a problem spec file.</p> <p>This is what Algobattle uses as the problem definition. Once you're familiar with the way Algobattle does things you can cross-reference this to see what exactly your code needs to do. But it's also not directly meant to be human-readable and easily understandable, in particular if you're not familiar with Python and Pydantic.</p>"},{"location":"tutorial/getting_started/#the-description-file","title":"The <code>description.*</code> file","text":"<p>Note</p> <p>This will only exist if you used a problem spec file and your course instructors included it.</p> <p>This is the version of the problem definition that's more fun to read. It can be whatever your course instructors wanted to include, but most commonly is a Markdown or Pdf file.</p>"},{"location":"tutorial/installation/","title":"Installing Algobattle","text":"<p>The first thing we'll need to do is install the Algobattle framework. There's several ways to do this, which one you choose is entirely up to you and won't change the way things behaves. For each step we've outlined what we think is the easiest option and also outlined some alternatives.</p>"},{"location":"tutorial/installation/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"tutorial/installation/#installing-python","title":"Installing Python","text":"<p>Algobattle is a python package, so the first step is to make sure we have Python version 3.11 or higher available to us in an environment that you can install the Algobattle package and some dependencies into. If you already have that setup or know how to do it, feel free to skip to the next section.</p> <p>Not sure if you've already got python 3.11?</p> <p>You can check if you've already installed Python and what version it is by running <code>python --version</code>.</p> <p>Our recommendation</p> <p>There's a few different ways to install and use Python. If you don't care too much about the specifics, we recommend using Conda since it can do everything in one tool. There's several other programs that do similar jobs, and they all will have the same result. If you're already using one of them, feel free to just stick to using that one.</p>"},{"location":"tutorial/installation/#with-conda","title":"With Conda","text":"<p>Conda is very easy to use and manages python versions, virtual environments, and packages for you. You can get an installer for your operating system from the official Conda website. Once you've got it running you don't need to do anything else for this step since it will install python for you when we make a virtual environment.</p>"},{"location":"tutorial/installation/#manually","title":"Manually","text":"<p>You can also install Python manually from the Python website, or use another package manager.</p>"},{"location":"tutorial/installation/#virtual-environments","title":"Virtual environments","text":"<p>Python doesn't do a great job of managing package dependencies, which can cause issues if Algobattle needs a version of a library (or of Python itself) that some other program you use is incompatible with. To prevent this issue we use virtual environments, which basically behave as though they are separate installations of Python that do not affect each other. This means we can just make a fresh environment with Python 3.11 and install Algobattle there and never have to worry about anything breaking.</p> <p>First we create a virtual environment like this</p> <pre><code>conda create -n algobattle python=3.11\n</code></pre> <p>This process may take a second if it needs to download and install python. Once it's done we can now activate the environment</p> <pre><code>conda  activate algobattle\n</code></pre> <p>What this does, is make your current shell session use the Python installation from that environment. So if you now run <code>python --version</code> you should see 3.11, not whatever your global installation is (if you even have one). The environment will stay active until you close the shell or run <code>conda deactivate</code>. For everything other than Python commands your console will keep behaving just like it normally would.</p> <p>Tip</p> <p>Always remember to activate this environment when you want to use Algobattle. You won't need to do it every time you run a command, but once when you start a new terminal. If you're using an IDE like VSCode you can also configure it to automatically activate the environment whenever you open a console in a specific project.</p> <p>Using the global Python</p> <p>If you have a global Python installation that is 3.11 or higher you can also skip making a virtual environment. This generally is not a great idea, but if you really want to you can do it. In that case we recommend installing Algobattle into user space as explained in the last step.</p>"},{"location":"tutorial/installation/#installing-docker","title":"Installing Docker","text":"<p>We use Docker to easily manage and run the code students write, so you'll need to grab a fresh installation of it too. You can get the latest version from the official site here.</p> <p>Tip</p> <p>If you're using Linux you have the choice between Docker desktop and the Linux Docker Engine. If you're unsure what to get, we recommend Docker desktop as it provides a nicer user experience.</p>"},{"location":"tutorial/installation/#installing-algobattle_1","title":"Installing Algobattle","text":"<p>Installing Algobattle itself is the easiest part of everything since it's available in the Python Package Index. All we need to do is make sure the correct environment is active and run this</p> <pre><code>pip install algobattle-base\n</code></pre> <p>Using the global Python</p> <p>If you really want to install Algobattle into the global environment we recommend running <code>pip install --user algobattle-base</code> instead.</p>"},{"location":"tutorial/match/","title":"Running a match","text":""},{"location":"tutorial/match/#overview","title":"Overview","text":"<p>Now that we've got everything we need and have even written some working code we can try running an actual match. A match is basically Algobattle's way of determining whose code generates the hardest instances and solves them the best. It does this by running everyone's generator against everyone else's solver in what is called a battle.</p> Example <p>Let's say there are three teams Crows, Cats, and Otters. The battles will then look like this</p> Generating Solving crows cats crows otters cats crows cats otters otters crows otters cats <p>Tip</p> <p>If there's only one team Algobattle will run a single battle with that team performing both roles. You can use this to easily try out how well your code performs.</p> <p>Algobattle also lets course instructors customize what each battle looks like. This is usually done much more rarely than changing up the problem, so you won't have to learn much more stuff! Throughout this page we will be using the Iterated battle type since it's the default and explains things the best. The idea behind Iterated battles is that we want to figure out what the biggest size is where the solving team can still correctly solve the generating team's instances. We do this by first having the generator create an instance up to some particular size. Then the solving team must solve this instance. If it manages to do so, we repeat this cycle (called a Fight) with a bigger maximum instance size. At some point the instances will be so big that the solver can't keep up any more and produces a wrong solution. The last size where the solving team still was correct becomes that team's score.</p> <p>More details</p> <p>The process described above is the best way to explain this battle type, but it's not actually precisely how it works. You can find the actual process description in our battle types page.</p>"},{"location":"tutorial/match/#lets-get-started","title":"Let's get started","text":"<p>To run a match we just execute</p> <pre><code>algobattle run\n</code></pre> <p>This will display a lot of info to the command line. We will now go through it all step by step and explain what Algobattle is doing and what the interface is trying to tell us.</p>"},{"location":"tutorial/match/#building-programs","title":"Building programs","text":"<p>The First part of a match is building every team's programs. Depending on how complicated they are this may take a little while. During this step Algobattle gets all the programs ready for execution, compiles and installs them, etc.</p> You can't just skip over what's actually happening! <p>Yes I can . The actual details of this are somewhat complicated if you're not familiar with Docker (and if you are, you'll have already figured our what's going on) so we recommend skipping over this for now. We recommend skipping over the details here for now and if you still want to learn more later you can check out the advanced guide on Docker.</p> <p>During this the interface will look something like this</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Algobattle 4.0.0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Building programs \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2578\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/2 \u2502\n\u2502 Red Pandas \u2834 \u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501 0:00:15                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>This looks much better with colours</p> <p>Don't worry if you find this hard to read here, it should be a lot more readable in your terminal with proper alignment and colour rendering.</p> <p>This should be fairly straightforward, the top progress bar tracks how many programs need to be built in total and below we have a full listing of every participating team. There are two programs here since there is only one team with a generator and a solver.</p>"},{"location":"tutorial/match/#the-match-itself","title":"The match itself","text":"<p>With the programs built, the actual match can start. While this is happening a lot of different things will be displayed, so let's go through each of them on its own:</p>"},{"location":"tutorial/match/#match-overview","title":"Match overview","text":"<pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Algobattle 4.0.0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                              \u2502\n\u2502            Match overview                                                    \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513                                         \u2502\n\u2502 \u2503 Generating \u2503  Solving   \u2503 Result \u2503                                         \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529                                         \u2502\n\u2502 \u2502 Red Pandas \u2502 Red Pandas \u2502    290 \u2502                                         \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\n\u2502                                                                              \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Red Pandas vs Red Pandas \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                              \u2502\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500 Current Fight \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u256d\u2500 Battle Data \u2500\u2500\u256e                            \u2502\n\u2502 \u2502 Max size: 294              \u2502 \u2502 reached: [290] \u2502                            \u2502\n\u2502 \u2502 Generator   0.5 / 20 \u2714     \u2502 \u2502 cap: 389       \u2502                            \u2502\n\u2502 \u2502 Solver    \u2819 1.1 / 20       \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                            \u2502\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                                               \u2502\n\u2502                              Most recent fights                              \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2502\n\u2502 \u2503 Fight \u2503 Max size \u2503  Score \u2503 Detail                                       \u2503 \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502\n\u2502 \u2502    12 \u2502      290 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 1.7s                 \u2502 \u2502\n\u2502 \u2502    11 \u2502      389 \u2502   0.0% \u2502 Solver failed: The json file does not exist. \u2502 \u2502\n\u2502 \u2502    10 \u2502      289 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 2.0s                 \u2502 \u2502\n\u2502 \u2502     9 \u2502      208 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.2s                 \u2502 \u2502\n\u2502 \u2502     8 \u2502      144 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.4s                 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>Right at the top you will see an overview over the whole match. This table lists every battle in the match, its participants, and what the result of that match was. For the Iterated battle type the result just is the highest size the solving team was able to solve.</p> <p>Everything below this is specific to each battle. It starts off by just showing you who the generating and solving team is.</p>"},{"location":"tutorial/match/#current-fight","title":"Current fight","text":"<pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Algobattle 4.0.0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                              \u2502\n\u2502            Match overview                                                    \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513                                         \u2502\n\u2502 \u2503 Generating \u2503  Solving   \u2503 Result \u2503                                         \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529                                         \u2502\n\u2502 \u2502 Red Pandas \u2502 Red Pandas \u2502    290 \u2502                                         \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\n\u2502                                                                              \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Red Pandas vs Red Pandas \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                              \u2502\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500 Current Fight \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u256d\u2500 Battle Data \u2500\u2500\u256e                            \u2502\n\u2502 \u2502 Max size: 294              \u2502 \u2502 reached: [290] \u2502                            \u2502\n\u2502 \u2502 Generator   0.5 / 20 \u2714     \u2502 \u2502 cap: 389       \u2502                            \u2502\n\u2502 \u2502 Solver    \u2819 1.1 / 20       \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                            \u2502\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                                               \u2502\n\u2502                              Most recent fights                              \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2502\n\u2502 \u2503 Fight \u2503 Max size \u2503  Score \u2503 Detail                                       \u2503 \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502\n\u2502 \u2502    12 \u2502      290 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 1.7s                 \u2502 \u2502\n\u2502 \u2502    11 \u2502      389 \u2502   0.0% \u2502 Solver failed: The json file does not exist. \u2502 \u2502\n\u2502 \u2502    10 \u2502      289 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 2.0s                 \u2502 \u2502\n\u2502 \u2502     9 \u2502      208 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.2s                 \u2502 \u2502\n\u2502 \u2502     8 \u2502      144 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.4s                 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>On the left we have info on the current fight. What maximum size it is using, and basic data on the programs. Here we can see that the generator has already run successfully using only half a second of the 20 it has, and the solver is still running at the moment.</p>"},{"location":"tutorial/match/#battle-data","title":"Battle data","text":"<p>On the right we see some data specific to the battle type. If you want to learn what the Iterated type displays here, check out its documentation in the battle types page.</p>"},{"location":"tutorial/match/#most-recent-fights","title":"Most recent fights","text":"<pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Algobattle 4.0.0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502                                                                              \u2502\n\u2502            Match overview                                                    \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513                                         \u2502\n\u2502 \u2503 Generating \u2503  Solving   \u2503 Result \u2503                                         \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529                                         \u2502\n\u2502 \u2502 Red Pandas \u2502 Red Pandas \u2502    290 \u2502                                         \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                         \u2502\n\u2502                                                                              \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Red Pandas vs Red Pandas \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                              \u2502\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500 Current Fight \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u256d\u2500 Battle Data \u2500\u2500\u256e                            \u2502\n\u2502 \u2502 Max size: 294              \u2502 \u2502 reached: [290] \u2502                            \u2502\n\u2502 \u2502 Generator   0.5 / 20 \u2714     \u2502 \u2502 cap: 389       \u2502                            \u2502\n\u2502 \u2502 Solver    \u2819 1.1 / 20       \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                            \u2502\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f                                               \u2502\n\u2502                              Most recent fights                              \u2502\n\u2502 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2502\n\u2502 \u2503 Fight \u2503 Max size \u2503  Score \u2503 Detail                                       \u2503 \u2502\n\u2502 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502\n\u2502 \u2502    12 \u2502      290 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 1.7s                 \u2502 \u2502\n\u2502 \u2502    11 \u2502      389 \u2502   0.0% \u2502 Solver failed: The json file does not exist. \u2502 \u2502\n\u2502 \u2502    10 \u2502      289 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 2.0s                 \u2502 \u2502\n\u2502 \u2502     9 \u2502      208 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.2s                 \u2502 \u2502\n\u2502 \u2502     8 \u2502      144 \u2502 100.0% \u2502 Runtimes: gen 0.1s, sol 0.4s                 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>At the bottom we can see some more info on the last five fights. The score of a fight indicates how well the solver did, with the Pairsum problem it can really only pass or fail, but some other problems judge the solution by e.g. how well it approximates an optimal solution. The detail column will display the runtimes of the programs if everything went well, or a short error message if some error occurred. Here we can see that all but the second to last fight happened without issue, but in that one the solver didn't actually output a solution, and thus failed.</p>"},{"location":"tutorial/match/#finishing-the-match","title":"Finishing the match","text":"<p>To get the full results you need to wait until the match is done running everything it needs to. But this can take quite a while, if you want you can safely cancel it early by pressing Ctrl+C. Algobattle will handle stopping any running programs and log the (partially) completed match to the file path it prints. This file will also contain more detailed error messages that didn't fit on the command line interface for every error that happened during the match.</p> <p>Finally, the leaderboard is displayed. Points are allocated by comparing how well each team did against each other team.</p>"},{"location":"tutorial/programs/","title":"Writing programs","text":""},{"location":"tutorial/programs/#problems","title":"Problems","text":"<p>Now that we've got our project setup we can take a look at what we actually need to do: solve some problem. In this page we'll work with the Pairsum problem. It's a nice and easy starting point to get familiar with things, but you can also jump right into things with the problem your course instructors gave you.</p>"},{"location":"tutorial/programs/#what-is-a-problem","title":"What is a problem?","text":"<p>The Algobattle lab course is about solving algorithmic problems. So what is that exactly? From a theoretical computer science perspective this doesn't have a clear answer, there are decision problems, function problems, optimization problems, etc. What all of them share is that a problem is a description of what its instances look like, and what correct solutions to them are.</p> <p>This idea is what Algobattle works with, a problem really is just some specification of what instances look like and what solutions of these are. For Pairsum this is very straightforward, each instance is a list of natural numbers and a solution is two pairs of them that have the same sum. For example, in the list <code>1, 2, 3, 4, 5</code> we find <code>2 + 5 = 3 + 4</code>. Unfortunately computers aren't quite clever enough to just take such an abstract definition and work with it directly, so each Algobattle problem also defines how instances and solutions should be encoded/decoded. Pairsum uses json for this, so the example above looks like this:</p> <p>Example instance</p> <pre><code>{\n    \"numbers\": [1, 2, 3, 4, 5]\n}\n</code></pre> <p>Example solution</p> <pre><code>{\n    \"indices\": [1, 4, 2, 3]\n}\n</code></pre> <p>Where the solution is the list of the indices of the numbers that we found, 2 is at index 1, 5 at 4, etc.</p>"},{"location":"tutorial/programs/#what-do-we-need-to-do","title":"What do we need to do?","text":"<p>Previously we've said that the code we're going to write will solve problems, but that is only half of the truth. What we actually need to do is write two different programs for each problem, one that generates instances and one that solves them. In a stroke of creativity typical for computer science we'll call these the generator and the solver and use the correspondingly named subfolders for them.</p> Project config <p>This is why the <code>teams</code> table in the project config has that structure. It tells Algobattle which teams' programs can be found where.</p>"},{"location":"tutorial/programs/#generator","title":"Generator","text":""},{"location":"tutorial/programs/#setup","title":"Setup","text":"<p>The first step in writing a program is deciding what language you want to use. Algobattle lets you choose whatever language you want, whether that be Python or rust, or even more esoteric choices like Brainfuck or PROLOG. But it's a lot easier to use one of the more common languages since it comes with some project templates for them. The list of these is:</p> <ul> <li>Python</li> <li>Rust</li> <li>C</li> <li>C++</li> <li>C#</li> <li>JavaScript</li> <li>Typescript</li> <li>Java</li> <li>Go</li> </ul> <p>Can't find your favourite language?</p> <p>If the language you want to use isn't on here you can still use it, but you have to set some things up yourself. It's probably easier to get started with one of these first and then once you're familiar with everything switch to what you want to stick with.</p> Help us make Algobattle better <p>Some languages either have no templates or some very bare-bones ones. This is mainly just because we aren't familiar enough with every language to provide better support. If you want to help us out make Algobattle even more awesome you can open an issue or submit a pull request on our GitHub with a better template for your language.</p> <p>We can then rerun the project initialization step and also tell it what language we want to use, Python in this example. Since the project is already initialized we can just omit the <code>--problem</code> option to reuse the current setup.</p> <pre><code>algobattle init --generator python\n</code></pre> <p>Overriding data</p> <p>Whenever you tell Algobattle to do something that would override already existing files it will ask you if you want to continue. Make sure that you only confirm if you don't need these files any more. In this example the data is just the initially auto-generated file we made when we set up the project folder, so we can safely replace it with the python template.</p> <p>No need to repeat yourself</p> <p>You can directly specify the languages you want to use when unpacking the problem spec file. We're only doing it in several steps here to explain every part on its own.</p> <p>Our project folder should now look something like this</p> <pre><code>.\n\u2514\u2500 Pairsum\n   \u251c\u2500 generator/\n   \u2502  \u251c\u2500 .gitignore    \n   \u2502  \u251c\u2500 Dockerfile\n   \u2502  \u251c\u2500 generator.py\n   \u2502  \u2514\u2500 pyproject.toml\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 .gitignore\n   \u2514\u2500 algobattle.toml\n</code></pre> <p>The important file here is <code>generator.py</code>, we need to put the code that we want to run as our generator in there.</p> What's <code>pyproject.toml</code>? <p>This is the file that Python uses to specify package metadata such as dependencies, project names, etc. It's already filled out with the data we need so we can just leave it as is for now.</p> What's <code>Dockerfile</code>? <p>This is the file that specified what Docker is supposed to do with our code. What exactly Docker does and what the Dockerfile says is rather complicated and not super important for us right now. It's explained in detail in the Docker guide.</p>"},{"location":"tutorial/programs/#what-it-needs-to-do","title":"What it needs to do","text":"<p>When we look in there it's rather empty right now:</p> generator.py<pre><code>\"\"\"Main module, will be run as the generator.\"\"\"\nimport json\nfrom pathlib import Path\n\n\nmax_size = int(Path(\"/input/max_size.txt\").read_text()) # (1)!\n\n\ninstance = ...\nsolution = ...\n\n\nPath(\"/output/instance.json\").write_text(json.dumps(instance))  # (2)!\nPath(\"/output/solution.json\").write_text(json.dumps(solution))\n</code></pre> <ol> <li> <p>This opens the input file and parses it into an integer.</p> </li> <li> <p>This writes the generated instance/solution as correctly formatted json to the output file.</p> </li> </ol> <p>The first thing that stands out is that we read from and write to some rather weird files. This is very intentional! When Algobattle is run your program won't see the actual filesystem of your computer but a more or less empty Linux install. It will also see two special folders there: <code>/input</code> and <code>/output</code>. As their names suggest these are responsible for holding the input to the program and where Algobattle looks for its output.</p> <p>So if a generator's job is to just create some difficult instance, why is it getting any input? This is because in principle a generator could make its job very easy by not actually making hard instances but just making big ones. Finding pairs of numbers with the same sum is going to be much harder in a 10000 number long list than one with only 10 after all. To make things more comparable and not just about who can write the most data to a file Algobattle forces us to stick to some given upper limit of size of instance we make.</p> <p>Info</p> <p>Usually your generator will be called with various different instance sizes, don't assume that it will always be the same. But on the other hand, you can always output an instance that is smaller than the asked for maximum size.</p> What exactly is an instance's size? <p>The exact definition of an instance's size depends on the particular problem. Most of the time it is what you'd intuitively understand it to mean though. In Pairsum's case it is the length of the list, practically all graph problems use the number of vertices, etc. If you're unsure check the problem description or ask your course instructors.</p> <p>The code then writes things to the output directory, but it doesn't just write the instance, it also writes a solution. It might seem weird at first, but many problems do require the generator to not only come up with an instance, but also solve it. This is to make sure that the instance does indeed have a solution. Otherwise, we could just make some list of numbers were no two pairs have the same sum and then always win no matter how good the other teams' solvers are!</p>"},{"location":"tutorial/programs/#writing-the-code","title":"Writing the code","text":"<p>Now comes the hardest part, writing the code that actually does all that! What exactly that looks like will depend on the particular problem you're working with, the language you chose, your workflow, etc. The great part is that Algobattle lets you have a lot of freedom here, you are completely free to write the code how you want to. To keep going with this tutorial we've provided an example generator here, but the particularities of it aren't super important for you to understand.</p> <p>Example generator</p> <p>An easy way to make a generator for Pairsum is to just output a bunch of random numbers:</p> generator.py<pre><code>\"\"\"Main module, will be run as the generator.\"\"\"\nimport json\nfrom pathlib import Path\nfrom random import randrange\n\n\nmax_size = int(Path(\"/input/max_size.txt\").read_text())\n\nnumbers = [randrange(2**63 - 1) for _ in range(max_size)]  # (1)!\ninstance = {\n    \"numbers\": numbers,  # (2)!\n}\nsolution = ...\n\n\nPath(\"/output/instance.json\").write_text(json.dumps(instance))\nPath(\"/output/solution.json\").write_text(json.dumps(solution))\n</code></pre> <ol> <li> <p>Generate <code>max_size</code> many random numbers in the 64-bit unsigned integer range.</p> </li> <li> <p>Pairsum expects a json object with a single key, <code>numbers</code> that contains the list of numbers.</p> </li> </ol> <p>But if we do that we'd then have to also actually solve this instance and if we're particularly unlucky that might not even be possible! So it's better if we don't make the entire list random and insert a handcrafted solution into the list:</p> generator.py<pre><code>\"\"\"Main module, will be run as the generator.\"\"\"\nimport json\nfrom pathlib import Path\nfrom random import randrange, sample\n\n\nmax_size = int(Path(\"/input/max_size.txt\").read_text())\n\n\nnumbers = [randrange(2**63 - 1) for _ in range(max_size - 4)]  # (1)!\ninstance = {\n    \"numbers\": numbers,\n}\n\na, b = randrange(2**63 - 1), randrange(2**63 - 1)  # (2)!\nc = randrange(min(a + b, 2**63 - 1))\nd = a + b - c\n\nindices = sorted(sample(range(max_size), 4))  # (3)!\nfor index, number in zip(indices, [a, b, c, d]):\n    numbers.insert(index, number)\n\nsolution = {\n    \"indices\": indices,\n}\n\n\nPath(\"/output/instance.json\").write_text(json.dumps(instance))\nPath(\"/output/solution.json\").write_text(json.dumps(solution))\n</code></pre> <ol> <li> <p>We now use four fewer random numbers</p> </li> <li> <p>Create four numbers such that a + b = c + d</p> </li> <li> <p>Insert them into the list at random places</p> </li> </ol>"},{"location":"tutorial/programs/#trying-it-out","title":"Trying it out","text":"<p>Now that we have an actual program we're ready to test it out by running</p> <pre><code>algobattle test\n</code></pre> <p>This tests both the generator and the solver, so it's expected that it shouts at us right now about the solver not working since we haven't written that yet. If your generator is written correctly the build and run tests for it should complete without issue though. If something isn't working quite right you will find the particular error message in the json document it links to.</p>"},{"location":"tutorial/programs/#solver","title":"Solver","text":"<p>With a working generator all that's missing is a solver. During a match this program will get the instances other teams' generators have created and be asked to solve them. In this example I will use rust for this, but you can again choose any language you like. First we run the initialization command again</p> <pre><code>algobattle init --solver rust\n</code></pre> <p>The project then looks like this</p> <pre><code>.\n\u2514\u2500 Pairsum\n   \u251c\u2500 generator/\n   \u2502  \u251c\u2500 .gitignore    \n   \u2502  \u251c\u2500 Dockerfile\n   \u2502  \u251c\u2500 generator.py\n   \u2502  \u2514\u2500 pyproject.toml\n   \u251c\u2500 results/\n   \u251c\u2500 solver/\n   \u2502  \u251c\u2500 src\n   \u2502  \u2502  \u2514\u2500 main.rs\n   \u2502  \u251c\u2500 .gitignore\n   \u2502  \u251c\u2500 Cargo.toml\n   \u2502  \u2514\u2500 Dockerfile\n   \u251c\u2500 .gitignore\n   \u2514\u2500 algobattle.toml\n</code></pre> <p>We can again see a similar structure to the Python template, but this time it's using a slightly different layout.</p> What's <code>Cargo.toml</code>? <p>This is what rust's tool Cargo uses for project specification. We can again ignore the contents of this for now.</p>"},{"location":"tutorial/programs/#writing-the-code_1","title":"Writing the code","text":"<p>The solver takes an instance and should produce a solution for it. Similar to the generator these will be in the <code>/input</code> and <code>/output</code> directory, but this time called <code>/input/instance.json</code> and <code>/output/solution.json</code> as you'd expect. Since we're already familiar with this I/O structure we can get right into writing the actual program.</p> <p>This will again widely vary based on how you choose to do things, We've got our rust example solver here:</p> <p>Example solver</p> <p>This solver just iterates over all possible combinations of four numbers in the input list and checks if they form a valid pair. It's horribly inefficient but will do for now </p> main.rs<pre><code>// Main module, will be run as the solver\n\nuse std::fs;\nuse std::error::Error;\nuse serde_json::{to_string, from_str};\nuse itertools::Itertools;\nuse serde::{Deserialize, Serialize};\n\n#[derive(Deserialize)] // (1)!\nstruct Instance {\n    numbers: Vec&lt;u64&gt;,\n}\n\n#[derive(Serialize)] // (2)!\nstruct Solution {\n    indices: Vec&lt;usize&gt;\n}\n\n\nfn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let instance: Instance = from_str(&amp;fs::read_to_string(\"/input/instance.json\")?)?;\n    let numbers = instance.numbers;\n\n    for indices in (0..numbers.len()).combinations(4) { // (3)!\n        let first = numbers[indices[0]] + numbers[indices[1]];\n        let second = numbers[indices[2]] + numbers[indices[3]];\n\n        if first == second { // (4)!\n            let solution = Solution {indices: indices};\n            fs::write(\"/output/solution.json\", to_string(&amp;solution)?)?;\n            return Ok(());\n        }\n    }\n    unreachable!()\n}\n</code></pre> <ol> <li> <p>This tells rust how to destructure the json input</p> </li> <li> <p>And this how to serialize the output</p> </li> <li> <p>Iterate over all possible combinations of four indices</p> </li> <li> <p>If the pairs have the same number we output them as the solutions</p> </li> </ol> <p>Note</p> <p>This program uses itertools so we have to run <code>cargo add itertools</code> inside the solver directory to add it to our dependencies.</p> Not familiar with Rust? <p>If you're not familiar with Rust this program probably looks pretty intimidating, but don't worry you won't need to understand the details of this program.</p>"},{"location":"tutorial/programs/#trying-it-out_1","title":"Trying it out","text":"<p>Now we can try our programs out again</p> <pre><code>algobattle test\n</code></pre> <p>This time it should run without any errors. If that doesn't work for you, there's error messages in the linked json file.</p>"},{"location":"tutorial/programs/#packaging-the-programs","title":"Packaging the Programs","text":"<p>You may want to share your code with e.g. your lab instructors. The best way to do that is to package them into Algobattle program files. We do this by running</p> <pre><code>algobattle package programs\n</code></pre> <p>Using the web framework</p> <p>If your lab is using the web framework, these files are what you need to upload to have your programs run in the matches.</p> <p>Keep program sizes down</p> <p>Algobattle will package everything in the program directories. This may include unnecessary build artefacts, logs, program output, etc. It's best to remove any superfluous files (in particular, anything in your <code>.gitignore</code>) from the directories before running this command.</p> <p>A peek behind the curtain</p> <p>These files again are just <code>zip</code> files containing everything in your programs' folders in a specific format.</p> <p>This will create two <code>.prog</code> files that contain all the data Algobattle needs to run our programs. We can then easily share our code using just these files, or upload them to the Algobattle website.</p>"},{"location":"tutorial/summary/","title":"Conclusion","text":"<p>If you've made it all the way through the tutorial you're now probably ready to start coding things yourself! There's a lot of stuff left to cover, but none of it is essential to get started and can be more easily understood once you're a bit more familiar with the framework. Feel free to try things out and come back to either the tutorial, or the advanced topics whenever you're having questions.</p> <p>Hope you have fun with Algobattle!</p>"}]}